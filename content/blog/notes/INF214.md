---
title: INF214 Cheat Sheet
date: "2020-07-01T22:12:03.284Z"
tags: Notes
---

# **INF214 Cheat Sheet**

- [**INF214 Cheat Sheet**](#inf214-cheat-sheet)
  - [Processes and Synchronization](#processes-and-synchronization)
    - [Terms](#terms)
      - [State](#state)
      - [Atomic Action {#atomic-action}](#atomic-action-atomic-action)
      - [Interference {#interference}](#interference-interference)
      - [Noninterference {#noninterference}](#noninterference-noninterference)
      - [Race Condition {#race-condition}](#race-condition-race-condition)
      - [Unnecessary delay {#unnecessary-delay}](#unnecessary-delay-unnecessary-delay)
      - [Eventual Entry {#eventual-entry}](#eventual-entry-eventual-entry)
      - [Properties {#properties}](#properties-properties)
      - [Assertions {#assertions}](#assertions-assertions)
      - [Pre Condition {#precondition}](#pre-condition-precondition)
      - [Post Condition {#postcondition}](#post-condition-postcondition)
      - [Fine-Grained Atomicity {#fine-grained-atomicity}](#fine-grained-atomicity-fine-grained-atomicity)
      - [Coarse-Grained Atomicity {#coarse-grained-atomicity}](#coarse-grained-atomicity-coarse-grained-atomicity)
      - [At-Most-Once Property {#at-most-once-property}](#at-most-once-property-at-most-once-property)
      - [Partial Correctness {#partial-correctness}](#partial-correctness-partial-correctness)
      - [Total Correctness {#total-correctness}](#total-correctness-total-correctness)
      - [Mutual exclusion {#mutual-exclusion}](#mutual-exclusion-mutual-exclusion)
      - [Critical Reference {#critical-reference}](#critical-reference-critical-reference)
      - [Critical Section {#critical-section}](#critical-section-critical-section)
    - [Logic](#logic)
    - [Fairness {#fairness}](#fairness-fairness)
      - [Unconditional fairness {#unconditional-fairness}](#unconditional-fairness-unconditional-fairness)
      - [Weak fairness {#weak-fairness}](#weak-fairness-weak-fairness)
      - [Strong fairness {#strong-fairness}](#strong-fairness-strong-fairness)
  - [Locks and Barriers {#locks-barriers}](#locks-and-barriers-locks-barriers)
    - [Locks {#locks}](#locks-locks)
      - [Deadlock {#deadlock}](#deadlock-deadlock)
      - [Livelock {livelock}](#livelock-livelock)
      - [Spinlock {#spinlock}](#spinlock-spinlock)
    - [Fair Solutions Algorithms {#fair-solutions-algorithms}](#fair-solutions-algorithms-fair-solutions-algorithms)
      - [The Ticket Algorithm {#ticket-algorithm}](#the-ticket-algorithm-ticket-algorithm)
  - [Barriers {#barriers}](#barriers-barriers)
    - [Barrier Implementation {#barrier-implementation}](#barrier-implementation-barrier-implementation)
      - [(BAD) Shared counter {#shared-counter}](#bad-shared-counter-shared-counter)
    - [Flags and Coordinator {#flags-and-coordinators}](#flags-and-coordinator-flags-and-coordinators)
    - [Symmetric Barriers {#symmetric-barriers}](#symmetric-barriers-symmetric-barriers)
  - [Semaphores {#semaphores}](#semaphores-semaphores)
    - [Semaphore Definition {#semaphore-definition}](#semaphore-definition-semaphore-definition)
    - [Syntax](#syntax)
    - [Mutual Exclusion With Semaphores {#mutex-semaphores}](#mutual-exclusion-with-semaphores-mutex-semaphores)
    - [Barrier With Semaphores {#barrier-semaphores}](#barrier-with-semaphores-barrier-semaphores)
    - [Split Binary Semaphores {#split-binary-semaphores}](#split-binary-semaphores-split-binary-semaphores)
  - [Monitors {#monitors}](#monitors-monitors)
    - [Monitor Properties {#monitor-properties}](#monitor-properties-monitor-properties)
  - [Monitor-Implementation {#monitor-implementation}](#monitor-implementation-monitor-implementation)
  - [Signalling {#monitor-signalling}](#signalling-monitor-signalling)
    - [C++ Monitor API {#cpp-monitor-api}](#c-monitor-api-cpp-monitor-api)
  - [Alang {#alang}](#alang-alang)
    - [Basics {#alang-basics}](#basics-alang-basics)
      - [Lambda Funcions{#lambda}](#lambda-funcionslambda)
      - [Processes in alang {#ps-alang}](#processes-in-alang-ps-alang)
      - [Indexes Processes {#indexed-processes}](#indexes-processes-indexed-processes)
      - [CO Function {#co-function}](#co-function-co-function)
    - [Atomic Execution {#alang-atomic-execution}](#atomic-execution-alang-atomic-execution)
      - [Critical Sections {#alang-critical-section}](#critical-sections-alang-critical-section)
      - [Atomic Variables {#alang-atomic}](#atomic-variables-alang-atomic)
      - [AWAIT Statement {#alang-await}](#await-statement-alang-await)
    - [SemaphoresÂ {#alang-semaphores}](#semaphores-alang-semaphores)
    - [Monitors {#alang-monitors}](#monitors-alang-monitors)
    - [Channels {#alang-channels}](#channels-alang-channels)
    - [Pointes {#pointers}](#pointes-pointers)
  - [C++ Concurrency {#cpp-concurrency}](#c-concurrency-cpp-concurrency)
    - [Sequential Consistency {#sequential-consistency}](#sequential-consistency-sequential-consistency)
    - [C++ Threads {#cpp-threads}](#c-threads-cpp-threads)
    - [Mutex {#cpp-mutex}](#mutex-cpp-mutex)
    - [Types of mutexes {#cpp-mutex-types}](#types-of-mutexes-cpp-mutex-types)
    - [Examples {#cpp-mutex-examples}](#examples-cpp-mutex-examples)
      - [Try-Lock Recursive mutex example: {#tlrme}](#try-lock-recursive-mutex-example-tlrme)
      - [Timed Mutex Example: {#tme}](#timed-mutex-example-tme)
      - [Shared Mutex Example: {#sme}](#shared-mutex-example-sme)
    - [Mutex-Wrappers {#cpp-mutex-wrapper}](#mutex-wrappers-cpp-mutex-wrapper)
      - [RAII {#raii}](#raii-raii)
      - [lock and lock_guard: {#lock-lockguard}](#lock-and-lockguard-lock-lockguard)
      - [unique_lock {#unique-lock}](#uniquelock-unique-lock)
      - [scoped_lock wrapper {#scoped-lock-wrapper}](#scopedlock-wrapper-scoped-lock-wrapper)
    - [C++ Conditional Variables {#cpp-conditional-variables}](#c-conditional-variables-cpp-conditional-variables)
      - [Thread Local Variables {#thread-local-variables}](#thread-local-variables-thread-local-variables)
      - [Call once {#call-once}](#call-once-call-once)
      - [C++ Atomics {#cpp-atomics}](#c-atomics-cpp-atomics)
      - [Atomic Objects {#atomic-objects}](#atomic-objects-atomic-objects)
      - [Compare and Swap {#compare-and-swap}](#compare-and-swap-compare-and-swap)
      - [Task-Based Parallelism {#task-based-paralellelism}](#task-based-parallelism-task-based-paralellelism)
    - [Futures {#futures}](#futures-futures)
      - [Future Class {#future-class}](#future-class-future-class)
      - [shared_future<T> {#shared-future}](#sharedfuturet-shared-future)
      - [Future Combinators {#future-combinators}](#future-combinators-future-combinators)
      - [future::then {#future-then}](#futurethen-future-then)
    - [Promises {#promises}](#promises-promises)
    - [Async {#async}](#async-async)
    - [Task System Implementations {#task-system-implementations}](#task-system-implementations-task-system-implementations)
    - [Number of threads {#number of threads}](#number-of-threads-number-of-threads)
    - [Compute Primes {#compute-primes}](#compute-primes-compute-primes)
  - [Software Transactional Memory {#stm}](#software-transactional-memory-stm)
    - [Rollback](#rollback)
  - [Message Passing Concurrency](#message-passing-concurrency)
    - [Channel](#channel)
    - [Client-Server with Message Passing](#client-server-with-message-passing)
    - [Synchronouse Message Passing](#synchronouse-message-passing)
  - [Coroutine {#coroutine}](#coroutine-coroutine)
    - [Subroutine {#subroutine}](#subroutine-subroutine)
    - [**Symmetric**](#symmetric)
    - [**Asymmetric**](#asymmetric)
    - [First-class coroutines](#first-class-coroutines)
    - [Generators-Iterators-Coroutines {#iterators}](#generators-iterators-coroutines-iterators)
    - [Coroutine Frame](#coroutine-frame)
    - [Closing coroutines](#closing-coroutines)
    - [Suspending coroutine](#suspending-coroutine)
    - [Resuming coroutine](#resuming-coroutine)
  - [Coding {#coding}](#coding-coding)
    - [**C++ Coding {cpp-coding}**](#c-coding-cpp-coding)
    - [Ticket Algorithm {c++-ticket}](#ticket-algorithm-c-ticket)
    - [Semaphores {#cpp-semaphores}](#semaphores-cpp-semaphores)
    - [Semaphores implementation {#cpp-semaphores-implementation}](#semaphores-implementation-cpp-semaphores-implementation)
    - [Semaphores Banking Problem {#cpp-banking-problem}](#semaphores-banking-problem-cpp-banking-problem)
    - [Monitor {#cpp-monitor}](#monitor-cpp-monitor)
      - [Bridge Crossing Problem {#cpp-bridge}](#bridge-crossing-problem-cpp-bridge)
    - [Message Passing and Channels {#message-passing-channels}](#message-passing-and-channels-message-passing-channels)
    - [Filters With Quicksort {#filters-with-quicksort}](#filters-with-quicksort-filters-with-quicksort)
    - [Saving Account {#savings-account}](#saving-account-savings-account)
## Processes and Synchronization

### Terms

#### State

- A value a variable has at a given time

#### Atomic Action {#atomic-action}

- A sequence of one or more statements that appears to execute as a single, indivisible action

#### Interference {#interference}

- The result of two processes reading and writing the same variable in an unpredictable order

#### Noninterference {#noninterference}

- A relation between an atomic action and a critical assertion C in another process. Executing a does not interfere with c if it leaves c true if c is already true

#### Race Condition {#race-condition}

- A scenario where to processes interacts with a shared variable, causing on process to write to the variable and continue executing. Thus racing ahead before the other process and changes the variable again before the other process sees the result of the first change

#### Unnecessary delay {#unnecessary-delay}

- If a process is trying to enter its critical section and the other processes are executing their noncritical sections or have terminated, the process is not prevented from entering its critical section

#### Eventual Entry {#eventual-entry}

- A process that is trying to enter its critical section, is eventually allowed to succeed

#### Properties {#properties}

- Attribute that is true for every possible history of the program
- **Safety Property**
  - A property where the program never enters a bad state, where the variables have undesired values
- **Liveness Property**
  - A property where the program eventually reaches a good state, variables have desired values

#### Assertions {#assertions}

- An assertion characterises an acceptable program state

#### Pre Condition {#precondition}

- An assertion that is true when statement **S** finishes

#### Post Condition {#postcondition}

- An assertion that is true when statement **Q** finished

#### Fine-Grained Atomicity {#fine-grained-atomicity}

- No intermediate state is visible to the program
- An assignment appears to be atomic since no state from a process is visible to another process

#### Coarse-Grained Atomicity {#coarse-grained-atomicity}

- Atomicity implemented using [critical section](#critical-section) protocols

#### At-Most-Once Property {#at-most-once-property}

- Attribute of an assignment **x = e** where x is not read by another process and e only contains at most one reference to a variable changed by another process, it does contains a [critical reference](#critical-reference), or
- x is not written by another process and e contains no references to a variable changed by another process
- There can be at most one shared variable that can at most be referenced once
- If the assignments meets AMO, it will appear [atomic](#atomic-action)

#### Partial Correctness {#partial-correctness}

- The program is correct if the final state is correct
- If the initial program state satisfies P, then the final state will satisfy Q assuming S terminates

#### Total Correctness {#total-correctness}

- Combines partial correction with termination. A program is totally correct if the program always terminates with the desired results

#### Mutual exclusion {#mutual-exclusion}

- A synchronization ensuring statements in different processes can not execute at the same time

#### Critical Reference {#critical-reference}

- Reference to a variable changed by another process

#### Critical Section {#critical-section}

- A sequence of statements where shared variables are read and written by multiple processes

### Logic

- Formal logic system that allows one to state and prove properties of programs (PL system)
- Formulas of PL are called triples{#triples}

  - Has the form **{P} S {Q}**
  - P and Q are [assertions](#assertions)
  - P is the [pre condition](#precondition) and Q the [post condition](#postcondition)
  - Is true if execution of S has begun in a state satisfying P resulting in Q when the program terminates
  - Executing **S** in state **{P}** == **{Q}**
  - Is [partial correctness](#partial-correctness)

- Hoare tripple
  - **{P} C {Q}**
  - P and Q are [assertions](#assertions)
  - C is the command
  - Provides logical axioms and interference rules causing the command to execute when the [pre condition](#precondition) is met, and establishes the [post condition](#postcondition)

### Fairness {#fairness}

- **An attribute of a program ensuring that every delayed process gets a chance to proceed**
- Concerned with guaranteeing that a process gets a chance to proceed regardless of the other processes
- A process is **eligible**{#eligible} if it is the next [atomic action](#atomic-action) in the process that could be executed
- A scheduling policy determines which process will be executed next

#### Unconditional fairness {#unconditional-fairness}

- A scheduling policy is unconditionally fair if every unconditionally atomic action is eligible for execution eventually

#### Weak fairness {#weak-fairness}

- Unconditionally fair
- Action is continuously enabled and will eventually be executed
- If p holds from a point and on, then q will also hold eventually
- Not sufficient for ensuring every eligible await statement is executed eventually because the condition might change from **true** to **false** while a process is delayed, for this, **strong fairness** is required

#### Strong fairness {#strong-fairness}

- Implies an action has to be continuously enabled infinitely often
- If p holds infinitely often, then eventually q will hold
- If an await statement is present in a program, even though the condition is false, the program will eventually terminate because the condition is infinitely often true

## Locks and Barriers {#locks-barriers}

- The **Goal** is to implement a system satisfying the following properties:
  - **[Mutual Exclusion](#mutual-exclusion)**
  - **[Absence of Deadlock](#deadlock)(Livelock)** ([safety property](#safety-property))
  - **[Absence of Unnecessary Delay](#unnecessary-delay)** ([safety property](#safety-property))
  - **[Eventual Entry](#eventual-entry)**
- The first three are [safety properties](#safety-property)
- The last is a [liveness property](#liveness-property)

### Locks {#locks}

#### Deadlock {#deadlock}

- A state where to processes wait for each other where none gets to execute

#### Livelock {livelock}

- A scenario where a process is waiting for a process to be **true**, that will never become true. Livelock is the busy-waiting analog of deadlock

#### Spinlock {#spinlock}

- A boolean variable used with a busy-waiting to protect a critical section. A process wanting to enter, spins until it is allowed to enter

### Fair Solutions Algorithms {#fair-solutions-algorithms}

#### The Ticket Algorithm {#ticket-algorithm}

- Name based on drawing tickets
- **Practical example:** - Imagine a bakery where customers are served based on their arrival - When a customer arrives, he draws a ticket one larger than the previous customer - The customer waits until all the previous customers are served until it is his turn - Implemented by a number dispenser and a display displaying which customers turn it is - see [C++ Ticket Algorithm](#c++-ticket)

## Barriers {#barriers}

- Two solution to parallel computation:
  - **BAD**: Using CO statements in the body of the iteration depending on the previous iteration and ignoring termination
    - Inefficient because it is costly to the memory to create and destroy processes than to implement process synchronization
  - **GOOD** : Create the processes once at the beginning of the computation, then have them synchronize at the end of each computation.
    - This is what **Barrier Synchronization** is
- Computes disjoints parts of the solution in parallel
- Iterations are dependent of the result of the previous iteration
- Has a delay point(barrier) at the end of each iteration every process has to reach before any is allowed to pass

### Barrier Implementation {#barrier-implementation}

#### (BAD) Shared counter {#shared-counter}

- A counter that is initially 0, and when it reaches the desired n, all processes may pass
  - **AWAIT**
  - **Not Efficient!** since counter has to reset each time all processes pass
  - Can be solved with two counters, but this adds complexity since a process might get delayed examining one of the counters
  - Should only be used if target machine has [atomic](#atomic-action) increment instructions

### Flags and Coordinator {#flags-and-coordinators}

- Solves the memory contention problem from shared counters by implementing count as a sum of n shared values
- Achieved by adding a creating a array of integers **Arrive** and a new set new set of shared variables called **coordinator**
- Instead of having each worker sum and test values, set **Arrive[i]** to 1, each **worker[i]** delays waiting for **continue[i]** to become 1, this only has to wait for a single value to become true
- By calling this single value **continue**(which is an array of integers initialized as 0), a **worker[i]** only has to wait for **continue[i]** to be 1
- The **coordinator** waits for all elements of **arrive** to become 1 before letting before setting all elements of **continue** to be 1
- **Arrive** and **Continue** are examples of **Flag Variables**{#flag-variables}
- A variable raised by one process to signal another that the synchronization is true -

- **Flag Synchronization**{#flag-synchronization}
  - A process that wait for synchronization flag to be set, is the one that should clear the flag
    - Ensures flag is not cleared before it has been seen to be set
  - A flag should not be set until it is known that it is clear
    - Ensures a process not setting the same flag again if it has already been set

### Symmetric Barriers {#symmetric-barriers}

- Each process has a flag it sets when itâs arriving at a barrier. It then waits for the other process to set its flag before clearing the other processes flag
- Communicating with a binary connection
- **Butterfly Barrier:** -
  - Each process communicates with another process at each stage
  - Processes are indirectly synchronized with each other

## Semaphores {#semaphores}

### Semaphore Definition {#semaphore-definition}

- A program variable - Whose value is an integer > 0
- Can **only** be updated
- Controlled by two operations:
  - **P** : Wait for signal -
    - Wait until value > 0, then decrease value by one
  - **V** : Signal an event
    - Increase value by one

### Syntax

```cpp
sem; // init to null
sem s=k; // init to k
sem s[n] = ([n]1); // array of semaphores
```

- By default a semaphore is initialized as 0, but it can be initialized as any non-negative integer
- A **Binary Semaphore** only takes in the values 0 and 1

### Mutual Exclusion With Semaphores {#mutex-semaphores}

```cpp
sem mutex = 1;
process P[i=1 to m]{
 while(true){
 P(mutex);
 CS(critical section)
 V(mutex);
 non-cs
 }
}
```

- Semaphore initially 1, so that one process can enter the [Critical Section](#critical-section)
- **Always** **P**before **V** so value stays <=1
- Use one semaphore for each [synchronization flag](#flag-synchronization)
  - A PS sets a flag by executing **V**
  - Then waits for a flag to be set, and clears it with **P**

### Barrier With Semaphores {#barrier-semaphores}

- Using to signaling semaphores
- Processes signal their arrival by executing a **V** operation on its own semaphore, then waiting for another process and executing a **P** operation on its semaphore
- Typical signaling pattern:

```cpp
sem arrive1 = 0, arrive2 =0;
process P1 {
 V(arrive1) // signal arrival
 P(arrive2) // wait for other process
}
process P2{
 V(arrive2) // signal arrival
 P(arrive1) // wait for other process
}
```

- semaphores initialized to Ã
  - signal event **V**
  - wait for event **P**

### Split Binary Semaphores {#split-binary-semaphores}

- A set of semaphores where the **sum** of values <= 1
- [Mutual Exclusion](#mutual-exclusion) of many PSâs, guiding which one can execute
  - Initialize one semaphore to 1, other to Ã
  - Ensure that on every execution **P(s1)** is followed by **V(s2)** for some of the semaphores s1, s2
  - All statements between **P(s1)** and **P(s2)** is executed in mutual exclusion
- Has a shared buffer
- **Empty** and **Full** are two semaphores indicating if the buffer is full or empty

```cpp
typeT buf; // buffer of some type T
sem empty = 1, full = 0;

process Producer[i = 1 to m] {
 while(true){
  â¦
  // produce some data and deposit it in the buffer
  P(empty);
  buf = data;
  V(full)
 }
}
process Consumer[i = 1 to m] {
 while(true){
  â¦
  // fetch result, then consume it
  P(full);
  result = buf;
  V(empty)
  }
 }


```

## Monitors {#monitors}

### Monitor Properties {#monitor-properties}

- Thread safe abstract data type with synchronization
- Encapsulates representation of an abstract object
- Allows implicit [mutual exclusion](#mutual-exclusion)(at most one process can execute a function at any given time) and wait condition
- Has a [mutex lock](#mutex-lock) and conditional variables
- Threads wait for certain conditions to be met
- Processes are active, while monitors are passive

- **Monitor invariant**
  - Predicate that is true when no procedure is running, describes the valid good states
    - When an object is in a valid state, the class invariant holds
    - Must hold after initialization, when procedure terminates and when wait suspends executing
    - Assumes to hold at the beginning of procedure and after wait

## Monitor-Implementation {#monitor-implementation}

monitor m {
<br> permanent variables // shared by all processes
<br> initialization
<br> procedures // public
<br>}

## Signalling {#monitor-signalling}

- if cvâs queue is empty, no effect
- wake up a ps
- when ps calls signal, it is inside a monitor, making it two active psâs: current and the one being awakened

- Two strategies for ps to not run simultaneously
  - Signal and continue (SC), signaller continues running
  - Signal and wait (SW), signalled starts executing

### C++ Monitor API {#cpp-monitor-api}

- cond cv; // declaration
- empty(cv); // check if empty queue
- wait(cv); // make ps wait in cvâs queue
- signal(cv); // wake up a ps in cvâs queue
- signal_all(cv); // wake up all ps in cvâs queue

## Alang {#alang}

### Basics {#alang-basics}

- **compile with :**
  - -std=c++2a

#### Lambda Funcions{#lambda}

```cpp
[&, i, j, k] { /* body that uses i, j, and k */ }

```

#### Processes in alang {#ps-alang}

```cpp
processes ps; // ps will hold all processes

  ps += [&] { // define a task and start executing it
    while (x == 0);
```

#### Indexes Processes {#indexed-processes}

```cpp
int sum = 0;
{   // note this extra scope
    processes ps;

    for (int i=0; i<10; ++i) ps += [&,i]{ sum = sum + i; };
  } // ps goes out of scope here. Execution waits until all processes finished

  cout << "Sum is = " << sum << endl;
```

#### CO Function {#co-function}

```cpp
int x = 0;

  for (int i : range(0, 1000000))
    CO([&]{ x = x + 1; }, [&]{ x = x + 1; });

  cout << x << endl;

```

### Atomic Execution {#alang-atomic-execution}

#### Critical Sections {#alang-critical-section}

- [Definition](#critical-section)

```cpp
processes ps;
  for (int i : range(0, 10)) ps += [&, i] {
    enter_critical;
    cout << i << "+" << i << "=" << i+i << endl;
    exit_critical;
  };
```

#### Atomic Variables {#alang-atomic}

- [Definition](#atomic-action)

```cpp
 A<int> x = 0; // must use A<int>; otherwise ATOMIC has no effect

  for (int i : range(0, 100000))
    CO([&]{ ATOMIC([&]{x = x + 1;}); },
       [&]{ ATOMIC([&]{x = x + 1;}); },
       [&]{ ATOMIC([&]{x = x + 1;}); },
       [&]{ ATOMIC([&]{x = x + 1;}); });

  cout << x << endl;
```

```cpp
 A<int> x;
  ATO
    x = 1;
    return;
    x = 2;
  MIC;
  cout << x << endl;
```

#### AWAIT Statement {#alang-await}

```cpp
A<int> x = 0;
  CO([&]{ ATO AWAIT (x == 100); x = -100; MIC; },
     [&]{ ATO while (x < 100) x = x + 1; MIC; });
  alang::logl(x);
```

### SemaphoresÂ {#alang-semaphores}

- [Definition](#semaphore-definition)

```cpp
semaphore sem1;     // declare a semaphore, initialize to 0
semaphore sem2 = 1; // declare a semaphore, initialize to 1

sem1.P(); // P operation
sem1.V(); // V operation
```

```cpp
semaphore sem;

  CO([&]{ cout << "Waiting... "; sem.P(); cout << "Got through." << endl; },
     [&]{ sleep(1s); cout << "Releasing... "; sem.V(); });
```

### Monitors {#alang-monitors}

- [Definition](#monitor)

```cpp
class semon : monitor {
  cond cv; // declare a condition variable in the monitor
  int s;   // semaphore's value
public:
  semon(int s=0) : s(s) { if (s<0) throw "bad semaphore"; }

  void P() {
    SYNC;
    while (s == 0) { wait(cv); }
    s = s - 1;
  }

  void V() {
    SYNC;
    s = s + 1;
    signal(cv);
  }

  int value() { SYNC; return s; } // not part of the semaphore API. Added so we can test.
};

int main() {
  semon s = 0;
  {
    processes ps;
    ps += [&s]{            for (int i=0; i<100; ++i) s.P(); };
    ps += [&s]{ sleep(1s); for (int i=0; i<200; ++i) s.V(); };
  }
  alang::logl(s.value());
}
```

```cpp
class m1 : monitor {
public:
  void f() { SYNC; }
  void g() { SYNC; f(); } // cannot call another procedure that is SYNCed
}

class m2 : monitor {
  helper() { /* do some work */ }
public:
  void f() { SYNC; helper(); } // ok
  void g() { SYNC; helper(); } // ok
}
```

### Channels {#alang-channels}

- [Definition](#channel)

```cpp
channel<int> c1;
channel<int, string> c2;
channel<vector<int>> c3;
channel<channel<int>*> c4;
```

```cpp


#include "alang.hpp"
using alang::channel;

int main() {
  channel<channel<int>, int> request;

  processes ps;

  // a server that doubles an integer
  ps += [&request]{
    channel<int> cr; // the channel for the response from the server
    int i;
    request.receive(cr, i);
    cr.send(2*i);
  };

  // a client process
  ps += [&request]{
    channel<int> c; int i;
    request.send(c, 1);
    c.receive(i);
    logl(i);
  };
}
```

### Pointes {#pointers}

```cpp
int x = 10;
int& y = x; // y refers to x, y and x are aliased
int z = y; // z = 10, z is not aliased with x or y
```

## C++ Concurrency {#cpp-concurrency}

- A memory model defines the semantics of shared variables
  - A set of guarantees about the order a program reads and writes are observed by a thread
    - âRulesâ a programmer has to follow when writing concurrent code
- **Threads**
  - Multiple threads can access the same shared variables
  - Each thread has its own local variables

### Sequential Consistency {#sequential-consistency}

- The result of an execution is the same for any order the operations from a processor
  - A sequential processor does **NOT** guarantee sequential consistency
  - Each processor issues memory requests
  - Processed from a FIFO(first-in, first-out) queue
  - If a program has no [data races](#race-condition), it is sequentially consistent
  - If else its behaviour is undefined
  - None of todays architecture is sequential consistent \* Because of performance optimization in hardware and

### C++ Threads {#cpp-threads}

- Each instance of the **thread** class represents threads of execution
- Communicates through shared variables
- Only terminates from inside program, not outside
- Creating a thread object:

```cpp
void print(string s1, string s2) {
cout << s1 << s2; }
std::thread t1([]() {
cout << "Hello"; });
std::thread t2(print, ", ", "World!");
```

- A thread may be joinable
  - A joinable thread is potentially executing
  - A not joinable thread is not executing
  - Only not joinable threads can be safely destroyed
  - Destructor of thread calls **std::terminate()**
- Example of joining thread:

```cpp
#include <iostream>
#include <thread>
void print(string s1, string s2) { cout << s1 << s2; }

int main() {
 std::thread t1([]() {cout << "Hello"; });
 std::thread t2(print, ", ", "World!");
 t1.join();
 t2.join();
 return 0;
}
```

- Example of **NOT** joining threads:

```cpp
#include <iostream>
#include <thread>
void print(string s1, string s2) { cout << s1 << s2; }
int main() {
 std::thread t1([]() { cout << "Hello"; });
 std::thread t2(print, ", ", "World!");
 //    t1.join();
 //    t2.join();
 return 0;
}
```

- Same example in alang:

```cpp
#include "alang.hpp"
void print(string s1, string s2) { cout << s1 << s2; }
int main() {
 processes ps;ps += []() {
 cout << "Hello";
 };
  ps += []() {
  print(", ", "World!");
  };
  return 0;
 }
```

- Helper function:

```cpp
void pause_thread_s(int n) {
 std::this_thread::sleep_for(std::chrono::seconds(n));
}
void pause_thread_ms(int n) {
 std::this_thread::sleep_for(std::chrono::milliseconds(n));
}
```

- this_thread:
  _get_id gets threads id
  _ yield hints to the scheduler to reschedule

- **detach()** lets a thread âlooseâ
- thread object becomes not joinable
- Example, removing âWorld!â:

```cpp
void print(string s1, string s2) { cout << s1 << s2; }
int main(){
 std::thread([]() {
 pause_thread_s(2);
 std::cout << "Hello";}).detach();
 std::thread(print, ", ", "World!").detach();
 pause_thread_s(1);
}
```

- Thread constructor parameters:

```cpp
template <class Fn, class... Args>
explicit thread (Fn&& fn, Args&&... args);
```

- Unhandled exceptions on thread terminates a program

### Mutex {#cpp-mutex}

- C++ protects access to shared data with:
  - [Mutexes](#mutual-exclusions)
  - [Locks](#locks)
  - [Atomics](#atomic-action)
- Mutual exclusion object
  - Thread gets ownership of a mutex by locking and releases it by unlocking
  - Member functions
  - **lock()** - block until mutex is available, the lock and continue
  - **try_lock()** - lock if available, otherwise false
    - **unlock()** - release ownership
- Code example:

```cpp

int acc = 0;
mutex acc_mutex;
void acc_square(int x) {
 int tmp = x * x;
 acc_mutex.lock();
 acc += tmp;acc_mutex.unlock();
 }
int main() {
 map<int, int> m;
 for (int j=0; j<1000; ++j) {
 acc = 0;
  vector<thread> ts;
  for (int i = 1; i <= 10; i++)
  ts.push_back(thread(acc_square, i));
  for (auto& t : ts) t.join();
  if (m.count(acc) == 0)
   m[acc] = 1;
    else m[acc]++;
    }
    for (auto kv : m)
    cout << "acc=" << kv.first << ": " << kv.second << " times\n";
  }
```

### Types of mutexes {#cpp-mutex-types}

- **Recursive mutex**
  _ Can be locked repeatedly by the same thread
  _ Released when unlocked the same amount of times
- **Timed Mutex**
  - Only wait for a locked mutex a limited amount of time before it gives up
- **Shared-timed-mutex, shared-recursive-mutex**:
  _ Shared and exclusive access
  _ Use full when there is a lot of read activity, but writing has to be exclusive

### Examples {#cpp-mutex-examples}

#### Try-Lock Recursive mutex example: {#tlrme}

```cpp
class counter {
 recursive_mutex mut;
 int c = 0;
 public:void tick() {
   mut.lock();
    ++c;
    mut.unlock();
    }
 void tickManyIfCan(int n) {
 if (mut.try_lock()) {
 while (n-- > 0) tick();
 mut.unlock();
  }
 }
 int value() {
 return c;
  }
 };
 void task(counter& ctr) {
 for (int i=0; i<100; i++) {
 pause_thread_ms(1);
 ctr.tickManyIfCan(10);
  }
 }
 int main() {
 counter ctr;
 thread t1(task, ref(ctr)), t2(task, ref(ctr)), t3(task, ref(ctr));
 t1.join(); t2.join(); t3.join();
 cout << "\nvalue = " << ctr.value();
 }
```

#### Timed Mutex Example: {#tme}

```cpp
timed_mutex mut;
 void attempt (atomic<int>& successes) {
  if (mut.try_lock_for(chrono::milliseconds(50))) {
  // now we have the lock
  ++successes;
  pause_thread_ms(2);
  mut.unlock();
 }
}
 void run() {
  thread ts[100];
   atomic<int> successes = 0;
   for (int i=0; i<100; ++i)
   ts[i] = thread(attempt, ref(successes));
   for (auto& t : ts)
   t.join();
   cout << "#successes = " << successes << endl;
  }
 int main() {
  run(); run(); run();
 }
```

#### Shared Mutex Example: {#sme}

```cpp
 td::shared_mutex
  s_mut;
  timer tm;
  void reading(const string& data, int secs) {
   s_mut.lock_shared();
   pause_thread_s(secs);
   alang::logl("Reader ", data, " ", tm.elapsed());
   s_mut.unlock_shared();
 }
  void writing(string& data, string d, int secs) {
   s_mut.lock();
   pause_thread_s(secs);
   data = d;
   s_mut.unlock();
   alang::logl("Writer ", d, " ", tm.elapsed());
  }
  int main() {
   string data = "A";
   vector<thread> ts;
   tm.reset();
   ts.emplace_back(reading, cref(data), 3);
   ts.emplace_back(reading, cref(data), 4);
   ts.emplace_back(writing, ref(data), "B", 1);
   ts.emplace_back(writing, ref(data), "C", 2);
   ts.emplace_back(reading, cref(data), 0);
   for (auto& t : ts) t.join();
 }
```

### Mutex-Wrappers {#cpp-mutex-wrapper}

#### RAII {#raii}

```cpp
int c;
mutex cm;
 ...
 {
 lock_guard<mutex> lock(cm); // mutex locked here
 foo(c);
 } // unlocked here when lock destroyed

```

#### lock and lock_guard: {#lock-lockguard}

- Adopts an already locked mutex \* **std::lock()** takes a given number of mutexes and locking them without [deadlocking](#deadlock)

```cpp
container a, b; // assume both have mutex member variable
{
 std::lock(a.mutex, b.mutex);
 lock_guard<mutex> l1(a.mutex, std::adopt_lock_t);
 lock_guard<mutex> l2(b.mutex, std::adopt_lock_t);
 a.put(b.get()); // maybe exceptions
 } // locks released here

```

#### unique_lock {#unique-lock}

- Can be given more policies
  - **adopt_lock_t**
  - **defer_lock_t**
  - **try_to_lock_t**
- or a duration or time point
  - For how long or wait time to acquire lock
- Moveable, transfers the mutex
- Unlocking and re locking possible

```cpp
container a, b; // assume both have mutex member variable
{
 unique_lock<mutex> l1(a.mutex, defer_lock_t);
 unique_lock<mutex> l2(b.mutex, defer_lock_t);
 lock(l1, l2);
 a.put(b.get());// maybe exceptions
 }// locks released here

```

#### scoped_lock wrapper {#scoped-lock-wrapper}

- Easiest mutex lock
- Can wrapt multiple mutexes from the constructor without deadlocking

```cpp
std::mutex m1, m2, m3;
 ...
{
 std::scoped_lock lock(m1, m2, m3);
 // critical section
} // mutexes released here (in reverse order)
```

- Mutexes can be different types
- No need to specify mutex types(C++17âs class template argument deduction)

### C++ Conditional Variables {#cpp-conditional-variables}

- Allows blocking a thread until notified
- Waiting methods from the **conditional variable** class puts the thread to sleep, to start waiting for a conditional variable
  - **void wait(unique_lock<mutex>);** see [unique-lock](#unique-lock)
  - **void wait_for(unique_lock<mutex>, chrono::duration<â¦>);** see [unique_lock](#unique_lock)
  - **wait_until(unique_lock<mutex>, chrono::time_point<â¦>);**
- A thread starts waiting holding a lock, and wakes up holding a lock
  - unique_lock associated with a mutex
- Notifies threads with:
  - **void notify_one()**
  - **void notify_all)()**
- **Spurious wakeup**
  - Scheduler can wake up threads without a calling notifying function

- Example:

```cpp
#include <condition_variable>
mutex mut;
condition_variable cv;
int resource = 0;
void worker (int amount) {
 unique_lock<mutex> lock(mut);
 while (amount > resource) cv.wait(lock);
 resource -= amount;
 cout << "Handled  " << amount << ", remains " << resource << endl;
 }
int main ()  {
 thread ts[10];
 for (int i = 0; i < 10; ++i)
  ts[i] = thread(worker, i);

  {
   unique_lock<mutex> lock(mut);
   pause_thread_s(1);
   resource = 100;} // unlock here
   cv.notify_all();
   for (auto& t : ts) t.join();
  }
```

#### Thread Local Variables {#thread-local-variables}

- **thread_local** \* Each thread has an instance of thread_local variable
- Allocated when a thread begins and Deallocated when it terminates
- Can be namespace scope, block scope or static member variables

#### Call once {#call-once}

- Allocates a piece of code to a single thread
- **call_once()**

```cpp
template< class Callable, class... Args >
void call_once(std::once_flag& flag, Callable&& f, Args&&... args);
```

- Each call of call_once with the once_flag defines a group
  - Other threads block on **call_once()** so that once thread at a time can execute until the flag is set

#### C++ Atomics {#cpp-atomics}

- **atomic<T> x**
  _ **T** cannot be arbitrary type, used for integral and pointer types
  _ Can be created an instance trivially copy type
  _ Can be implemented with hardware lock-free atomic opâs or:
  _ implemented using mutexes

#### Atomic Objects {#atomic-objects}

- **Atomic assignment**
  - T operator=(T)
  - void store(T, memory_order = std::memory_order_seq_cst)
- **Atomic read**
  - operator T() const
  - T load(memory_order = std::memory_order_seq_cst) const
- **Atomic Swap**
  - T exchange(T, memory_order = std::memory_order_seq_cst)
- **Compare-and-swap**
  - bool compare_exchange_weak (T& expected, T desired, ...)
  - bool compare_exchange_strong(T& expected, T desired, ...)
    - (the...stands for memory order parameters)
- **Atomic bit manipulation and arithmetic for those T that make sense**
  - fetch_and,fetch_or,fetch_xor,fetch_add,fetch_sub

#### Compare and Swap {#compare-and-swap}

```cpp
bool atomic<T>::compare_exchange_weak(T& expected, T desired);
```

- Use in a loop for as long as the value is expected

#### Task-Based Parallelism {#task-based-paralellelism}

- Abstracts over OS thread
  - Because OS threads are more expensive
  - Decomposed into independent **tasks**
- Tasks are determined from **dependency graphs**
  - **Future/Promised** and [**async**](#async) creates these graphs
  - **Promise and Future** are basic building blocks
  - A packaged task wraps any function object with a promise-future channel
  - A **Future object** is attached to the wrapped function object
  - Calling the object resolves the promise with **set_value**
  - Exception sets with **set_exception** \* **async** abstracts over a packaged task
- **Implementation ideas:**
  - **Thread pools**
  - **Work stealing**
  - Idle PSâs steal tasks from another PSâs queue
  - Tasks should be freely migrated between threads

### Futures {#futures}

- Delayed value that promises that eventually a value will exist

    ```cpp
    future<int> f = async([]{ return hailstone(9780657631) });
    ```

- A future can be queried when a value is required \* Could be blocking until value is not available yet

    ```cpp
     if (f.get() == 1) { ... }
     ```

- A placeholder for a result of a computation
  - **Three States**
    - Pending: Future has no value yet
    - Fulfilled: The future value has been achieved
    - Rejected: The future never got it's expected value

#### Future Class {#future-class}

- **template<class T> class future;**
  - Tis the type of the result (can be void)
  - T must beMoveConstructible
  - future<T>cannot be copied, only moved
- **void wait() const;**
  - blocks until futureâs result available
  - also wait_for() and wait_until()
- **T get();**
  - blocks until result available, then returns it
  - get can only be called once
- **bool valid() const;**
  - has the value not been queried? (with get or share)
  - does the future have a shared state
- **std::shared_future<T> share();** \
  - gets the value and moves the futureâs value to a shared future

#### shared_future<T> {#shared-future}

- Same as **future<T>** but can be copied
  - Many threads can wait
- Construct shared_future object for each shared state
- Example:

```cpp
void detect(int x, shared_future<int> y) {
 static std::mutex iom;
 if (x == y.get()) {
  unique_lock l(iom);
   cout << "Found " << x << endl;
   } else {
   unique_lock l(iom);
    cout << "Expecting " << x << endl;
    }
 }

int main() {
 promise<int> p;
 shared_future<int> f = p.get_future().share();
 for (int j=0; j<10; ++j)
  thread(detect, j, f).detach();
  pause_thread_s(1);
  p.set_value(7);
  pause_thread_s(1);
 }
```

#### Future Combinators {#future-combinators}

- **when_any**
  - Wait until at least one of a set of futures is ready:

   ```cpp
   auto f_or_g = when_any(async(f), async(g)); f_or_g.then([](future<int> f) { ... });
   ```

- **when_all**
  - Wait until all futures of a set is ready:

  ```cpp
  future<tuple<future<int>, future<int>>> f_and_g = when_all(async(f), async(g));
  future<int> futf, futg; tie(futf, futg) = f_and_g.get(); // blocks
  cout << futf.get() + futg.get();// does not block
  ```

#### future::then {#future-then}

- Used instead of blocking with **get** until a future is ready \* Does not block
- Example:

```cpp
#include <future>
using namespace std;
 future<int> f1 = async([]{ return hailstone(12342342); });
 future<string> f2 = f1.then(
 [](int i) { return to_string(i); }
 };

 cout << f2.get();
}

```

### Promises {#promises}

- Object
- Promise -> Future is a one-off communication channel
  - Together has a shared state
  - Ready flag
  - Eventual result or exception when ready
  - Only one future per promise
  - **get_future** can be called once
  - or [shared_future](#shared-future)
  - **set_value, set exception**
  - set ready flag and value/exception
  - unblock threads waiting for promise
  - Destruction a promise
  - Gives up shared state
  - Deletes if no future waiting
    - Else throws **broken_promise**
- Synchronized with **set_value** and **set_exception**
  - e.g futures **get** and **wait**

### Async {#async}

Two **Overloads:**

```cpp
// 1
template<class Function, class... Args>
std::future<typename std::result_of<Function(Args...)>::type>
async(Function&& f, Args&&... args);

// 2
template< class Function, class... Args >
std::future<typename std::result_of<Function(Args...)>::type>
async(std::launch policy, Function&& f, Args&&... args);

```

- Launch policy:
  - **launch::async** executes a new thread with thread locals initialized
  - **launch::deferred** executes in the same thread at a **get()** call

### Task System Implementations {#task-system-implementations}

- Determine the benefits of multithreading
  - **Amdahlâs Law:**
  - $ S(n) = \frac{1}{1-p + \frac{p}{n}} $
  - S is theoretical speedup
  - n is the factor of increase in resources(number of cores)
    - p is the portion benefitting from the resources(unit is time)

- Returning out results is a way for tasks to communicate
  - **async** schedules a packaged task and returns a future
  - future becomes **ready** when task completes

- All following examples assumes these are included:

```cpp
#include <thread>
#include <mutex>
#include <deque>
#include <vector>
#include <unordered_map>
#include <functional>
#include <algorithm>
#include <string>
#include <future>
#include <type_traits>
using std::forward;
using std::move;
using std::function;
using std::thread;
using std::string;
using std::future;
using lock_t = std::unique_lock<std::mutex>;
```

### Number of threads {#number of threads}

- **thread::hardware_concurrency()**
  - May provide the number of cores currently in our system
- Number of threads allocated for the task affects speedup

```cpp
unsigned int number_of_threads() {
 return std::min(
 32u,
 std::max(1u, thread::hardware_concurrency()));
 }
```

### Compute Primes {#compute-primes}

```cpp
#include "task-system-utilities.hpp"

class notification_queue {
 std::deque<function<void()>> _q;
 std::mutex                   _mutex;
 std::condition_variable      _ready;
 bool                         _done = false;
  public:
   void done() {
    {
  lock_t lock(_mutex); _done = true;
     }
  _ready.notify_all();
   }

   bool pop(function<void()>& f) {
    lock_t lock(_mutex);
    while (_q.empty() && !_done) _ready.wait(lock);
    if (_q.empty()) return false;
    f = move(_q.front());
    _q.pop_front();return true;
   }
   template <typename F> void push(F&& f) {
    {
      lock_t lock(_mutex);
      _q.emplace_back(forward<F>(f));
      }
     _ready.notify_one();
   }
  };

class task_system {
 const unsigned int  _nthreads;
 std::vector<thread> _threads;
 notification_queue  _q;
 void run() {
  while (true) {
   function<void()> f;
   if (!_q.pop(f)) break; // !
   f();
   }
  }
 public:
  task_system(int nthreads = 0)
  : _nthreads(nthreads > 0 ? nthreads : number_of_threads())
  {
  for (unsigned int n = 0; n < _nthreads; ++n) {
  _threads.emplace_back([&]{ run(); });
  }
 }
 ~task_system() { _q.done(); for (thread& t: _threads) t.join(); }
 template <typename F>
 void async(F&& f) { _q.push(forward<F>(f)); }
};

bool is_prime(long num) {
 long limit = sqrt(num);
 if (num < 2) return false;
 for (long i=2; i<=limit ; i++) {
 if (num % i == 0) return false;
 } return true;
}

std::atomic<int> found = 0;
int count_primes(long n) {
 int count = 0; while (n-- > 1) { if (is_prime(n)) ++count; }
 return count;
}

const int ntasks = 4096;
void test(int nthreads) {
 double time;
  timer tmr;
  {
   task_system ts(nthreads);
   for (int i=0; i<ntasks; ++i)
    ts.async([&]{ found += count_primes(1000);  });
    }
  time = tmr.elapsed();
  logl("time ", time, " using ", nthreads, " threads");
 }

int main() {
 for (int n = 1; n <= 2048; n *= 2)
 test(n);
 test(thread::hardware_concurrency());
}
```

- **lock_t** is defined as **[std::unique_lock<std::mutex>](#unique-lock)**

- **front** accesses the first element, **pop_front** discards it
- Functions are moved, not copied

## Software Transactional Memory {#stm}

- Declare blocks of code that should execute atomically
- No locks
- Threads write without regard for other threads
- Keeps log of memory read/write
  - Logs are read after execution and compared to the memory
  - If execution has changed, the transaction is rolled back
  - Otherwise commited
- Good for programmer because
  - No need to keep track of locks(unless implemented)
  - No deadlock

- **Pros**
  - [Fine-Grained](#fine-grained-atomicity)
  - Good performance in dist. inviroments
- **Cons**
  - Performance could be a lot worse than locking

### Rollback

- **Occurs**
  - On Read
    - if variable is locked
    - Version greated than rv
- On commit
  - If any log variable can not be loacked
  - If any log variable locked or version higher than rv

## Message Passing Concurrency

- **Distributed Memory Architectures**
  - Processors has private memory
  - Connects with other PS's with **interconnect** network
  - Processes communicate by sending messages and recieving messages through **shared channels**
    - Via **RPC** og **rendez-vous**
    - Big Picture:

    ```cpp

                                        (implicit mutual exclusion)
                                     --> [Monitors]        -->
    [Busy Waiting] --> [Semaphores]                             [RPC/Rendez-vous]
                                     --> [Message Passing] -->
                                        (each semaphore carries data)

    ```

### Channel

- Communication path between processes
- chan c(type1, id1,....,typen,idn)

- ```cpp
    chan c1(int acc-id, int ctr, int amount)
    ```

- **Primitives**
  - Send
    - c(e1,e2,....,en)
    - Channel has c Space
    - Blocks if channel is full
  - recieve
    - c(var1,var2,...,varn)
    - Removes the message if C has atleast one
    - Blocks if empty
  - empty(c)

- **Channel abstraction**
  - One way
  - FIFO Queue
  - Atomic access to queue
  - Error-free
  - Typed

- **Filters**
  - One-way interaction pattern
  - A PS who recieves message from input channel
  - Sends to output(function of input and initial state) channels

### Client-Server with Message Passing

```cpp
    chan request(int clientID, typesofinpit);
    chan reply[n] (typesofresults)
    Process Server{
        int clientID;
        // initializstion, permanent variables
        while(true){
            recieve request(clientID, input values);
            // body
            send reply[clientID, result values]
        }
    }
    process client[i=0 to n-1]{
        send request(i,args);
        recieve reply[i] (res_args)
    }
    monitor Server{
        permanenet variables;
        initialization code;
        procesdure op(input_args){/* body; */ }
    }
```

### Synchronouse Message Passing

- **Sync_Send**
  - c(e1,e2,....,en)
  - Blocks until message is recieved
  - Sender and reciever synchroniza on sending and recieving a message
- **Perks**
  - Fixed channel size(no memory for message data)
    - At most one pending recieves message
    - At most one undelievered message
- **Draws**
  - Reduced parallelism
  - Higher [deadlock](#deadlock) risk
    - Deadlock example:

    ```cpp
    chan in1(int),in2(int);
    process P1{
        int v1,v2 = 1;
        sync_send
    }
    process P2 {
        int v1,v2 = 2;
        sync_send in1 (v2);
        recieve in2(v1):
    }


    ```

## Coroutine {#coroutine}

- Control abstraction for co-operative, or non-preemptive multitasking
- Generalization of [subroutines](#subroutine)
  - Suspending the execution
  - Resuming a suspended execution
- Coroutines are in progress simultaneously, but not executed at the same time

- Five transfer of control events:
  - Call
    - Activation frame/record pushed on to the stack
  - Return
    - Activation frame/record is popped from the stack
  - Suspend
    - Suspends execution, saves the frame/record, remembers the current point and transfer execution back to caller
  - Resume
    - Restores saved frame/record
  - Destroy
    - Deallocates saved frame/record

- Corollary: activation frame lifetime are not nested
  - Heap allocation

- Can run asynchronously with caller
- Caller can wait for suspension/return

```javascript
function* primes() {
    let primes = [];
    let c = 2;
    while (true) {
        let composite = false;
        for (let p of primes) {
            if (c % p == 0) {
                 composite = true;
                  break;
                   }
                  }
                  if (!composite) {
                      primes.push(c);
                       yield c;
                    }
                    ++c;
            }
    }
let p = primes();
while (true) {
    let r = p.next();
    if (r.value > 20) break;
    console.log(r.value);
    }

```

### Subroutine {#subroutine}

- Has a call and return

- Call
  - Pushes a new frame to stack
  - Suspends caller
  - jumps to the beginning of the function
- Return
  - passes return value to caller
  - Pops the frame
  - Resumes callerâs execution

- Has register for top of stack and allocates/deallocates(modify) the top of the stack

### **Symmetric**

- Singe control transfer operator that specifies target

### **Asymmetric**

- Similar to subroutines, transferred back to caller
- Symmetric/Asymmetric equally expensive, so can emulate each other

### First-class coroutines

- âBehaves like any value
- Can be store in variable
- Passed as parameter
- Returned from function
- Be yielded

- **Stackfull**
  - coroutines can suspend in nested functions
- **Stackless** coroutines can only suspend at top level
  - Must create new coroutine layer

### Generators-Iterators-Coroutines {#iterators}

- Is iterator if it implements next() with:
  - no arguments
  - returns object p such that
    - p.done : boolean
  - if p.done == false, then p.value is returned by the iterator

- An object is iterable if it has the computed property [Symbol.iterator], which is a nullary function returning an iterator

### Coroutine Frame

- Located in the iterator object
- Local variables are iterator objectsâs member variables

### Closing coroutines

- Breaking out of the iterator loop, closes the iterator
- Generators are close able iterators
- Resources can be cleansed at close
- Generators/Iterators are iterables and iterators

### Suspending coroutine

- yield communicates data from a coroutine to its caller when the coroutine is suspended
- yield e also receives data when coroutine resumed

### Resuming coroutine

- yield e is an expression, its value is the value sent to coroutine when it is resumed
- yield e can resume with an exception sent from its caller(ASYNC/AWAIT)

- Functions defined as async can contain await statements
- await e evaluates e to a promise, and waits until the promise is resolved
- The resolved promiseâs value is the value of the expression await e
- A rejected promise turns into an exception

## Coding {#coding}

### **C++ Coding {cpp-coding}**

### Ticket Algorithm {c++-ticket}

- [Explanation of the algorithm](#ticket-algorithm)

```cpp
#include "alang.hpp"
#include <vector>
using namespace std;

const int n = 4;
const int nCustomers = 4; // this many customers
const int nRounds = 5;    // each use service this many times
A<int> current_number = 0, next_served = 0;

int take_ticket_and_wait(int i)
{
    // take a ticket, print the received ticket number, and block until it is your turn
    // return the recived ticket number
    int myturn;
    ATO myturn = current_number;
    current_number = current_number + 1;MIC;
    alang::log("\nProcess ", i, " got turn: ", myturn);
    ATO AWAIT(myturn == next_served);MIC;
    return myturn;
}

void release_ticket()
{
    // let the next process proceed
    ATO next_served = next_served + 1; MIC;
}

int main()
{
    {
        processes ps;

        for (int i : range(0, nCustomers))
        {
            ps += [&, i] {
                for (int j : range(0, nRounds))
                {
                    int turn = take_ticket_and_wait(i);
                    // Perform task
                    alang::logl("\nProcess ", i, " runs on turn ", turn);
                    release_ticket();
                }
            };
        }
    }
}
```

**Output:**
<br>Process 1 got turn 0
<br>Process 0 got turn 1
<br>Process 2 got turn 2
<br>Process 3 got turn 3
<br>Process 1 runs on turn 0
<br>Process 1 got turn 4
<br>Process 0 runs on turn 1
<br>Process 0 got turn 5
<br>Process 2 runs on turn 2
<br>Process 2 got turn 6
<br>Process 3 runs on turn 3
<br>Process 3 got turn 7
<br>Process 1 runs on turn 4
<br>Process 1 got turn 8
<br>Process 0 runs on turn 5
<br>Process 0 got turn 9
<br>Process 2 runs on turn 6
<br>Process 2 got turn 10
<br>Process 3 runs on turn 7
<br>Process 3 got turn 11
<br>Process 1 runs on turn 8
<br>Process 1 got turn 12
<br>Process 0 runs on turn 9
<br>Process 0 got turn 13
<br>Process 2 runs on turn 10
<br>Process 2 got turn 14
<br>Process 3 runs on turn 11
<br>Process 3 got turn 15
<br>Process 1 runs on turn 12
<br>Process 1 got turn 16
<br>Process 0 runs on turn 13
<br>Process 0 got turn 17
<br>Process 2 runs on turn 14
<br>Process 2 got turn 18
<br>Process 3 runs on turn 15
<br>Process 3 got turn 19
<br>Process 1 runs on turn 16
<br>Process 0 runs on turn 17
<br>Process 2 runs on turn 18
<br>Process 3 runs on turn 19

### Semaphores {#cpp-semaphores}

- See [semaphores](semaphores)

### Semaphores implementation {#cpp-semaphores-implementation}

```cpp
#include "alang.hpp"

class barrier
{
    alang::semaphore arrive, depart;
    int ctr, n;

public:
    barrier(int n) : arrive(1), depart(0), ctr(0), n(n) {}

    void set(){
        arrive.P();
        if(ctr > n){
            arrive.V();
        } else {
            depart.V();
        }
        depart.P();
        if(ctr > 0){depart.V();}
             else{
                 arrive.V();
             }
        }
};

void launch_processes(processes &ps, barrier &b, int stages, int n){
    for (int i = 0; i < n; ++i)
    {
        ps += [&, i, stages] {
            for (int s = 0; s < stages; ++s)
            {
                logl("Stage ", s, ", process ", i);
                b.set();
            }
        };
    }
}
int main(){
    {
        barrier b(4);
        processes ps;
        launch_processes(ps, b, 3, 4);
    }
}

```

**Output:**
Stage 0, process 0
Stage 1, process 0
Stage 2, process 0
Stage 0, process 1
Stage 1, process 1
Stage 2, process 1
Stage 0, process 3
Stage 1, process 3
Stage 2, process 3
Stage 0, process 2
Stage 1, process 2
Stage 2, process 2

### Semaphores Banking Problem {#cpp-banking-problem}

- Multiple threads trying to deposit and withdraw from bank accounts

```cpp

#include "alang.hpp"

class bank_account
{
    alang::semaphore sem;
    int balance;
    int number;

public:
    bank_account(int n) :sem(1), balance(0), number(n) {}

    int get_number() { return number; }
    int get_balance() { return balance; }

    void deposit(int sum){
        sem.P();
        balance = balance + sum;
        sem.V();
    }

    void withdraw(int sum){
        sem.P();
        balance = balance - sum;
        sem.V();
    }

    void transfer_to(bank_account &b, int sum){
        if(this -> number < b.number){
        sem.P();
        b.sem.P();
        balance = balance - sum;
        b.balance = b.balance + sum;
        b.sem.V();
        sem.V();
        }else{
            sem.P();
            b.sem.P();
            balance = balance - sum;
            b.balance = b.balance + sum;
            sem.V();
            b.sem.V();
        }
    }
};
int main(){
    std::vector<bank_account *> vec;
    for (int i = 0; i < 10; ++i)
    {
        vec.push_back(new bank_account(i));
    }
    {
        processes ps;
        for (int i = 0; i < 100; ++i)
        {
            ps += [i, &vec] {
                for (int j = 0; j < 10; ++j)
                {
                    for (int k = 0; k < 10; ++k)
                    {
                        vec[j]->deposit(100);
                        vec[k]->withdraw(100);
                        vec[j]->withdraw(100);
                        vec[k]->deposit(100);
                        if (j != k)
                            vec[j]->transfer_to(*(vec[k]), 10);
                    }
                }
            };
        }
    }
    for (int i = 0; i < 10; ++i){
        alang::logl("Account ", i, " has balance ", vec[i]->get_balance());
    }
}

```

**Output**
<br>Account 0 has balance -70
<br>Account 1 has balance -240
<br>Account 2 has balance 0
<br>Account 3 has balance -210
<br>Account 4 has balance 30
<br>Account 5 has balance 110
<br>Account 6 has balance 90
<br>Account 7 has balance 90
<br>Account 8 has balance -300
<br>Account 9 has balance 240

### Monitor {#cpp-monitor}

#### Bridge Crossing Problem {#cpp-bridge}

- Cars has to drive over a bridge
- Only cars allowed in the same direction is allowed to drive at once
- Cars can drive past each other
- Cars coming from the opposite direction has to wait until the cars on the bridge have passed

```cpp
#include "alang.hpp"
#include <array>

using alang::logl;
using alang::prandom;
using alang::sleep_ms;
using std::array;
using std::string;

// "?" is a conditional statment in c++. If north is true, north is return, otherwise south
enum direction{ north = 0, south = 1};
direction opposite(direction dir){return (dir == north ? south : north);}

class bridge :  monitor{
    private:
        array<int, 2> ncars = { 0,0 }; // creates an array to see how many cars going in each direction
        // invariant ncars[north] == 0 ||Â ncars[south] == 0
        cond empty_bridge;
    public:
        bridge() {}
            array<int, 2> bridge_status(){
                SYNC;
                return ncars;
            }

            void car_arrive(direction dir){
                SYNC;
                while(ncars[opposite(dir)] != 0){
                    wait(empty_bridge);
                }
                ++(ncars[dir]);
            }

            void car_leave(direction dir){
            {
                SYNC;
                --(ncars[dir]);
            }
            if(ncars[dir]==0)
                signal_all(empty_bridge);
            }
};

auto car(bridge &b,
         int max_crossings,     // cross at most this many times
         int min_crossing_time, // crossing takes at least this long
         int max_crossing_time, // crossing takes at most this long
         int min_idle_time,     // wait at least this long before trying to cross again
         int max_idle_time){ // wait at most this long before trying to cross again

    return [=, &b] {
        direction dir = static_cast<direction>(prandom(0, 1)); // Casts a random direction
        int n = prandom(max_crossings);

        while(n-- > 0)
        {
            sleep_ms(prandom(min_idle_time, max_idle_time)); // Random idle time
            b.car_arrive(dir); // car arrives on bridge
            array<int, 2> counts = b.bridge_status(); // car on bridge checks car distrubution(invariant)
            assert(counts[north] == 0 || counts[south] == 0); // checks if it is empty

            if(counts[north] > 0)
                logl(string(counts[north], 'N'));
            else
                 logl(string(counts[south], 'S'));

            alang::sleep_ms(alang::prandom(min_crossing_time, max_crossing_time)); //random crossing time for car
            b.car_leave(dir); // bye bye car

            counts = b.bridge_status(); // checks bridge status againg
            assert(counts[north] == 0 || counts[south] == 0);

            dir = opposite(dir); // car turns back
        }
    };
}

int main(){
    bridge b;{
        processes ps;
        for (int i = 0; i < 10; i++){
            ps += car(b, 8, 1, 10, 2, 20);
             // 10 cars, 8 crossings each, each crossing takes 1-10ms, each car waits 2-20 ms
        }
    }
}

```

**Output:**
<br>N
<br>NN
<br>S
<br>SS
<br>SSS
<br>SSS
<br>N
<br>NN
<br>NNN
<br>S
<br>...

### Message Passing and Channels {#message-passing-channels}

- P1 sends random numbers to P2
- When P1 generates -1, P2 sends back the sum of the numbers sent by P1

```cpp
#include "alang.hpp"

alang::channel<int> c1, c2;

int main(){
    processes ps;
    ps += [] {
        int sum, m;
        while(m != -1){
			m = alang::prandom(-1, 10);
            c1.send(m);
            alang::logl("Sent ", m);
    	}
		c2.receive(sum);
		alang::logl("Recieved sum ", sum);
	};

    ps += [] {
        int sum, m = 0;
		while(true){
			c1.receive(m);
			alang::logl("Recieved ", m);
			if(m == -1)	break;
			sum += m;
			}
		alang::logl("Sending sum ", sum);
		c2.send(sum);
    };
}

```

### Filters With Quicksort {#filters-with-quicksort}

```cpp
#include "alang.hpp"

using d_channel = alang::channel<int>;
using alang::channel;
using alang::prandom;
using std::vector;

const int EOS = -1;

void partition_filter(int pivot, d_channel in1, d_channel out1, d_channel out2){
    int r;
    in1.receive(r);
    while(r != EOS){
        if(r <= pivot)
            out1.send(r);
        else
            out2.send(r);
        in1.receive(r);
    }
    out1.send(EOS);
    out2.send(EOS);
}

void merge_filter(d_channel in1, d_channel in2, d_channel out){
    int v1, v2;
    in1.receive(v1);
    in2.receive(v2);
    while (v1 != EOS && v2 != EOS){
        if (v1 <= v2){
            out.send(v1);
            in1.receive(v1);
        } else{
            out.send(v2);
            in2.receive(v2);
        }
    }while (v1 != EOS)  {
        out.send(v1);
        in1.receive(v1);
    }   while (v2 != EOS)  {
        out.send(v2);
        in2.receive(v2);
    }
    out.send(EOS);
}

void quick_sort(d_channel in, d_channel out){
    int pivot;
    in.receive(pivot);
    if(pivot == EOS){
        out.send(EOS);
        return;
    }
    d_channel sort1, sort2, o1, o2;

    processes ps;
    ps += [&]() { partition_filter(pivot, in, o1, o2); };
    ps += [&]() { quick_sort(o1, sort1); };
    ps += [&]() { sort2.send(pivot); quick_sort(o2,sort2); };
    ps += [&]() { merge_filter(sort1, sort2, out); };
}


int main(){
    const int EOS = -1;
    vector<int> vin, vout;{
        d_channel in, out; // note: channels are defined before ps, so that they are destructed after ps
        processes ps;

        ps += [&] { quick_sort(in, out); };

        ps += [&] {
            int p;
            do{
                p = prandom(-1, 10);
                vin.push_back(p);
                in.send(p);
            } while (p != EOS);
        };
        ps += [&] {
            while (true){
                int p;
                out.receive(p);
                vout.push_back(p);
                if (p == EOS)break;
            }
        };
    }
    for (auto i : vin)
        log(i, " ");
    logl();
    for (auto i : vout)
        log(i, " ");
    logl();
}

```

### Saving Account {#savings-account}

```cpp
#include "alang.hpp"

using alang::channel;
using std::to_string;
using std::vector;

using money = int;
using option = int;
using reply = money;

channel <channel<reply> , option, money> request;

const int DEPOSIT = 0, WITHDRAW = 1, KILL = 2;

auto bankServer = [] {
    std::deque<std::pair<channel<reply>, money>> queue;
    int balance = 0;
    while(true)
    {
        channel<reply> reply_channel;

        option op;
        money amount;

        request.receive(reply_channel, op, amount);
        switch (op)
        {

        case DEPOSIT:
            balance += amount;
            reply_channel.send(balance);

            while(!queue.empty())
            {
                auto p = queue.front();
                if(p.second < balance)
                {
                    balance -= p.second;
                    p.first.send(balance);
                    queue.pop_front();
                }else{
                    break;
                }
            }
            break;

        case WITHDRAW:
            if(amount > balance)
            {
                queue.push_back(std::make_pair(reply_channel, amount));

            }
            else{
                balance -= amount;
                reply_channel.send(amount);
            }
            break;

        case KILL: return;
        }
    }
};

int main(){
    processes ps;
    ps += [] {
        reply r;
        channel<reply> ch;
        for (int i = 0; i < 10; ++i)
        {
            request.send(ch, DEPOSIT, 100);
            ch.receive(r);
            logl(r);
        }
    };
    ps += [] {
        reply r;
        channel<reply> ch;
        for (int i = 0; i < 10; ++i)
        {
            request.send(ch, WITHDRAW, 100);
            ch.receive(r);
            logl(r);
        }
    };
    ps += bankServer;
    sleep(100ms);
    request.send(channel<reply>(), KILL, 0);

}# **INF214 Cheat Sheet**

- [**INF214 Cheat Sheet**](#inf214-cheat-sheet)
  - [Processes and Synchronization](#processes-and-synchronization)
    - [Terms](#terms)
      - [State](#state)
      - [Atomic Action {#atomic-action}](#atomic-action-atomic-action)
      - [Interference {#interference}](#interference-interference)
      - [Noninterference {#noninterference}](#noninterference-noninterference)
      - [Race Condition {#race-condition}](#race-condition-race-condition)
      - [Unnecessary delay {#unnecessary-delay}](#unnecessary-delay-unnecessary-delay)
      - [Eventual Entry {#eventual-entry}](#eventual-entry-eventual-entry)
      - [Properties {#properties}](#properties-properties)
      - [Assertions {#assertions}](#assertions-assertions)
      - [Pre Condition {#precondition}](#pre-condition-precondition)
      - [Post Condition {#postcondition}](#post-condition-postcondition)
      - [Fine-Grained Atomicity {#fine-grained-atomicity}](#fine-grained-atomicity-fine-grained-atomicity)
      - [Coarse-Grained Atomicity {#coarse-grained-atomicity}](#coarse-grained-atomicity-coarse-grained-atomicity)
      - [At-Most-Once Property {#at-most-once-property}](#at-most-once-property-at-most-once-property)
      - [Partial Correctness {#partial-correctness}](#partial-correctness-partial-correctness)
      - [Total Correctness {#total-correctness}](#total-correctness-total-correctness)
      - [Mutual exclusion {#mutual-exclusion}](#mutual-exclusion-mutual-exclusion)
      - [Critical Reference {#critical-reference}](#critical-reference-critical-reference)
      - [Critical Section {#critical-section}](#critical-section-critical-section)
    - [Logic](#logic)
    - [Fairness {#fairness}](#fairness-fairness)
      - [Unconditional fairness {#unconditional-fairness}](#unconditional-fairness-unconditional-fairness)
      - [Weak fairness {#weak-fairness}](#weak-fairness-weak-fairness)
      - [Strong fairness {#strong-fairness}](#strong-fairness-strong-fairness)
  - [Locks and Barriers {#locks-barriers}](#locks-and-barriers-locks-barriers)
    - [Locks {#locks}](#locks-locks)
      - [Deadlock {#deadlock}](#deadlock-deadlock)
      - [Livelock {livelock}](#livelock-livelock)
      - [Spinlock {#spinlock}](#spinlock-spinlock)
    - [Fair Solutions Algorithms {#fair-solutions-algorithms}](#fair-solutions-algorithms-fair-solutions-algorithms)
      - [The Ticket Algorithm {#ticket-algorithm}](#the-ticket-algorithm-ticket-algorithm)
  - [Barriers {#barriers}](#barriers-barriers)
    - [Barrier Implementation {#barrier-implementation}](#barrier-implementation-barrier-implementation)
      - [(BAD) Shared counter {#shared-counter}](#bad-shared-counter-shared-counter)
    - [Flags and Coordinator {#flags-and-coordinators}](#flags-and-coordinator-flags-and-coordinators)
    - [Symmetric Barriers {#symmetric-barriers}](#symmetric-barriers-symmetric-barriers)
  - [Semaphores {#semaphores}](#semaphores-semaphores)
    - [Semaphore Definition {#semaphore-definition}](#semaphore-definition-semaphore-definition)
    - [Syntax](#syntax)
    - [Mutual Exclusion With Semaphores {#mutex-semaphores}](#mutual-exclusion-with-semaphores-mutex-semaphores)
    - [Barrier With Semaphores {#barrier-semaphores}](#barrier-with-semaphores-barrier-semaphores)
    - [Split Binary Semaphores {#split-binary-semaphores}](#split-binary-semaphores-split-binary-semaphores)
  - [Monitors {#monitors}](#monitors-monitors)
    - [Monitor Properties {#monitor-properties}](#monitor-properties-monitor-properties)
  - [Monitor-Implementation {#monitor-implementation}](#monitor-implementation-monitor-implementation)
  - [Signalling {#monitor-signalling}](#signalling-monitor-signalling)
    - [C++ Monitor API {#cpp-monitor-api}](#c-monitor-api-cpp-monitor-api)
  - [Alang {#alang}](#alang-alang)
    - [Basics {#alang-basics}](#basics-alang-basics)
      - [Lambda Funcions{#lambda}](#lambda-funcionslambda)
      - [Processes in alang {#ps-alang}](#processes-in-alang-ps-alang)
      - [Indexes Processes {#indexed-processes}](#indexes-processes-indexed-processes)
      - [CO Function {#co-function}](#co-function-co-function)
    - [Atomic Execution {#alang-atomic-execution}](#atomic-execution-alang-atomic-execution)
      - [Critical Sections {#alang-critical-section}](#critical-sections-alang-critical-section)
      - [Atomic Variables {#alang-atomic}](#atomic-variables-alang-atomic)
      - [AWAIT Statement {#alang-await}](#await-statement-alang-await)
    - [SemaphoresÂ {#alang-semaphores}](#semaphores-alang-semaphores)
    - [Monitors {#alang-monitors}](#monitors-alang-monitors)
    - [Channels {#alang-channels}](#channels-alang-channels)
    - [Pointes {#pointers}](#pointes-pointers)
  - [C++ Concurrency {#cpp-concurrency}](#c-concurrency-cpp-concurrency)
    - [Sequential Consistency {#sequential-consistency}](#sequential-consistency-sequential-consistency)
    - [C++ Threads {#cpp-threads}](#c-threads-cpp-threads)
    - [Mutex {#cpp-mutex}](#mutex-cpp-mutex)
    - [Types of mutexes {#cpp-mutex-types}](#types-of-mutexes-cpp-mutex-types)
    - [Examples {#cpp-mutex-examples}](#examples-cpp-mutex-examples)
      - [Try-Lock Recursive mutex example: {#tlrme}](#try-lock-recursive-mutex-example-tlrme)
      - [Timed Mutex Example: {#tme}](#timed-mutex-example-tme)
      - [Shared Mutex Example: {#sme}](#shared-mutex-example-sme)
    - [Mutex-Wrappers {#cpp-mutex-wrapper}](#mutex-wrappers-cpp-mutex-wrapper)
      - [RAII {#raii}](#raii-raii)
      - [lock and lock_guard: {#lock-lockguard}](#lock-and-lockguard-lock-lockguard)
      - [unique_lock {#unique-lock}](#uniquelock-unique-lock)
      - [scoped_lock wrapper {#scoped-lock-wrapper}](#scopedlock-wrapper-scoped-lock-wrapper)
    - [C++ Conditional Variables {#cpp-conditional-variables}](#c-conditional-variables-cpp-conditional-variables)
      - [Thread Local Variables {#thread-local-variables}](#thread-local-variables-thread-local-variables)
      - [Call once {#call-once}](#call-once-call-once)
      - [C++ Atomics {#cpp-atomics}](#c-atomics-cpp-atomics)
      - [Atomic Objects {#atomic-objects}](#atomic-objects-atomic-objects)
      - [Compare and Swap {#compare-and-swap}](#compare-and-swap-compare-and-swap)
      - [Task-Based Parallelism {#task-based-paralellelism}](#task-based-parallelism-task-based-paralellelism)
    - [Futures {#futures}](#futures-futures)
      - [Future Class {#future-class}](#future-class-future-class)
      - [shared_future<T> {#shared-future}](#sharedfuturet-shared-future)
      - [Future Combinators {#future-combinators}](#future-combinators-future-combinators)
      - [future::then {#future-then}](#futurethen-future-then)
    - [Promises {#promises}](#promises-promises)
    - [Async {#async}](#async-async)
    - [Task System Implementations {#task-system-implementations}](#task-system-implementations-task-system-implementations)
    - [Number of threads {#number of threads}](#number-of-threads-number-of-threads)
    - [Compute Primes {#compute-primes}](#compute-primes-compute-primes)
  - [Software Transactional Memory {#stm}](#software-transactional-memory-stm)
    - [Rollback](#rollback)
  - [Message Passing Concurrency](#message-passing-concurrency)
    - [Channel](#channel)
    - [Client-Server with Message Passing](#client-server-with-message-passing)
    - [Synchronouse Message Passing](#synchronouse-message-passing)
  - [Coroutine {#coroutine}](#coroutine-coroutine)
    - [Subroutine {#subroutine}](#subroutine-subroutine)
    - [**Symmetric**](#symmetric)
    - [**Asymmetric**](#asymmetric)
    - [First-class coroutines](#first-class-coroutines)
    - [Generators-Iterators-Coroutines {#iterators}](#generators-iterators-coroutines-iterators)
    - [Coroutine Frame](#coroutine-frame)
    - [Closing coroutines](#closing-coroutines)
    - [Suspending coroutine](#suspending-coroutine)
    - [Resuming coroutine](#resuming-coroutine)
  - [Coding {#coding}](#coding-coding)
    - [**C++ Coding {cpp-coding}**](#c-coding-cpp-coding)
    - [Ticket Algorithm {c++-ticket}](#ticket-algorithm-c-ticket)
    - [Semaphores {#cpp-semaphores}](#semaphores-cpp-semaphores)
    - [Semaphores implementation {#cpp-semaphores-implementation}](#semaphores-implementation-cpp-semaphores-implementation)
    - [Semaphores Banking Problem {#cpp-banking-problem}](#semaphores-banking-problem-cpp-banking-problem)
    - [Monitor {#cpp-monitor}](#monitor-cpp-monitor)
      - [Bridge Crossing Problem {#cpp-bridge}](#bridge-crossing-problem-cpp-bridge)
    - [Message Passing and Channels {#message-passing-channels}](#message-passing-and-channels-message-passing-channels)
    - [Filters With Quicksort {#filters-with-quicksort}](#filters-with-quicksort-filters-with-quicksort)
    - [Saving Account {#savings-account}](#saving-account-savings-account)
## Processes and Synchronization

### Terms

#### State

- A value a variable has at a given time

#### Atomic Action {#atomic-action}

- A sequence of one or more statements that appears to execute as a single, indivisible action

#### Interference {#interference}

- The result of two processes reading and writing the same variable in an unpredictable order

#### Noninterference {#noninterference}

- A relation between an atomic action and a critical assertion C in another process. Executing a does not interfere with c if it leaves c true if c is already true

#### Race Condition {#race-condition}

- A scenario where to processes interacts with a shared variable, causing on process to write to the variable and continue executing. Thus racing ahead before the other process and changes the variable again before the other process sees the result of the first change

#### Unnecessary delay {#unnecessary-delay}

- If a process is trying to enter its critical section and the other processes are executing their noncritical sections or have terminated, the process is not prevented from entering its critical section

#### Eventual Entry {#eventual-entry}

- A process that is trying to enter its critical section, is eventually allowed to succeed

#### Properties {#properties}

- Attribute that is true for every possible history of the program
- **Safety Property**
  - A property where the program never enters a bad state, where the variables have undesired values
- **Liveness Property**
  - A property where the program eventually reaches a good state, variables have desired values

#### Assertions {#assertions}

- An assertion characterises an acceptable program state

#### Pre Condition {#precondition}

- An assertion that is true when statement **S** finishes

#### Post Condition {#postcondition}

- An assertion that is true when statement **Q** finished

#### Fine-Grained Atomicity {#fine-grained-atomicity}

- No intermediate state is visible to the program
- An assignment appears to be atomic since no state from a process is visible to another process

#### Coarse-Grained Atomicity {#coarse-grained-atomicity}

- Atomicity implemented using [critical section](#critical-section) protocols

#### At-Most-Once Property {#at-most-once-property}

- Attribute of an assignment **x = e** where x is not read by another process and e only contains at most one reference to a variable changed by another process, it does contains a [critical reference](#critical-reference), or
- x is not written by another process and e contains no references to a variable changed by another process
- There can be at most one shared variable that can at most be referenced once
- If the assignments meets AMO, it will appear [atomic](#atomic-action)

#### Partial Correctness {#partial-correctness}

- The program is correct if the final state is correct
- If the initial program state satisfies P, then the final state will satisfy Q assuming S terminates

#### Total Correctness {#total-correctness}

- Combines partial correction with termination. A program is totally correct if the program always terminates with the desired results

#### Mutual exclusion {#mutual-exclusion}

- A synchronization ensuring statements in different processes can not execute at the same time

#### Critical Reference {#critical-reference}

- Reference to a variable changed by another process

#### Critical Section {#critical-section}

- A sequence of statements where shared variables are read and written by multiple processes

### Logic

- Formal logic system that allows one to state and prove properties of programs (PL system)
- Formulas of PL are called triples{#triples}

  - Has the form **{P} S {Q}**
  - P and Q are [assertions](#assertions)
  - P is the [pre condition](#precondition) and Q the [post condition](#postcondition)
  - Is true if execution of S has begun in a state satisfying P resulting in Q when the program terminates
  - Executing **S** in state **{P}** == **{Q}**
  - Is [partial correctness](#partial-correctness)

- Hoare tripple
  - **{P} C {Q}**
  - P and Q are [assertions](#assertions)
  - C is the command
  - Provides logical axioms and interference rules causing the command to execute when the [pre condition](#precondition) is met, and establishes the [post condition](#postcondition)

### Fairness {#fairness}

- **An attribute of a program ensuring that every delayed process gets a chance to proceed**
- Concerned with guaranteeing that a process gets a chance to proceed regardless of the other processes
- A process is **eligible**{#eligible} if it is the next [atomic action](#atomic-action) in the process that could be executed
- A scheduling policy determines which process will be executed next

#### Unconditional fairness {#unconditional-fairness}

- A scheduling policy is unconditionally fair if every unconditionally atomic action is eligible for execution eventually

#### Weak fairness {#weak-fairness}

- Unconditionally fair
- Action is continuously enabled and will eventually be executed
- If p holds from a point and on, then q will also hold eventually
- Not sufficient for ensuring every eligible await statement is executed eventually because the condition might change from **true** to **false** while a process is delayed, for this, **strong fairness** is required

#### Strong fairness {#strong-fairness}

- Implies an action has to be continuously enabled infinitely often
- If p holds infinitely often, then eventually q will hold
- If an await statement is present in a program, even though the condition is false, the program will eventually terminate because the condition is infinitely often true

## Locks and Barriers {#locks-barriers}

- The **Goal** is to implement a system satisfying the following properties:
  - **[Mutual Exclusion](#mutual-exclusion)**
  - **[Absence of Deadlock](#deadlock)(Livelock)** ([safety property](#safety-property))
  - **[Absence of Unnecessary Delay](#unnecessary-delay)** ([safety property](#safety-property))
  - **[Eventual Entry](#eventual-entry)**
- The first three are [safety properties](#safety-property)
- The last is a [liveness property](#liveness-property)

### Locks {#locks}

#### Deadlock {#deadlock}

- A state where to processes wait for each other where none gets to execute

#### Livelock {livelock}

- A scenario where a process is waiting for a process to be **true**, that will never become true. Livelock is the busy-waiting analog of deadlock

#### Spinlock {#spinlock}

- A boolean variable used with a busy-waiting to protect a critical section. A process wanting to enter, spins until it is allowed to enter

### Fair Solutions Algorithms {#fair-solutions-algorithms}

#### The Ticket Algorithm {#ticket-algorithm}

- Name based on drawing tickets
- **Practical example:** - Imagine a bakery where customers are served based on their arrival - When a customer arrives, he draws a ticket one larger than the previous customer - The customer waits until all the previous customers are served until it is his turn - Implemented by a number dispenser and a display displaying which customers turn it is - see [C++ Ticket Algorithm](#c++-ticket)

## Barriers {#barriers}

- Two solution to parallel computation:
  - **BAD**: Using CO statements in the body of the iteration depending on the previous iteration and ignoring termination
    - Inefficient because it is costly to the memory to create and destroy processes than to implement process synchronization
  - **GOOD** : Create the processes once at the beginning of the computation, then have them synchronize at the end of each computation.
    - This is what **Barrier Synchronization** is
- Computes disjoints parts of the solution in parallel
- Iterations are dependent of the result of the previous iteration
- Has a delay point(barrier) at the end of each iteration every process has to reach before any is allowed to pass

### Barrier Implementation {#barrier-implementation}

#### (BAD) Shared counter {#shared-counter}

- A counter that is initially 0, and when it reaches the desired n, all processes may pass
  - **AWAIT**
  - **Not Efficient!** since counter has to reset each time all processes pass
  - Can be solved with two counters, but this adds complexity since a process might get delayed examining one of the counters
  - Should only be used if target machine has [atomic](#atomic-action) increment instructions

### Flags and Coordinator {#flags-and-coordinators}

- Solves the memory contention problem from shared counters by implementing count as a sum of n shared values
- Achieved by adding a creating a array of integers **Arrive** and a new set new set of shared variables called **coordinator**
- Instead of having each worker sum and test values, set **Arrive[i]** to 1, each **worker[i]** delays waiting for **continue[i]** to become 1, this only has to wait for a single value to become true
- By calling this single value **continue**(which is an array of integers initialized as 0), a **worker[i]** only has to wait for **continue[i]** to be 1
- The **coordinator** waits for all elements of **arrive** to become 1 before letting before setting all elements of **continue** to be 1
- **Arrive** and **Continue** are examples of **Flag Variables**{#flag-variables}
- A variable raised by one process to signal another that the synchronization is true -

- **Flag Synchronization**{#flag-synchronization}
  - A process that wait for synchronization flag to be set, is the one that should clear the flag
    - Ensures flag is not cleared before it has been seen to be set
  - A flag should not be set until it is known that it is clear
    - Ensures a process not setting the same flag again if it has already been set

### Symmetric Barriers {#symmetric-barriers}

- Each process has a flag it sets when itâs arriving at a barrier. It then waits for the other process to set its flag before clearing the other processes flag
- Communicating with a binary connection
- **Butterfly Barrier:** -
  - Each process communicates with another process at each stage
  - Processes are indirectly synchronized with each other

## Semaphores {#semaphores}

### Semaphore Definition {#semaphore-definition}

- A program variable - Whose value is an integer > 0
- Can **only** be updated
- Controlled by two operations:
  - **P** : Wait for signal -
    - Wait until value > 0, then decrease value by one
  - **V** : Signal an event
    - Increase value by one

### Syntax

```cpp
sem; // init to null
sem s=k; // init to k
sem s[n] = ([n]1); // array of semaphores
```

- By default a semaphore is initialized as 0, but it can be initialized as any non-negative integer
- A **Binary Semaphore** only takes in the values 0 and 1

### Mutual Exclusion With Semaphores {#mutex-semaphores}

```cpp
sem mutex = 1;
process P[i=1 to m]{
 while(true){
 P(mutex);
 CS(critical section)
 V(mutex);
 non-cs
 }
}
```

- Semaphore initially 1, so that one process can enter the [Critical Section](#critical-section)
- **Always** **P**before **V** so value stays <=1
- Use one semaphore for each [synchronization flag](#flag-synchronization)
  - A PS sets a flag by executing **V**
  - Then waits for a flag to be set, and clears it with **P**

### Barrier With Semaphores {#barrier-semaphores}

- Using to signaling semaphores
- Processes signal their arrival by executing a **V** operation on its own semaphore, then waiting for another process and executing a **P** operation on its semaphore
- Typical signaling pattern:

```cpp
sem arrive1 = 0, arrive2 =0;
process P1 {
 V(arrive1) // signal arrival
 P(arrive2) // wait for other process
}
process P2{
 V(arrive2) // signal arrival
 P(arrive1) // wait for other process
}
```

- semaphores initialized to Ã
  - signal event **V**
  - wait for event **P**

### Split Binary Semaphores {#split-binary-semaphores}

- A set of semaphores where the **sum** of values <= 1
- [Mutual Exclusion](#mutual-exclusion) of many PSâs, guiding which one can execute
  - Initialize one semaphore to 1, other to Ã
  - Ensure that on every execution **P(s1)** is followed by **V(s2)** for some of the semaphores s1, s2
  - All statements between **P(s1)** and **P(s2)** is executed in mutual exclusion
- Has a shared buffer
- **Empty** and **Full** are two semaphores indicating if the buffer is full or empty

```cpp
typeT buf; // buffer of some type T
sem empty = 1, full = 0;

process Producer[i = 1 to m] {
 while(true){
  â¦
  // produce some data and deposit it in the buffer
  P(empty);
  buf = data;
  V(full)
 }
}
process Consumer[i = 1 to m] {
 while(true){
  â¦
  // fetch result, then consume it
  P(full);
  result = buf;
  V(empty)
  }
 }


```

## Monitors {#monitors}

### Monitor Properties {#monitor-properties}

- Thread safe abstract data type with synchronization
- Encapsulates representation of an abstract object
- Allows implicit [mutual exclusion](#mutual-exclusion)(at most one process can execute a function at any given time) and wait condition
- Has a [mutex lock](#mutex-lock) and conditional variables
- Threads wait for certain conditions to be met
- Processes are active, while monitors are passive

- **Monitor invariant**
  - Predicate that is true when no procedure is running, describes the valid good states
    - When an object is in a valid state, the class invariant holds
    - Must hold after initialization, when procedure terminates and when wait suspends executing
    - Assumes to hold at the beginning of procedure and after wait

## Monitor-Implementation {#monitor-implementation}

monitor m {
<br> permanent variables // shared by all processes
<br> initialization
<br> procedures // public
<br>}

## Signalling {#monitor-signalling}

- if cvâs queue is empty, no effect
- wake up a ps
- when ps calls signal, it is inside a monitor, making it two active psâs: current and the one being awakened

- Two strategies for ps to not run simultaneously
  - Signal and continue (SC), signaller continues running
  - Signal and wait (SW), signalled starts executing

### C++ Monitor API {#cpp-monitor-api}

- cond cv; // declaration
- empty(cv); // check if empty queue
- wait(cv); // make ps wait in cvâs queue
- signal(cv); // wake up a ps in cvâs queue
- signal_all(cv); // wake up all ps in cvâs queue

## Alang {#alang}

### Basics {#alang-basics}

- **compile with :**
  - -std=c++2a

#### Lambda Funcions{#lambda}

```cpp
[&, i, j, k] { /* body that uses i, j, and k */ }

```

#### Processes in alang {#ps-alang}

```cpp
processes ps; // ps will hold all processes

  ps += [&] { // define a task and start executing it
    while (x == 0);
```

#### Indexes Processes {#indexed-processes}

```cpp
int sum = 0;
{   // note this extra scope
    processes ps;

    for (int i=0; i<10; ++i) ps += [&,i]{ sum = sum + i; };
  } // ps goes out of scope here. Execution waits until all processes finished

  cout << "Sum is = " << sum << endl;
```

#### CO Function {#co-function}

```cpp
int x = 0;

  for (int i : range(0, 1000000))
    CO([&]{ x = x + 1; }, [&]{ x = x + 1; });

  cout << x << endl;

```

### Atomic Execution {#alang-atomic-execution}

#### Critical Sections {#alang-critical-section}

- [Definition](#critical-section)

```cpp
processes ps;
  for (int i : range(0, 10)) ps += [&, i] {
    enter_critical;
    cout << i << "+" << i << "=" << i+i << endl;
    exit_critical;
  };
```

#### Atomic Variables {#alang-atomic}

- [Definition](#atomic-action)

```cpp
 A<int> x = 0; // must use A<int>; otherwise ATOMIC has no effect

  for (int i : range(0, 100000))
    CO([&]{ ATOMIC([&]{x = x + 1;}); },
       [&]{ ATOMIC([&]{x = x + 1;}); },
       [&]{ ATOMIC([&]{x = x + 1;}); },
       [&]{ ATOMIC([&]{x = x + 1;}); });

  cout << x << endl;
```

```cpp
 A<int> x;
  ATO
    x = 1;
    return;
    x = 2;
  MIC;
  cout << x << endl;
```

#### AWAIT Statement {#alang-await}

```cpp
A<int> x = 0;
  CO([&]{ ATO AWAIT (x == 100); x = -100; MIC; },
     [&]{ ATO while (x < 100) x = x + 1; MIC; });
  alang::logl(x);
```

### SemaphoresÂ {#alang-semaphores}

- [Definition](#semaphore-definition)

```cpp
semaphore sem1;     // declare a semaphore, initialize to 0
semaphore sem2 = 1; // declare a semaphore, initialize to 1

sem1.P(); // P operation
sem1.V(); // V operation
```

```cpp
semaphore sem;

  CO([&]{ cout << "Waiting... "; sem.P(); cout << "Got through." << endl; },
     [&]{ sleep(1s); cout << "Releasing... "; sem.V(); });
```

### Monitors {#alang-monitors}

- [Definition](#monitor)

```cpp
class semon : monitor {
  cond cv; // declare a condition variable in the monitor
  int s;   // semaphore's value
public:
  semon(int s=0) : s(s) { if (s<0) throw "bad semaphore"; }

  void P() {
    SYNC;
    while (s == 0) { wait(cv); }
    s = s - 1;
  }

  void V() {
    SYNC;
    s = s + 1;
    signal(cv);
  }

  int value() { SYNC; return s; } // not part of the semaphore API. Added so we can test.
};

int main() {
  semon s = 0;
  {
    processes ps;
    ps += [&s]{            for (int i=0; i<100; ++i) s.P(); };
    ps += [&s]{ sleep(1s); for (int i=0; i<200; ++i) s.V(); };
  }
  alang::logl(s.value());
}
```

```cpp
class m1 : monitor {
public:
  void f() { SYNC; }
  void g() { SYNC; f(); } // cannot call another procedure that is SYNCed
}

class m2 : monitor {
  helper() { /* do some work */ }
public:
  void f() { SYNC; helper(); } // ok
  void g() { SYNC; helper(); } // ok
}
```

### Channels {#alang-channels}

- [Definition](#channel)

```cpp
channel<int> c1;
channel<int, string> c2;
channel<vector<int>> c3;
channel<channel<int>*> c4;
```

```cpp


#include "alang.hpp"
using alang::channel;

int main() {
  channel<channel<int>, int> request;

  processes ps;

  // a server that doubles an integer
  ps += [&request]{
    channel<int> cr; // the channel for the response from the server
    int i;
    request.receive(cr, i);
    cr.send(2*i);
  };

  // a client process
  ps += [&request]{
    channel<int> c; int i;
    request.send(c, 1);
    c.receive(i);
    logl(i);
  };
}
```

### Pointes {#pointers}

```cpp
int x = 10;
int& y = x; // y refers to x, y and x are aliased
int z = y; // z = 10, z is not aliased with x or y
```

## C++ Concurrency {#cpp-concurrency}

- A memory model defines the semantics of shared variables
  - A set of guarantees about the order a program reads and writes are observed by a thread
    - âRulesâ a programmer has to follow when writing concurrent code
- **Threads**
  - Multiple threads can access the same shared variables
  - Each thread has its own local variables

### Sequential Consistency {#sequential-consistency}

- The result of an execution is the same for any order the operations from a processor
  - A sequential processor does **NOT** guarantee sequential consistency
  - Each processor issues memory requests
  - Processed from a FIFO(first-in, first-out) queue
  - If a program has no [data races](#race-condition), it is sequentially consistent
  - If else its behaviour is undefined
  - None of todays architecture is sequential consistent \* Because of performance optimization in hardware and

### C++ Threads {#cpp-threads}

- Each instance of the **thread** class represents threads of execution
- Communicates through shared variables
- Only terminates from inside program, not outside
- Creating a thread object:

```cpp
void print(string s1, string s2) {
cout << s1 << s2; }
std::thread t1([]() {
cout << "Hello"; });
std::thread t2(print, ", ", "World!");
```

- A thread may be joinable
  - A joinable thread is potentially executing
  - A not joinable thread is not executing
  - Only not joinable threads can be safely destroyed
  - Destructor of thread calls **std::terminate()**
- Example of joining thread:

```cpp
#include <iostream>
#include <thread>
void print(string s1, string s2) { cout << s1 << s2; }

int main() {
 std::thread t1([]() {cout << "Hello"; });
 std::thread t2(print, ", ", "World!");
 t1.join();
 t2.join();
 return 0;
}
```

- Example of **NOT** joining threads:

```cpp
#include <iostream>
#include <thread>
void print(string s1, string s2) { cout << s1 << s2; }
int main() {
 std::thread t1([]() { cout << "Hello"; });
 std::thread t2(print, ", ", "World!");
 //    t1.join();
 //    t2.join();
 return 0;
}
```

- Same example in alang:

```cpp
#include "alang.hpp"
void print(string s1, string s2) { cout << s1 << s2; }
int main() {
 processes ps;ps += []() {
 cout << "Hello";
 };
  ps += []() {
  print(", ", "World!");
  };
  return 0;
 }
```

- Helper function:

```cpp
void pause_thread_s(int n) {
 std::this_thread::sleep_for(std::chrono::seconds(n));
}
void pause_thread_ms(int n) {
 std::this_thread::sleep_for(std::chrono::milliseconds(n));
}
```

- this_thread:
  _get_id gets threads id
  _ yield hints to the scheduler to reschedule

- **detach()** lets a thread âlooseâ
- thread object becomes not joinable
- Example, removing âWorld!â:

```cpp
void print(string s1, string s2) { cout << s1 << s2; }
int main(){
 std::thread([]() {
 pause_thread_s(2);
 std::cout << "Hello";}).detach();
 std::thread(print, ", ", "World!").detach();
 pause_thread_s(1);
}
```

- Thread constructor parameters:

```cpp
template <class Fn, class... Args>
explicit thread (Fn&& fn, Args&&... args);
```

- Unhandled exceptions on thread terminates a program

### Mutex {#cpp-mutex}

- C++ protects access to shared data with:
  - [Mutexes](#mutual-exclusions)
  - [Locks](#locks)
  - [Atomics](#atomic-action)
- Mutual exclusion object
  - Thread gets ownership of a mutex by locking and releases it by unlocking
  - Member functions
  - **lock()** - block until mutex is available, the lock and continue
  - **try_lock()** - lock if available, otherwise false
    - **unlock()** - release ownership
- Code example:

```cpp

int acc = 0;
mutex acc_mutex;
void acc_square(int x) {
 int tmp = x * x;
 acc_mutex.lock();
 acc += tmp;acc_mutex.unlock();
 }
int main() {
 map<int, int> m;
 for (int j=0; j<1000; ++j) {
 acc = 0;
  vector<thread> ts;
  for (int i = 1; i <= 10; i++)
  ts.push_back(thread(acc_square, i));
  for (auto& t : ts) t.join();
  if (m.count(acc) == 0)
   m[acc] = 1;
    else m[acc]++;
    }
    for (auto kv : m)
    cout << "acc=" << kv.first << ": " << kv.second << " times\n";
  }
```

### Types of mutexes {#cpp-mutex-types}

- **Recursive mutex**
  _ Can be locked repeatedly by the same thread
  _ Released when unlocked the same amount of times
- **Timed Mutex**
  - Only wait for a locked mutex a limited amount of time before it gives up
- **Shared-timed-mutex, shared-recursive-mutex**:
  _ Shared and exclusive access
  _ Use full when there is a lot of read activity, but writing has to be exclusive

### Examples {#cpp-mutex-examples}

#### Try-Lock Recursive mutex example: {#tlrme}

```cpp
class counter {
 recursive_mutex mut;
 int c = 0;
 public:void tick() {
   mut.lock();
    ++c;
    mut.unlock();
    }
 void tickManyIfCan(int n) {
 if (mut.try_lock()) {
 while (n-- > 0) tick();
 mut.unlock();
  }
 }
 int value() {
 return c;
  }
 };
 void task(counter& ctr) {
 for (int i=0; i<100; i++) {
 pause_thread_ms(1);
 ctr.tickManyIfCan(10);
  }
 }
 int main() {
 counter ctr;
 thread t1(task, ref(ctr)), t2(task, ref(ctr)), t3(task, ref(ctr));
 t1.join(); t2.join(); t3.join();
 cout << "\nvalue = " << ctr.value();
 }
```

#### Timed Mutex Example: {#tme}

```cpp
timed_mutex mut;
 void attempt (atomic<int>& successes) {
  if (mut.try_lock_for(chrono::milliseconds(50))) {
  // now we have the lock
  ++successes;
  pause_thread_ms(2);
  mut.unlock();
 }
}
 void run() {
  thread ts[100];
   atomic<int> successes = 0;
   for (int i=0; i<100; ++i)
   ts[i] = thread(attempt, ref(successes));
   for (auto& t : ts)
   t.join();
   cout << "#successes = " << successes << endl;
  }
 int main() {
  run(); run(); run();
 }
```

#### Shared Mutex Example: {#sme}

```cpp
 td::shared_mutex
  s_mut;
  timer tm;
  void reading(const string& data, int secs) {
   s_mut.lock_shared();
   pause_thread_s(secs);
   alang::logl("Reader ", data, " ", tm.elapsed());
   s_mut.unlock_shared();
 }
  void writing(string& data, string d, int secs) {
   s_mut.lock();
   pause_thread_s(secs);
   data = d;
   s_mut.unlock();
   alang::logl("Writer ", d, " ", tm.elapsed());
  }
  int main() {
   string data = "A";
   vector<thread> ts;
   tm.reset();
   ts.emplace_back(reading, cref(data), 3);
   ts.emplace_back(reading, cref(data), 4);
   ts.emplace_back(writing, ref(data), "B", 1);
   ts.emplace_back(writing, ref(data), "C", 2);
   ts.emplace_back(reading, cref(data), 0);
   for (auto& t : ts) t.join();
 }
```

### Mutex-Wrappers {#cpp-mutex-wrapper}

#### RAII {#raii}

```cpp
int c;
mutex cm;
 ...
 {
 lock_guard<mutex> lock(cm); // mutex locked here
 foo(c);
 } // unlocked here when lock destroyed

```

#### lock and lock_guard: {#lock-lockguard}

- Adopts an already locked mutex \* **std::lock()** takes a given number of mutexes and locking them without [deadlocking](#deadlock)

```cpp
container a, b; // assume both have mutex member variable
{
 std::lock(a.mutex, b.mutex);
 lock_guard<mutex> l1(a.mutex, std::adopt_lock_t);
 lock_guard<mutex> l2(b.mutex, std::adopt_lock_t);
 a.put(b.get()); // maybe exceptions
 } // locks released here

```

#### unique_lock {#unique-lock}

- Can be given more policies
  - **adopt_lock_t**
  - **defer_lock_t**
  - **try_to_lock_t**
- or a duration or time point
  - For how long or wait time to acquire lock
- Moveable, transfers the mutex
- Unlocking and re locking possible

```cpp
container a, b; // assume both have mutex member variable
{
 unique_lock<mutex> l1(a.mutex, defer_lock_t);
 unique_lock<mutex> l2(b.mutex, defer_lock_t);
 lock(l1, l2);
 a.put(b.get());// maybe exceptions
 }// locks released here

```

#### scoped_lock wrapper {#scoped-lock-wrapper}

- Easiest mutex lock
- Can wrapt multiple mutexes from the constructor without deadlocking

```cpp
std::mutex m1, m2, m3;
 ...
{
 std::scoped_lock lock(m1, m2, m3);
 // critical section
} // mutexes released here (in reverse order)
```

- Mutexes can be different types
- No need to specify mutex types(C++17âs class template argument deduction)

### C++ Conditional Variables {#cpp-conditional-variables}

- Allows blocking a thread until notified
- Waiting methods from the **conditional variable** class puts the thread to sleep, to start waiting for a conditional variable
  - **void wait(unique_lock<mutex>);** see [unique-lock](#unique-lock)
  - **void wait_for(unique_lock<mutex>, chrono::duration<â¦>);** see [unique_lock](#unique_lock)
  - **wait_until(unique_lock<mutex>, chrono::time_point<â¦>);**
- A thread starts waiting holding a lock, and wakes up holding a lock
  - unique_lock associated with a mutex
- Notifies threads with:
  - **void notify_one()**
  - **void notify_all)()**
- **Spurious wakeup**
  - Scheduler can wake up threads without a calling notifying function

- Example:

```cpp
#include <condition_variable>
mutex mut;
condition_variable cv;
int resource = 0;
void worker (int amount) {
 unique_lock<mutex> lock(mut);
 while (amount > resource) cv.wait(lock);
 resource -= amount;
 cout << "Handled  " << amount << ", remains " << resource << endl;
 }
int main ()  {
 thread ts[10];
 for (int i = 0; i < 10; ++i)
  ts[i] = thread(worker, i);

  {
   unique_lock<mutex> lock(mut);
   pause_thread_s(1);
   resource = 100;} // unlock here
   cv.notify_all();
   for (auto& t : ts) t.join();
  }
```

#### Thread Local Variables {#thread-local-variables}

- **thread_local** \* Each thread has an instance of thread_local variable
- Allocated when a thread begins and Deallocated when it terminates
- Can be namespace scope, block scope or static member variables

#### Call once {#call-once}

- Allocates a piece of code to a single thread
- **call_once()**

```cpp
template< class Callable, class... Args >
void call_once(std::once_flag& flag, Callable&& f, Args&&... args);
```

- Each call of call_once with the once_flag defines a group
  - Other threads block on **call_once()** so that once thread at a time can execute until the flag is set

#### C++ Atomics {#cpp-atomics}

- **atomic<T> x**
  _ **T** cannot be arbitrary type, used for integral and pointer types
  _ Can be created an instance trivially copy type
  _ Can be implemented with hardware lock-free atomic opâs or:
  _ implemented using mutexes

#### Atomic Objects {#atomic-objects}

- **Atomic assignment**
  - T operator=(T)
  - void store(T, memory_order = std::memory_order_seq_cst)
- **Atomic read**
  - operator T() const
  - T load(memory_order = std::memory_order_seq_cst) const
- **Atomic Swap**
  - T exchange(T, memory_order = std::memory_order_seq_cst)
- **Compare-and-swap**
  - bool compare_exchange_weak (T& expected, T desired, ...)
  - bool compare_exchange_strong(T& expected, T desired, ...)
    - (the...stands for memory order parameters)
- **Atomic bit manipulation and arithmetic for those T that make sense**
  - fetch_and,fetch_or,fetch_xor,fetch_add,fetch_sub

#### Compare and Swap {#compare-and-swap}

```cpp
bool atomic<T>::compare_exchange_weak(T& expected, T desired);
```

- Use in a loop for as long as the value is expected

#### Task-Based Parallelism {#task-based-paralellelism}

- Abstracts over OS thread
  - Because OS threads are more expensive
  - Decomposed into independent **tasks**
- Tasks are determined from **dependency graphs**
  - **Future/Promised** and [**async**](#async) creates these graphs
  - **Promise and Future** are basic building blocks
  - A packaged task wraps any function object with a promise-future channel
  - A **Future object** is attached to the wrapped function object
  - Calling the object resolves the promise with **set_value**
  - Exception sets with **set_exception** \* **async** abstracts over a packaged task
- **Implementation ideas:**
  - **Thread pools**
  - **Work stealing**
  - Idle PSâs steal tasks from another PSâs queue
  - Tasks should be freely migrated between threads

### Futures {#futures}

- Delayed value that promises that eventually a value will exist

    ```cpp
    future<int> f = async([]{ return hailstone(9780657631) });
    ```

- A future can be queried when a value is required \* Could be blocking until value is not available yet

    ```cpp
     if (f.get() == 1) { ... }
     ```

- A placeholder for a result of a computation
  - **Three States**
    - Pending: Future has no value yet
    - Fulfilled: The future value has been achieved
    - Rejected: The future never got it's expected value

#### Future Class {#future-class}

- **template<class T> class future;**
  - Tis the type of the result (can be void)
  - T must beMoveConstructible
  - future<T>cannot be copied, only moved
- **void wait() const;**
  - blocks until futureâs result available
  - also wait_for() and wait_until()
- **T get();**
  - blocks until result available, then returns it
  - get can only be called once
- **bool valid() const;**
  - has the value not been queried? (with get or share)
  - does the future have a shared state
- **std::shared_future<T> share();** \
  - gets the value and moves the futureâs value to a shared future

#### shared_future<T> {#shared-future}

- Same as **future<T>** but can be copied
  - Many threads can wait
- Construct shared_future object for each shared state
- Example:

```cpp
void detect(int x, shared_future<int> y) {
 static std::mutex iom;
 if (x == y.get()) {
  unique_lock l(iom);
   cout << "Found " << x << endl;
   } else {
   unique_lock l(iom);
    cout << "Expecting " << x << endl;
    }
 }

int main() {
 promise<int> p;
 shared_future<int> f = p.get_future().share();
 for (int j=0; j<10; ++j)
  thread(detect, j, f).detach();
  pause_thread_s(1);
  p.set_value(7);
  pause_thread_s(1);
 }
```

#### Future Combinators {#future-combinators}

- **when_any**
  - Wait until at least one of a set of futures is ready:

   ```cpp
   auto f_or_g = when_any(async(f), async(g)); f_or_g.then([](future<int> f) { ... });
   ```

- **when_all**
  - Wait until all futures of a set is ready:

  ```cpp
  future<tuple<future<int>, future<int>>> f_and_g = when_all(async(f), async(g));
  future<int> futf, futg; tie(futf, futg) = f_and_g.get(); // blocks
  cout << futf.get() + futg.get();// does not block
  ```

#### future::then {#future-then}

- Used instead of blocking with **get** until a future is ready \* Does not block
- Example:

```cpp
#include <future>
using namespace std;
 future<int> f1 = async([]{ return hailstone(12342342); });
 future<string> f2 = f1.then(
 [](int i) { return to_string(i); }
 };

 cout << f2.get();
}

```

### Promises {#promises}

- Object
- Promise -> Future is a one-off communication channel
  - Together has a shared state
  - Ready flag
  - Eventual result or exception when ready
  - Only one future per promise
  - **get_future** can be called once
  - or [shared_future](#shared-future)
  - **set_value, set exception**
  - set ready flag and value/exception
  - unblock threads waiting for promise
  - Destruction a promise
  - Gives up shared state
  - Deletes if no future waiting
    - Else throws **broken_promise**
- Synchronized with **set_value** and **set_exception**
  - e.g futures **get** and **wait**

### Async {#async}

Two **Overloads:**

```cpp
// 1
template<class Function, class... Args>
std::future<typename std::result_of<Function(Args...)>::type>
async(Function&& f, Args&&... args);

// 2
template< class Function, class... Args >
std::future<typename std::result_of<Function(Args...)>::type>
async(std::launch policy, Function&& f, Args&&... args);

```

- Launch policy:
  - **launch::async** executes a new thread with thread locals initialized
  - **launch::deferred** executes in the same thread at a **get()** call

### Task System Implementations {#task-system-implementations}

- Determine the benefits of multithreading
  - **Amdahlâs Law:**
  - $ S(n) = \frac{1}{1-p + \frac{p}{n}} $
  - S is theoretical speedup
  - n is the factor of increase in resources(number of cores)
    - p is the portion benefitting from the resources(unit is time)

- Returning out results is a way for tasks to communicate
  - **async** schedules a packaged task and returns a future
  - future becomes **ready** when task completes

- All following examples assumes these are included:

```cpp
#include <thread>
#include <mutex>
#include <deque>
#include <vector>
#include <unordered_map>
#include <functional>
#include <algorithm>
#include <string>
#include <future>
#include <type_traits>
using std::forward;
using std::move;
using std::function;
using std::thread;
using std::string;
using std::future;
using lock_t = std::unique_lock<std::mutex>;
```

### Number of threads {#number of threads}

- **thread::hardware_concurrency()**
  - May provide the number of cores currently in our system
- Number of threads allocated for the task affects speedup

```cpp
unsigned int number_of_threads() {
 return std::min(
 32u,
 std::max(1u, thread::hardware_concurrency()));
 }
```

### Compute Primes {#compute-primes}

```cpp
#include "task-system-utilities.hpp"

class notification_queue {
 std::deque<function<void()>> _q;
 std::mutex                   _mutex;
 std::condition_variable      _ready;
 bool                         _done = false;
  public:
   void done() {
    {
  lock_t lock(_mutex); _done = true;
     }
  _ready.notify_all();
   }

   bool pop(function<void()>& f) {
    lock_t lock(_mutex);
    while (_q.empty() && !_done) _ready.wait(lock);
    if (_q.empty()) return false;
    f = move(_q.front());
    _q.pop_front();return true;
   }
   template <typename F> void push(F&& f) {
    {
      lock_t lock(_mutex);
      _q.emplace_back(forward<F>(f));
      }
     _ready.notify_one();
   }
  };

class task_system {
 const unsigned int  _nthreads;
 std::vector<thread> _threads;
 notification_queue  _q;
 void run() {
  while (true) {
   function<void()> f;
   if (!_q.pop(f)) break; // !
   f();
   }
  }
 public:
  task_system(int nthreads = 0)
  : _nthreads(nthreads > 0 ? nthreads : number_of_threads())
  {
  for (unsigned int n = 0; n < _nthreads; ++n) {
  _threads.emplace_back([&]{ run(); });
  }
 }
 ~task_system() { _q.done(); for (thread& t: _threads) t.join(); }
 template <typename F>
 void async(F&& f) { _q.push(forward<F>(f)); }
};

bool is_prime(long num) {
 long limit = sqrt(num);
 if (num < 2) return false;
 for (long i=2; i<=limit ; i++) {
 if (num % i == 0) return false;
 } return true;
}

std::atomic<int> found = 0;
int count_primes(long n) {
 int count = 0; while (n-- > 1) { if (is_prime(n)) ++count; }
 return count;
}

const int ntasks = 4096;
void test(int nthreads) {
 double time;
  timer tmr;
  {
   task_system ts(nthreads);
   for (int i=0; i<ntasks; ++i)
    ts.async([&]{ found += count_primes(1000);  });
    }
  time = tmr.elapsed();
  logl("time ", time, " using ", nthreads, " threads");
 }

int main() {
 for (int n = 1; n <= 2048; n *= 2)
 test(n);
 test(thread::hardware_concurrency());
}
```

- **lock_t** is defined as **[std::unique_lock<std::mutex>](#unique-lock)**

- **front** accesses the first element, **pop_front** discards it
- Functions are moved, not copied

## Software Transactional Memory {#stm}

- Declare blocks of code that should execute atomically
- No locks
- Threads write without regard for other threads
- Keeps log of memory read/write
  - Logs are read after execution and compared to the memory
  - If execution has changed, the transaction is rolled back
  - Otherwise commited
- Good for programmer because
  - No need to keep track of locks(unless implemented)
  - No deadlock

- **Pros**
  - [Fine-Grained](#fine-grained-atomicity)
  - Good performance in dist. inviroments
- **Cons**
  - Performance could be a lot worse than locking

### Rollback

- **Occurs**
  - On Read
    - if variable is locked
    - Version greated than rv
- On commit
  - If any log variable can not be loacked
  - If any log variable locked or version higher than rv

## Message Passing Concurrency

- **Distributed Memory Architectures**
  - Processors has private memory
  - Connects with other PS's with **interconnect** network
  - Processes communicate by sending messages and recieving messages through **shared channels**
    - Via **RPC** og **rendez-vous**
    - Big Picture:

    ```cpp

                                        (implicit mutual exclusion)
                                     --> [Monitors]        -->
    [Busy Waiting] --> [Semaphores]                             [RPC/Rendez-vous]
                                     --> [Message Passing] -->
                                        (each semaphore carries data)

    ```

### Channel

- Communication path between processes
- chan c(type1, id1,....,typen,idn)

- ```cpp
    chan c1(int acc-id, int ctr, int amount)
    ```

- **Primitives**
  - Send
    - c(e1,e2,....,en)
    - Channel has c Space
    - Blocks if channel is full
  - recieve
    - c(var1,var2,...,varn)
    - Removes the message if C has atleast one
    - Blocks if empty
  - empty(c)

- **Channel abstraction**
  - One way
  - FIFO Queue
  - Atomic access to queue
  - Error-free
  - Typed

- **Filters**
  - One-way interaction pattern
  - A PS who recieves message from input channel
  - Sends to output(function of input and initial state) channels

### Client-Server with Message Passing

```cpp
    chan request(int clientID, typesofinpit);
    chan reply[n] (typesofresults)
    Process Server{
        int clientID;
        // initializstion, permanent variables
        while(true){
            recieve request(clientID, input values);
            // body
            send reply[clientID, result values]
        }
    }
    process client[i=0 to n-1]{
        send request(i,args);
        recieve reply[i] (res_args)
    }
    monitor Server{
        permanenet variables;
        initialization code;
        procesdure op(input_args){/* body; */ }
    }
```

### Synchronouse Message Passing

- **Sync_Send**
  - c(e1,e2,....,en)
  - Blocks until message is recieved
  - Sender and reciever synchroniza on sending and recieving a message
- **Perks**
  - Fixed channel size(no memory for message data)
    - At most one pending recieves message
    - At most one undelievered message
- **Draws**
  - Reduced parallelism
  - Higher [deadlock](#deadlock) risk
    - Deadlock example:

    ```cpp
    chan in1(int),in2(int);
    process P1{
        int v1,v2 = 1;
        sync_send
    }
    process P2 {
        int v1,v2 = 2;
        sync_send in1 (v2);
        recieve in2(v1):
    }


    ```

## Coroutine {#coroutine}

- Control abstraction for co-operative, or non-preemptive multitasking
- Generalization of [subroutines](#subroutine)
  - Suspending the execution
  - Resuming a suspended execution
- Coroutines are in progress simultaneously, but not executed at the same time

- Five transfer of control events:
  - Call
    - Activation frame/record pushed on to the stack
  - Return
    - Activation frame/record is popped from the stack
  - Suspend
    - Suspends execution, saves the frame/record, remembers the current point and transfer execution back to caller
  - Resume
    - Restores saved frame/record
  - Destroy
    - Deallocates saved frame/record

- Corollary: activation frame lifetime are not nested
  - Heap allocation

- Can run asynchronously with caller
- Caller can wait for suspension/return

```javascript
function* primes() {
    let primes = [];
    let c = 2;
    while (true) {
        let composite = false;
        for (let p of primes) {
            if (c % p == 0) {
                 composite = true;
                  break;
                   }
                  }
                  if (!composite) {
                      primes.push(c);
                       yield c;
                    }
                    ++c;
            }
    }
let p = primes();
while (true) {
    let r = p.next();
    if (r.value > 20) break;
    console.log(r.value);
    }

```

### Subroutine {#subroutine}

- Has a call and return

- Call
  - Pushes a new frame to stack
  - Suspends caller
  - jumps to the beginning of the function
- Return
  - passes return value to caller
  - Pops the frame
  - Resumes callerâs execution

- Has register for top of stack and allocates/deallocates(modify) the top of the stack

### **Symmetric**

- Singe control transfer operator that specifies target

### **Asymmetric**

- Similar to subroutines, transferred back to caller
- Symmetric/Asymmetric equally expensive, so can emulate each other

### First-class coroutines

- âBehaves like any value
- Can be store in variable
- Passed as parameter
- Returned from function
- Be yielded

- **Stackfull**
  - coroutines can suspend in nested functions
- **Stackless** coroutines can only suspend at top level
  - Must create new coroutine layer

### Generators-Iterators-Coroutines {#iterators}

- Is iterator if it implements next() with:
  - no arguments
  - returns object p such that
    - p.done : boolean
  - if p.done == false, then p.value is returned by the iterator

- An object is iterable if it has the computed property [Symbol.iterator], which is a nullary function returning an iterator

### Coroutine Frame

- Located in the iterator object
- Local variables are iterator objectsâs member variables

### Closing coroutines

- Breaking out of the iterator loop, closes the iterator
- Generators are close able iterators
- Resources can be cleansed at close
- Generators/Iterators are iterables and iterators

### Suspending coroutine

- yield communicates data from a coroutine to its caller when the coroutine is suspended
- yield e also receives data when coroutine resumed

### Resuming coroutine

- yield e is an expression, its value is the value sent to coroutine when it is resumed
- yield e can resume with an exception sent from its caller(ASYNC/AWAIT)

- Functions defined as async can contain await statements
- await e evaluates e to a promise, and waits until the promise is resolved
- The resolved promiseâs value is the value of the expression await e
- A rejected promise turns into an exception

## Coding {#coding}

### **C++ Coding {cpp-coding}**

### Ticket Algorithm {c++-ticket}

- [Explanation of the algorithm](#ticket-algorithm)

```cpp
#include "alang.hpp"
#include <vector>
using namespace std;

const int n = 4;
const int nCustomers = 4; // this many customers
const int nRounds = 5;    // each use service this many times
A<int> current_number = 0, next_served = 0;

int take_ticket_and_wait(int i)
{
    // take a ticket, print the received ticket number, and block until it is your turn
    // return the recived ticket number
    int myturn;
    ATO myturn = current_number;
    current_number = current_number + 1;MIC;
    alang::log("\nProcess ", i, " got turn: ", myturn);
    ATO AWAIT(myturn == next_served);MIC;
    return myturn;
}

void release_ticket()
{
    // let the next process proceed
    ATO next_served = next_served + 1; MIC;
}

int main()
{
    {
        processes ps;

        for (int i : range(0, nCustomers))
        {
            ps += [&, i] {
                for (int j : range(0, nRounds))
                {
                    int turn = take_ticket_and_wait(i);
                    // Perform task
                    alang::logl("\nProcess ", i, " runs on turn ", turn);
                    release_ticket();
                }
            };
        }
    }
}
```

**Output:**
<br>Process 1 got turn 0
<br>Process 0 got turn 1
<br>Process 2 got turn 2
<br>Process 3 got turn 3
<br>Process 1 runs on turn 0
<br>Process 1 got turn 4
<br>Process 0 runs on turn 1
<br>Process 0 got turn 5
<br>Process 2 runs on turn 2
<br>Process 2 got turn 6
<br>Process 3 runs on turn 3
<br>Process 3 got turn 7
<br>Process 1 runs on turn 4
<br>Process 1 got turn 8
<br>Process 0 runs on turn 5
<br>Process 0 got turn 9
<br>Process 2 runs on turn 6
<br>Process 2 got turn 10
<br>Process 3 runs on turn 7
<br>Process 3 got turn 11
<br>Process 1 runs on turn 8
<br>Process 1 got turn 12
<br>Process 0 runs on turn 9
<br>Process 0 got turn 13
<br>Process 2 runs on turn 10
<br>Process 2 got turn 14
<br>Process 3 runs on turn 11
<br>Process 3 got turn 15
<br>Process 1 runs on turn 12
<br>Process 1 got turn 16
<br>Process 0 runs on turn 13
<br>Process 0 got turn 17
<br>Process 2 runs on turn 14
<br>Process 2 got turn 18
<br>Process 3 runs on turn 15
<br>Process 3 got turn 19
<br>Process 1 runs on turn 16
<br>Process 0 runs on turn 17
<br>Process 2 runs on turn 18
<br>Process 3 runs on turn 19

### Semaphores {#cpp-semaphores}

- See [semaphores](semaphores)

### Semaphores implementation {#cpp-semaphores-implementation}

```cpp
#include "alang.hpp"

class barrier
{
    alang::semaphore arrive, depart;
    int ctr, n;

public:
    barrier(int n) : arrive(1), depart(0), ctr(0), n(n) {}

    void set(){
        arrive.P();
        if(ctr > n){
            arrive.V();
        } else {
            depart.V();
        }
        depart.P();
        if(ctr > 0){depart.V();}
             else{
                 arrive.V();
             }
        }
};

void launch_processes(processes &ps, barrier &b, int stages, int n){
    for (int i = 0; i < n; ++i)
    {
        ps += [&, i, stages] {
            for (int s = 0; s < stages; ++s)
            {
                logl("Stage ", s, ", process ", i);
                b.set();
            }
        };
    }
}
int main(){
    {
        barrier b(4);
        processes ps;
        launch_processes(ps, b, 3, 4);
    }
}

```

**Output:**
Stage 0, process 0
Stage 1, process 0
Stage 2, process 0
Stage 0, process 1
Stage 1, process 1
Stage 2, process 1
Stage 0, process 3
Stage 1, process 3
Stage 2, process 3
Stage 0, process 2
Stage 1, process 2
Stage 2, process 2

### Semaphores Banking Problem {#cpp-banking-problem}

- Multiple threads trying to deposit and withdraw from bank accounts

```cpp

#include "alang.hpp"

class bank_account
{
    alang::semaphore sem;
    int balance;
    int number;

public:
    bank_account(int n) :sem(1), balance(0), number(n) {}

    int get_number() { return number; }
    int get_balance() { return balance; }

    void deposit(int sum){
        sem.P();
        balance = balance + sum;
        sem.V();
    }

    void withdraw(int sum){
        sem.P();
        balance = balance - sum;
        sem.V();
    }

    void transfer_to(bank_account &b, int sum){
        if(this -> number < b.number){
        sem.P();
        b.sem.P();
        balance = balance - sum;
        b.balance = b.balance + sum;
        b.sem.V();
        sem.V();
        }else{
            sem.P();
            b.sem.P();
            balance = balance - sum;
            b.balance = b.balance + sum;
            sem.V();
            b.sem.V();
        }
    }
};
int main(){
    std::vector<bank_account *> vec;
    for (int i = 0; i < 10; ++i)
    {
        vec.push_back(new bank_account(i));
    }
    {
        processes ps;
        for (int i = 0; i < 100; ++i)
        {
            ps += [i, &vec] {
                for (int j = 0; j < 10; ++j)
                {
                    for (int k = 0; k < 10; ++k)
                    {
                        vec[j]->deposit(100);
                        vec[k]->withdraw(100);
                        vec[j]->withdraw(100);
                        vec[k]->deposit(100);
                        if (j != k)
                            vec[j]->transfer_to(*(vec[k]), 10);
                    }
                }
            };
        }
    }
    for (int i = 0; i < 10; ++i){
        alang::logl("Account ", i, " has balance ", vec[i]->get_balance());
    }
}

```

**Output**
<br>Account 0 has balance -70
<br>Account 1 has balance -240
<br>Account 2 has balance 0
<br>Account 3 has balance -210
<br>Account 4 has balance 30
<br>Account 5 has balance 110
<br>Account 6 has balance 90
<br>Account 7 has balance 90
<br>Account 8 has balance -300
<br>Account 9 has balance 240

### Monitor {#cpp-monitor}

#### Bridge Crossing Problem {#cpp-bridge}

- Cars has to drive over a bridge
- Only cars allowed in the same direction is allowed to drive at once
- Cars can drive past each other
- Cars coming from the opposite direction has to wait until the cars on the bridge have passed

```cpp
#include "alang.hpp"
#include <array>

using alang::logl;
using alang::prandom;
using alang::sleep_ms;
using std::array;
using std::string;

// "?" is a conditional statment in c++. If north is true, north is return, otherwise south
enum direction{ north = 0, south = 1};
direction opposite(direction dir){return (dir == north ? south : north);}

class bridge :  monitor{
    private:
        array<int, 2> ncars = { 0,0 }; // creates an array to see how many cars going in each direction
        // invariant ncars[north] == 0 ||Â ncars[south] == 0
        cond empty_bridge;
    public:
        bridge() {}
            array<int, 2> bridge_status(){
                SYNC;
                return ncars;
            }

            void car_arrive(direction dir){
                SYNC;
                while(ncars[opposite(dir)] != 0){
                    wait(empty_bridge);
                }
                ++(ncars[dir]);
            }

            void car_leave(direction dir){
            {
                SYNC;
                --(ncars[dir]);
            }
            if(ncars[dir]==0)
                signal_all(empty_bridge);
            }
};

auto car(bridge &b,
         int max_crossings,     // cross at most this many times
         int min_crossing_time, // crossing takes at least this long
         int max_crossing_time, // crossing takes at most this long
         int min_idle_time,     // wait at least this long before trying to cross again
         int max_idle_time){ // wait at most this long before trying to cross again

    return [=, &b] {
        direction dir = static_cast<direction>(prandom(0, 1)); // Casts a random direction
        int n = prandom(max_crossings);

        while(n-- > 0)
        {
            sleep_ms(prandom(min_idle_time, max_idle_time)); // Random idle time
            b.car_arrive(dir); // car arrives on bridge
            array<int, 2> counts = b.bridge_status(); // car on bridge checks car distrubution(invariant)
            assert(counts[north] == 0 || counts[south] == 0); // checks if it is empty

            if(counts[north] > 0)
                logl(string(counts[north], 'N'));
            else
                 logl(string(counts[south], 'S'));

            alang::sleep_ms(alang::prandom(min_crossing_time, max_crossing_time)); //random crossing time for car
            b.car_leave(dir); // bye bye car

            counts = b.bridge_status(); // checks bridge status againg
            assert(counts[north] == 0 || counts[south] == 0);

            dir = opposite(dir); // car turns back
        }
    };
}

int main(){
    bridge b;{
        processes ps;
        for (int i = 0; i < 10; i++){
            ps += car(b, 8, 1, 10, 2, 20);
             // 10 cars, 8 crossings each, each crossing takes 1-10ms, each car waits 2-20 ms
        }
    }
}

```

**Output:**
<br>N
<br>NN
<br>S
<br>SS
<br>SSS
<br>SSS
<br>N
<br>NN
<br>NNN
<br>S
<br>...

### Message Passing and Channels {#message-passing-channels}

- P1 sends random numbers to P2
- When P1 generates -1, P2 sends back the sum of the numbers sent by P1

```cpp
#include "alang.hpp"

alang::channel<int> c1, c2;

int main(){
    processes ps;
    ps += [] {
        int sum, m;
        while(m != -1){
			m = alang::prandom(-1, 10);
            c1.send(m);
            alang::logl("Sent ", m);
    	}
		c2.receive(sum);
		alang::logl("Recieved sum ", sum);
	};

    ps += [] {
        int sum, m = 0;
		while(true){
			c1.receive(m);
			alang::logl("Recieved ", m);
			if(m == -1)	break;
			sum += m;
			}
		alang::logl("Sending sum ", sum);
		c2.send(sum);
    };
}

```

### Filters With Quicksort {#filters-with-quicksort}

```cpp
#include "alang.hpp"

using d_channel = alang::channel<int>;
using alang::channel;
using alang::prandom;
using std::vector;

const int EOS = -1;

void partition_filter(int pivot, d_channel in1, d_channel out1, d_channel out2){
    int r;
    in1.receive(r);
    while(r != EOS){
        if(r <= pivot)
            out1.send(r);
        else
            out2.send(r);
        in1.receive(r);
    }
    out1.send(EOS);
    out2.send(EOS);
}

void merge_filter(d_channel in1, d_channel in2, d_channel out){
    int v1, v2;
    in1.receive(v1);
    in2.receive(v2);
    while (v1 != EOS && v2 != EOS){
        if (v1 <= v2){
            out.send(v1);
            in1.receive(v1);
        } else{
            out.send(v2);
            in2.receive(v2);
        }
    }while (v1 != EOS)  {
        out.send(v1);
        in1.receive(v1);
    }   while (v2 != EOS)  {
        out.send(v2);
        in2.receive(v2);
    }
    out.send(EOS);
}

void quick_sort(d_channel in, d_channel out){
    int pivot;
    in.receive(pivot);
    if(pivot == EOS){
        out.send(EOS);
        return;
    }
    d_channel sort1, sort2, o1, o2;

    processes ps;
    ps += [&]() { partition_filter(pivot, in, o1, o2); };
    ps += [&]() { quick_sort(o1, sort1); };
    ps += [&]() { sort2.send(pivot); quick_sort(o2,sort2); };
    ps += [&]() { merge_filter(sort1, sort2, out); };
}


int main(){
    const int EOS = -1;
    vector<int> vin, vout;{
        d_channel in, out; // note: channels are defined before ps, so that they are destructed after ps
        processes ps;

        ps += [&] { quick_sort(in, out); };

        ps += [&] {
            int p;
            do{
                p = prandom(-1, 10);
                vin.push_back(p);
                in.send(p);
            } while (p != EOS);
        };
        ps += [&] {
            while (true){
                int p;
                out.receive(p);
                vout.push_back(p);
                if (p == EOS)break;
            }
        };
    }
    for (auto i : vin)
        log(i, " ");
    logl();
    for (auto i : vout)
        log(i, " ");
    logl();
}

```

### Saving Account {#savings-account}

```cpp
#include "alang.hpp"

using alang::channel;
using std::to_string;
using std::vector;

using money = int;
using option = int;
using reply = money;

channel <channel<reply> , option, money> request;

const int DEPOSIT = 0, WITHDRAW = 1, KILL = 2;

auto bankServer = [] {
    std::deque<std::pair<channel<reply>, money>> queue;
    int balance = 0;
    while(true)
    {
        channel<reply> reply_channel;

        option op;
        money amount;

        request.receive(reply_channel, op, amount);
        switch (op)
        {

        case DEPOSIT:
            balance += amount;
            reply_channel.send(balance);

            while(!queue.empty())
            {
                auto p = queue.front();
                if(p.second < balance)
                {
                    balance -= p.second;
                    p.first.send(balance);
                    queue.pop_front();
                }else{
                    break;
                }
            }
            break;

        case WITHDRAW:
            if(amount > balance)
            {
                queue.push_back(std::make_pair(reply_channel, amount));

            }
            else{
                balance -= amount;
                reply_channel.send(amount);
            }
            break;

        case KILL: return;
        }
    }
};

int main(){
    processes ps;
    ps += [] {
        reply r;
        channel<reply> ch;
        for (int i = 0; i < 10; ++i)
        {
            request.send(ch, DEPOSIT, 100);
            ch.receive(r);
            logl(r);
        }
    };
    ps += [] {
        reply r;
        channel<reply> ch;
        for (int i = 0; i < 10; ++i)
        {
            request.send(ch, WITHDRAW, 100);
            ch.receive(r);
            logl(r);
        }
    };
    ps += bankServer;
    sleep(100ms);
    request.send(channel<reply>(), KILL, 0);

}


```



```
# **INF214 Cheat Sheet**

- [**INF214 Cheat Sheet**](#inf214-cheat-sheet)
  - [Processes and Synchronization](#processes-and-synchronization)
    - [Terms](#terms)
      - [State](#state)
      - [Atomic Action {#atomic-action}](#atomic-action-atomic-action)
      - [Interference {#interference}](#interference-interference)
      - [Noninterference {#noninterference}](#noninterference-noninterference)
      - [Race Condition {#race-condition}](#race-condition-race-condition)
      - [Unnecessary delay {#unnecessary-delay}](#unnecessary-delay-unnecessary-delay)
      - [Eventual Entry {#eventual-entry}](#eventual-entry-eventual-entry)
      - [Properties {#properties}](#properties-properties)
      - [Assertions {#assertions}](#assertions-assertions)
      - [Pre Condition {#precondition}](#pre-condition-precondition)
      - [Post Condition {#postcondition}](#post-condition-postcondition)
      - [Fine-Grained Atomicity {#fine-grained-atomicity}](#fine-grained-atomicity-fine-grained-atomicity)
      - [Coarse-Grained Atomicity {#coarse-grained-atomicity}](#coarse-grained-atomicity-coarse-grained-atomicity)
      - [At-Most-Once Property {#at-most-once-property}](#at-most-once-property-at-most-once-property)
      - [Partial Correctness {#partial-correctness}](#partial-correctness-partial-correctness)
      - [Total Correctness {#total-correctness}](#total-correctness-total-correctness)
      - [Mutual exclusion {#mutual-exclusion}](#mutual-exclusion-mutual-exclusion)
      - [Critical Reference {#critical-reference}](#critical-reference-critical-reference)
      - [Critical Section {#critical-section}](#critical-section-critical-section)
    - [Logic](#logic)
    - [Fairness {#fairness}](#fairness-fairness)
      - [Unconditional fairness {#unconditional-fairness}](#unconditional-fairness-unconditional-fairness)
      - [Weak fairness {#weak-fairness}](#weak-fairness-weak-fairness)
      - [Strong fairness {#strong-fairness}](#strong-fairness-strong-fairness)
  - [Locks and Barriers {#locks-barriers}](#locks-and-barriers-locks-barriers)
    - [Locks {#locks}](#locks-locks)
      - [Deadlock {#deadlock}](#deadlock-deadlock)
      - [Livelock {livelock}](#livelock-livelock)
      - [Spinlock {#spinlock}](#spinlock-spinlock)
    - [Fair Solutions Algorithms {#fair-solutions-algorithms}](#fair-solutions-algorithms-fair-solutions-algorithms)
      - [The Ticket Algorithm {#ticket-algorithm}](#the-ticket-algorithm-ticket-algorithm)
  - [Barriers {#barriers}](#barriers-barriers)
    - [Barrier Implementation {#barrier-implementation}](#barrier-implementation-barrier-implementation)
      - [(BAD) Shared counter {#shared-counter}](#bad-shared-counter-shared-counter)
    - [Flags and Coordinator {#flags-and-coordinators}](#flags-and-coordinator-flags-and-coordinators)
    - [Symmetric Barriers {#symmetric-barriers}](#symmetric-barriers-symmetric-barriers)
  - [Semaphores {#semaphores}](#semaphores-semaphores)
    - [Semaphore Definition {#semaphore-definition}](#semaphore-definition-semaphore-definition)
    - [Syntax](#syntax)
    - [Mutual Exclusion With Semaphores {#mutex-semaphores}](#mutual-exclusion-with-semaphores-mutex-semaphores)
    - [Barrier With Semaphores {#barrier-semaphores}](#barrier-with-semaphores-barrier-semaphores)
    - [Split Binary Semaphores {#split-binary-semaphores}](#split-binary-semaphores-split-binary-semaphores)
  - [Monitors {#monitors}](#monitors-monitors)
    - [Monitor Properties {#monitor-properties}](#monitor-properties-monitor-properties)
  - [Monitor-Implementation {#monitor-implementation}](#monitor-implementation-monitor-implementation)
  - [Signalling {#monitor-signalling}](#signalling-monitor-signalling)
    - [C++ Monitor API {#cpp-monitor-api}](#c-monitor-api-cpp-monitor-api)
  - [Alang {#alang}](#alang-alang)
    - [Basics {#alang-basics}](#basics-alang-basics)
      - [Lambda Funcions{#lambda}](#lambda-funcionslambda)
      - [Processes in alang {#ps-alang}](#processes-in-alang-ps-alang)
      - [Indexes Processes {#indexed-processes}](#indexes-processes-indexed-processes)
      - [CO Function {#co-function}](#co-function-co-function)
    - [Atomic Execution {#alang-atomic-execution}](#atomic-execution-alang-atomic-execution)
      - [Critical Sections {#alang-critical-section}](#critical-sections-alang-critical-section)
      - [Atomic Variables {#alang-atomic}](#atomic-variables-alang-atomic)
      - [AWAIT Statement {#alang-await}](#await-statement-alang-await)
    - [SemaphoresÂ {#alang-semaphores}](#semaphores-alang-semaphores)
    - [Monitors {#alang-monitors}](#monitors-alang-monitors)
    - [Channels {#alang-channels}](#channels-alang-channels)
    - [Pointes {#pointers}](#pointes-pointers)
  - [C++ Concurrency {#cpp-concurrency}](#c-concurrency-cpp-concurrency)
    - [Sequential Consistency {#sequential-consistency}](#sequential-consistency-sequential-consistency)
    - [C++ Threads {#cpp-threads}](#c-threads-cpp-threads)
    - [Mutex {#cpp-mutex}](#mutex-cpp-mutex)
    - [Types of mutexes {#cpp-mutex-types}](#types-of-mutexes-cpp-mutex-types)
    - [Examples {#cpp-mutex-examples}](#examples-cpp-mutex-examples)
      - [Try-Lock Recursive mutex example: {#tlrme}](#try-lock-recursive-mutex-example-tlrme)
      - [Timed Mutex Example: {#tme}](#timed-mutex-example-tme)
      - [Shared Mutex Example: {#sme}](#shared-mutex-example-sme)
    - [Mutex-Wrappers {#cpp-mutex-wrapper}](#mutex-wrappers-cpp-mutex-wrapper)
      - [RAII {#raii}](#raii-raii)
      - [lock and lock_guard: {#lock-lockguard}](#lock-and-lockguard-lock-lockguard)
      - [unique_lock {#unique-lock}](#uniquelock-unique-lock)
      - [scoped_lock wrapper {#scoped-lock-wrapper}](#scopedlock-wrapper-scoped-lock-wrapper)
    - [C++ Conditional Variables {#cpp-conditional-variables}](#c-conditional-variables-cpp-conditional-variables)
      - [Thread Local Variables {#thread-local-variables}](#thread-local-variables-thread-local-variables)
      - [Call once {#call-once}](#call-once-call-once)
      - [C++ Atomics {#cpp-atomics}](#c-atomics-cpp-atomics)
      - [Atomic Objects {#atomic-objects}](#atomic-objects-atomic-objects)
      - [Compare and Swap {#compare-and-swap}](#compare-and-swap-compare-and-swap)
      - [Task-Based Parallelism {#task-based-paralellelism}](#task-based-parallelism-task-based-paralellelism)
    - [Futures {#futures}](#futures-futures)
      - [Future Class {#future-class}](#future-class-future-class)
      - [shared_future<T> {#shared-future}](#sharedfuturet-shared-future)
      - [Future Combinators {#future-combinators}](#future-combinators-future-combinators)
      - [future::then {#future-then}](#futurethen-future-then)
    - [Promises {#promises}](#promises-promises)
    - [Async {#async}](#async-async)
    - [Task System Implementations {#task-system-implementations}](#task-system-implementations-task-system-implementations)
    - [Number of threads {#number of threads}](#number-of-threads-number-of-threads)
    - [Compute Primes {#compute-primes}](#compute-primes-compute-primes)
  - [Software Transactional Memory {#stm}](#software-transactional-memory-stm)
    - [Rollback](#rollback)
  - [Message Passing Concurrency](#message-passing-concurrency)
    - [Channel](#channel)
    - [Client-Server with Message Passing](#client-server-with-message-passing)
    - [Synchronouse Message Passing](#synchronouse-message-passing)
  - [Coroutine {#coroutine}](#coroutine-coroutine)
    - [Subroutine {#subroutine}](#subroutine-subroutine)
    - [**Symmetric**](#symmetric)
    - [**Asymmetric**](#asymmetric)
    - [First-class coroutines](#first-class-coroutines)
    - [Generators-Iterators-Coroutines {#iterators}](#generators-iterators-coroutines-iterators)
    - [Coroutine Frame](#coroutine-frame)
    - [Closing coroutines](#closing-coroutines)
    - [Suspending coroutine](#suspending-coroutine)
    - [Resuming coroutine](#resuming-coroutine)
  - [Coding {#coding}](#coding-coding)
    - [**C++ Coding {cpp-coding}**](#c-coding-cpp-coding)
    - [Ticket Algorithm {c++-ticket}](#ticket-algorithm-c-ticket)
    - [Semaphores {#cpp-semaphores}](#semaphores-cpp-semaphores)
    - [Semaphores implementation {#cpp-semaphores-implementation}](#semaphores-implementation-cpp-semaphores-implementation)
    - [Semaphores Banking Problem {#cpp-banking-problem}](#semaphores-banking-problem-cpp-banking-problem)
    - [Monitor {#cpp-monitor}](#monitor-cpp-monitor)
      - [Bridge Crossing Problem {#cpp-bridge}](#bridge-crossing-problem-cpp-bridge)
    - [Message Passing and Channels {#message-passing-channels}](#message-passing-and-channels-message-passing-channels)
    - [Filters With Quicksort {#filters-with-quicksort}](#filters-with-quicksort-filters-with-quicksort)
    - [Saving Account {#savings-account}](#saving-account-savings-account)
## Processes and Synchronization

### Terms

#### State

- A value a variable has at a given time

#### Atomic Action {#atomic-action}

- A sequence of one or more statements that appears to execute as a single, indivisible action

#### Interference {#interference}

- The result of two processes reading and writing the same variable in an unpredictable order

#### Noninterference {#noninterference}

- A relation between an atomic action and a critical assertion C in another process. Executing a does not interfere with c if it leaves c true if c is already true

#### Race Condition {#race-condition}

- A scenario where to processes interacts with a shared variable, causing on process to write to the variable and continue executing. Thus racing ahead before the other process and changes the variable again before the other process sees the result of the first change

#### Unnecessary delay {#unnecessary-delay}

- If a process is trying to enter its critical section and the other processes are executing their noncritical sections or have terminated, the process is not prevented from entering its critical section

#### Eventual Entry {#eventual-entry}

- A process that is trying to enter its critical section, is eventually allowed to succeed

#### Properties {#properties}

- Attribute that is true for every possible history of the program
- **Safety Property**
  - A property where the program never enters a bad state, where the variables have undesired values
- **Liveness Property**
  - A property where the program eventually reaches a good state, variables have desired values

#### Assertions {#assertions}

- An assertion characterises an acceptable program state

#### Pre Condition {#precondition}

- An assertion that is true when statement **S** finishes

#### Post Condition {#postcondition}

- An assertion that is true when statement **Q** finished

#### Fine-Grained Atomicity {#fine-grained-atomicity}

- No intermediate state is visible to the program
- An assignment appears to be atomic since no state from a process is visible to another process

#### Coarse-Grained Atomicity {#coarse-grained-atomicity}

- Atomicity implemented using [critical section](#critical-section) protocols

#### At-Most-Once Property {#at-most-once-property}

- Attribute of an assignment **x = e** where x is not read by another process and e only contains at most one reference to a variable changed by another process, it does contains a [critical reference](#critical-reference), or
- x is not written by another process and e contains no references to a variable changed by another process
- There can be at most one shared variable that can at most be referenced once
- If the assignments meets AMO, it will appear [atomic](#atomic-action)

#### Partial Correctness {#partial-correctness}

- The program is correct if the final state is correct
- If the initial program state satisfies P, then the final state will satisfy Q assuming S terminates

#### Total Correctness {#total-correctness}

- Combines partial correction with termination. A program is totally correct if the program always terminates with the desired results

#### Mutual exclusion {#mutual-exclusion}

- A synchronization ensuring statements in different processes can not execute at the same time

#### Critical Reference {#critical-reference}

- Reference to a variable changed by another process

#### Critical Section {#critical-section}

- A sequence of statements where shared variables are read and written by multiple processes

### Logic

- Formal logic system that allows one to state and prove properties of programs (PL system)
- Formulas of PL are called triples{#triples}

  - Has the form **{P} S {Q}**
  - P and Q are [assertions](#assertions)
  - P is the [pre condition](#precondition) and Q the [post condition](#postcondition)
  - Is true if execution of S has begun in a state satisfying P resulting in Q when the program terminates
  - Executing **S** in state **{P}** == **{Q}**
  - Is [partial correctness](#partial-correctness)

- Hoare tripple
  - **{P} C {Q}**
  - P and Q are [assertions](#assertions)
  - C is the command
  - Provides logical axioms and interference rules causing the command to execute when the [pre condition](#precondition) is met, and establishes the [post condition](#postcondition)

### Fairness {#fairness}

- **An attribute of a program ensuring that every delayed process gets a chance to proceed**
- Concerned with guaranteeing that a process gets a chance to proceed regardless of the other processes
- A process is **eligible**{#eligible} if it is the next [atomic action](#atomic-action) in the process that could be executed
- A scheduling policy determines which process will be executed next

#### Unconditional fairness {#unconditional-fairness}

- A scheduling policy is unconditionally fair if every unconditionally atomic action is eligible for execution eventually

#### Weak fairness {#weak-fairness}

- Unconditionally fair
- Action is continuously enabled and will eventually be executed
- If p holds from a point and on, then q will also hold eventually
- Not sufficient for ensuring every eligible await statement is executed eventually because the condition might change from **true** to **false** while a process is delayed, for this, **strong fairness** is required

#### Strong fairness {#strong-fairness}

- Implies an action has to be continuously enabled infinitely often
- If p holds infinitely often, then eventually q will hold
- If an await statement is present in a program, even though the condition is false, the program will eventually terminate because the condition is infinitely often true

## Locks and Barriers {#locks-barriers}

- The **Goal** is to implement a system satisfying the following properties:
  - **[Mutual Exclusion](#mutual-exclusion)**
  - **[Absence of Deadlock](#deadlock)(Livelock)** ([safety property](#safety-property))
  - **[Absence of Unnecessary Delay](#unnecessary-delay)** ([safety property](#safety-property))
  - **[Eventual Entry](#eventual-entry)**
- The first three are [safety properties](#safety-property)
- The last is a [liveness property](#liveness-property)

### Locks {#locks}

#### Deadlock {#deadlock}

- A state where to processes wait for each other where none gets to execute

#### Livelock {livelock}

- A scenario where a process is waiting for a process to be **true**, that will never become true. Livelock is the busy-waiting analog of deadlock

#### Spinlock {#spinlock}

- A boolean variable used with a busy-waiting to protect a critical section. A process wanting to enter, spins until it is allowed to enter

### Fair Solutions Algorithms {#fair-solutions-algorithms}

#### The Ticket Algorithm {#ticket-algorithm}

- Name based on drawing tickets
- **Practical example:** - Imagine a bakery where customers are served based on their arrival - When a customer arrives, he draws a ticket one larger than the previous customer - The customer waits until all the previous customers are served until it is his turn - Implemented by a number dispenser and a display displaying which customers turn it is - see [C++ Ticket Algorithm](#c++-ticket)

## Barriers {#barriers}

- Two solution to parallel computation:
  - **BAD**: Using CO statements in the body of the iteration depending on the previous iteration and ignoring termination
    - Inefficient because it is costly to the memory to create and destroy processes than to implement process synchronization
  - **GOOD** : Create the processes once at the beginning of the computation, then have them synchronize at the end of each computation.
    - This is what **Barrier Synchronization** is
- Computes disjoints parts of the solution in parallel
- Iterations are dependent of the result of the previous iteration
- Has a delay point(barrier) at the end of each iteration every process has to reach before any is allowed to pass

### Barrier Implementation {#barrier-implementation}

#### (BAD) Shared counter {#shared-counter}

- A counter that is initially 0, and when it reaches the desired n, all processes may pass
  - **AWAIT**
  - **Not Efficient!** since counter has to reset each time all processes pass
  - Can be solved with two counters, but this adds complexity since a process might get delayed examining one of the counters
  - Should only be used if target machine has [atomic](#atomic-action) increment instructions

### Flags and Coordinator {#flags-and-coordinators}

- Solves the memory contention problem from shared counters by implementing count as a sum of n shared values
- Achieved by adding a creating a array of integers **Arrive** and a new set new set of shared variables called **coordinator**
- Instead of having each worker sum and test values, set **Arrive[i]** to 1, each **worker[i]** delays waiting for **continue[i]** to become 1, this only has to wait for a single value to become true
- By calling this single value **continue**(which is an array of integers initialized as 0), a **worker[i]** only has to wait for **continue[i]** to be 1
- The **coordinator** waits for all elements of **arrive** to become 1 before letting before setting all elements of **continue** to be 1
- **Arrive** and **Continue** are examples of **Flag Variables**{#flag-variables}
- A variable raised by one process to signal another that the synchronization is true -

- **Flag Synchronization**{#flag-synchronization}
  - A process that wait for synchronization flag to be set, is the one that should clear the flag
    - Ensures flag is not cleared before it has been seen to be set
  - A flag should not be set until it is known that it is clear
    - Ensures a process not setting the same flag again if it has already been set

### Symmetric Barriers {#symmetric-barriers}

- Each process has a flag it sets when itâs arriving at a barrier. It then waits for the other process to set its flag before clearing the other processes flag
- Communicating with a binary connection
- **Butterfly Barrier:** -
  - Each process communicates with another process at each stage
  - Processes are indirectly synchronized with each other

## Semaphores {#semaphores}

### Semaphore Definition {#semaphore-definition}

- A program variable - Whose value is an integer > 0
- Can **only** be updated
- Controlled by two operations:
  - **P** : Wait for signal -
    - Wait until value > 0, then decrease value by one
  - **V** : Signal an event
    - Increase value by one

### Syntax

```cpp
sem; // init to null
sem s=k; // init to k
sem s[n] = ([n]1); // array of semaphores
```

- By default a semaphore is initialized as 0, but it can be initialized as any non-negative integer
- A **Binary Semaphore** only takes in the values 0 and 1

### Mutual Exclusion With Semaphores {#mutex-semaphores}

```cpp
sem mutex = 1;
process P[i=1 to m]{
 while(true){
 P(mutex);
 CS(critical section)
 V(mutex);
 non-cs
 }
}
```

- Semaphore initially 1, so that one process can enter the [Critical Section](#critical-section)
- **Always** **P**before **V** so value stays <=1
- Use one semaphore for each [synchronization flag](#flag-synchronization)
  - A PS sets a flag by executing **V**
  - Then waits for a flag to be set, and clears it with **P**

### Barrier With Semaphores {#barrier-semaphores}

- Using to signaling semaphores
- Processes signal their arrival by executing a **V** operation on its own semaphore, then waiting for another process and executing a **P** operation on its semaphore
- Typical signaling pattern:

```cpp
sem arrive1 = 0, arrive2 =0;
process P1 {
 V(arrive1) // signal arrival
 P(arrive2) // wait for other process
}
process P2{
 V(arrive2) // signal arrival
 P(arrive1) // wait for other process
}
```

- semaphores initialized to Ã
  - signal event **V**
  - wait for event **P**

### Split Binary Semaphores {#split-binary-semaphores}

- A set of semaphores where the **sum** of values <= 1
- [Mutual Exclusion](#mutual-exclusion) of many PSâs, guiding which one can execute
  - Initialize one semaphore to 1, other to Ã
  - Ensure that on every execution **P(s1)** is followed by **V(s2)** for some of the semaphores s1, s2
  - All statements between **P(s1)** and **P(s2)** is executed in mutual exclusion
- Has a shared buffer
- **Empty** and **Full** are two semaphores indicating if the buffer is full or empty

```cpp
typeT buf; // buffer of some type T
sem empty = 1, full = 0;

process Producer[i = 1 to m] {
 while(true){
  â¦
  // produce some data and deposit it in the buffer
  P(empty);
  buf = data;
  V(full)
 }
}
process Consumer[i = 1 to m] {
 while(true){
  â¦
  // fetch result, then consume it
  P(full);
  result = buf;
  V(empty)
  }
 }


```

## Monitors {#monitors}

### Monitor Properties {#monitor-properties}

- Thread safe abstract data type with synchronization
- Encapsulates representation of an abstract object
- Allows implicit [mutual exclusion](#mutual-exclusion)(at most one process can execute a function at any given time) and wait condition
- Has a [mutex lock](#mutex-lock) and conditional variables
- Threads wait for certain conditions to be met
- Processes are active, while monitors are passive

- **Monitor invariant**
  - Predicate that is true when no procedure is running, describes the valid good states
    - When an object is in a valid state, the class invariant holds
    - Must hold after initialization, when procedure terminates and when wait suspends executing
    - Assumes to hold at the beginning of procedure and after wait

## Monitor-Implementation {#monitor-implementation}

monitor m {
<br> permanent variables // shared by all processes
<br> initialization
<br> procedures // public
<br>}

## Signalling {#monitor-signalling}

- if cvâs queue is empty, no effect
- wake up a ps
- when ps calls signal, it is inside a monitor, making it two active psâs: current and the one being awakened

- Two strategies for ps to not run simultaneously
  - Signal and continue (SC), signaller continues running
  - Signal and wait (SW), signalled starts executing

### C++ Monitor API {#cpp-monitor-api}

- cond cv; // declaration
- empty(cv); // check if empty queue
- wait(cv); // make ps wait in cvâs queue
- signal(cv); // wake up a ps in cvâs queue
- signal_all(cv); // wake up all ps in cvâs queue

## Alang {#alang}

### Basics {#alang-basics}

- **compile with :**
  - -std=c++2a

#### Lambda Funcions{#lambda}

```cpp
[&, i, j, k] { /* body that uses i, j, and k */ }

```

#### Processes in alang {#ps-alang}

```cpp
processes ps; // ps will hold all processes

  ps += [&] { // define a task and start executing it
    while (x == 0);
```

#### Indexes Processes {#indexed-processes}

```cpp
int sum = 0;
{   // note this extra scope
    processes ps;

    for (int i=0; i<10; ++i) ps += [&,i]{ sum = sum + i; };
  } // ps goes out of scope here. Execution waits until all processes finished

  cout << "Sum is = " << sum << endl;
```

#### CO Function {#co-function}

```cpp
int x = 0;

  for (int i : range(0, 1000000))
    CO([&]{ x = x + 1; }, [&]{ x = x + 1; });

  cout << x << endl;

```

### Atomic Execution {#alang-atomic-execution}

#### Critical Sections {#alang-critical-section}

- [Definition](#critical-section)

```cpp
processes ps;
  for (int i : range(0, 10)) ps += [&, i] {
    enter_critical;
    cout << i << "+" << i << "=" << i+i << endl;
    exit_critical;
  };
```

#### Atomic Variables {#alang-atomic}

- [Definition](#atomic-action)

```cpp
 A<int> x = 0; // must use A<int>; otherwise ATOMIC has no effect

  for (int i : range(0, 100000))
    CO([&]{ ATOMIC([&]{x = x + 1;}); },
       [&]{ ATOMIC([&]{x = x + 1;}); },
       [&]{ ATOMIC([&]{x = x + 1;}); },
       [&]{ ATOMIC([&]{x = x + 1;}); });

  cout << x << endl;
```

```cpp
 A<int> x;
  ATO
    x = 1;
    return;
    x = 2;
  MIC;
  cout << x << endl;
```

#### AWAIT Statement {#alang-await}

```cpp
A<int> x = 0;
  CO([&]{ ATO AWAIT (x == 100); x = -100; MIC; },
     [&]{ ATO while (x < 100) x = x + 1; MIC; });
  alang::logl(x);
```

### SemaphoresÂ {#alang-semaphores}

- [Definition](#semaphore-definition)

```cpp
semaphore sem1;     // declare a semaphore, initialize to 0
semaphore sem2 = 1; // declare a semaphore, initialize to 1

sem1.P(); // P operation
sem1.V(); // V operation
```

```cpp
semaphore sem;

  CO([&]{ cout << "Waiting... "; sem.P(); cout << "Got through." << endl; },
     [&]{ sleep(1s); cout << "Releasing... "; sem.V(); });
```

### Monitors {#alang-monitors}

- [Definition](#monitor)

```cpp
class semon : monitor {
  cond cv; // declare a condition variable in the monitor
  int s;   // semaphore's value
public:
  semon(int s=0) : s(s) { if (s<0) throw "bad semaphore"; }

  void P() {
    SYNC;
    while (s == 0) { wait(cv); }
    s = s - 1;
  }

  void V() {
    SYNC;
    s = s + 1;
    signal(cv);
  }

  int value() { SYNC; return s; } // not part of the semaphore API. Added so we can test.
};

int main() {
  semon s = 0;
  {
    processes ps;
    ps += [&s]{            for (int i=0; i<100; ++i) s.P(); };
    ps += [&s]{ sleep(1s); for (int i=0; i<200; ++i) s.V(); };
  }
  alang::logl(s.value());
}
```

```cpp
class m1 : monitor {
public:
  void f() { SYNC; }
  void g() { SYNC; f(); } // cannot call another procedure that is SYNCed
}

class m2 : monitor {
  helper() { /* do some work */ }
public:
  void f() { SYNC; helper(); } // ok
  void g() { SYNC; helper(); } // ok
}
```

### Channels {#alang-channels}

- [Definition](#channel)

```cpp
channel<int> c1;
channel<int, string> c2;
channel<vector<int>> c3;
channel<channel<int>*> c4;
```

```cpp


#include "alang.hpp"
using alang::channel;

int main() {
  channel<channel<int>, int> request;

  processes ps;

  // a server that doubles an integer
  ps += [&request]{
    channel<int> cr; // the channel for the response from the server
    int i;
    request.receive(cr, i);
    cr.send(2*i);
  };

  // a client process
  ps += [&request]{
    channel<int> c; int i;
    request.send(c, 1);
    c.receive(i);
    logl(i);
  };
}
```

### Pointes {#pointers}

```cpp
int x = 10;
int& y = x; // y refers to x, y and x are aliased
int z = y; // z = 10, z is not aliased with x or y
```

## C++ Concurrency {#cpp-concurrency}

- A memory model defines the semantics of shared variables
  - A set of guarantees about the order a program reads and writes are observed by a thread
    - âRulesâ a programmer has to follow when writing concurrent code
- **Threads**
  - Multiple threads can access the same shared variables
  - Each thread has its own local variables

### Sequential Consistency {#sequential-consistency}

- The result of an execution is the same for any order the operations from a processor
  - A sequential processor does **NOT** guarantee sequential consistency
  - Each processor issues memory requests
  - Processed from a FIFO(first-in, first-out) queue
  - If a program has no [data races](#race-condition), it is sequentially consistent
  - If else its behaviour is undefined
  - None of todays architecture is sequential consistent \* Because of performance optimization in hardware and

### C++ Threads {#cpp-threads}

- Each instance of the **thread** class represents threads of execution
- Communicates through shared variables
- Only terminates from inside program, not outside
- Creating a thread object:

```cpp
void print(string s1, string s2) {
cout << s1 << s2; }
std::thread t1([]() {
cout << "Hello"; });
std::thread t2(print, ", ", "World!");
```

- A thread may be joinable
  - A joinable thread is potentially executing
  - A not joinable thread is not executing
  - Only not joinable threads can be safely destroyed
  - Destructor of thread calls **std::terminate()**
- Example of joining thread:

```cpp
#include <iostream>
#include <thread>
void print(string s1, string s2) { cout << s1 << s2; }

int main() {
 std::thread t1([]() {cout << "Hello"; });
 std::thread t2(print, ", ", "World!");
 t1.join();
 t2.join();
 return 0;
}
```

- Example of **NOT** joining threads:

```cpp
#include <iostream>
#include <thread>
void print(string s1, string s2) { cout << s1 << s2; }
int main() {
 std::thread t1([]() { cout << "Hello"; });
 std::thread t2(print, ", ", "World!");
 //    t1.join();
 //    t2.join();
 return 0;
}
```

- Same example in alang:

```cpp
#include "alang.hpp"
void print(string s1, string s2) { cout << s1 << s2; }
int main() {
 processes ps;ps += []() {
 cout << "Hello";
 };
  ps += []() {
  print(", ", "World!");
  };
  return 0;
 }
```

- Helper function:

```cpp
void pause_thread_s(int n) {
 std::this_thread::sleep_for(std::chrono::seconds(n));
}
void pause_thread_ms(int n) {
 std::this_thread::sleep_for(std::chrono::milliseconds(n));
}
```

- this_thread:
  _get_id gets threads id
  _ yield hints to the scheduler to reschedule

- **detach()** lets a thread âlooseâ
- thread object becomes not joinable
- Example, removing âWorld!â:

```cpp
void print(string s1, string s2) { cout << s1 << s2; }
int main(){
 std::thread([]() {
 pause_thread_s(2);
 std::cout << "Hello";}).detach();
 std::thread(print, ", ", "World!").detach();
 pause_thread_s(1);
}
```

- Thread constructor parameters:

```cpp
template <class Fn, class... Args>
explicit thread (Fn&& fn, Args&&... args);
```

- Unhandled exceptions on thread terminates a program

### Mutex {#cpp-mutex}

- C++ protects access to shared data with:
  - [Mutexes](#mutual-exclusions)
  - [Locks](#locks)
  - [Atomics](#atomic-action)
- Mutual exclusion object
  - Thread gets ownership of a mutex by locking and releases it by unlocking
  - Member functions
  - **lock()** - block until mutex is available, the lock and continue
  - **try_lock()** - lock if available, otherwise false
    - **unlock()** - release ownership
- Code example:

```cpp

int acc = 0;
mutex acc_mutex;
void acc_square(int x) {
 int tmp = x * x;
 acc_mutex.lock();
 acc += tmp;acc_mutex.unlock();
 }
int main() {
 map<int, int> m;
 for (int j=0; j<1000; ++j) {
 acc = 0;
  vector<thread> ts;
  for (int i = 1; i <= 10; i++)
  ts.push_back(thread(acc_square, i));
  for (auto& t : ts) t.join();
  if (m.count(acc) == 0)
   m[acc] = 1;
    else m[acc]++;
    }
    for (auto kv : m)
    cout << "acc=" << kv.first << ": " << kv.second << " times\n";
  }
```

### Types of mutexes {#cpp-mutex-types}

- **Recursive mutex**
  _ Can be locked repeatedly by the same thread
  _ Released when unlocked the same amount of times
- **Timed Mutex**
  - Only wait for a locked mutex a limited amount of time before it gives up
- **Shared-timed-mutex, shared-recursive-mutex**:
  _ Shared and exclusive access
  _ Use full when there is a lot of read activity, but writing has to be exclusive

### Examples {#cpp-mutex-examples}

#### Try-Lock Recursive mutex example: {#tlrme}

```cpp
class counter {
 recursive_mutex mut;
 int c = 0;
 public:void tick() {
   mut.lock();
    ++c;
    mut.unlock();
    }
 void tickManyIfCan(int n) {
 if (mut.try_lock()) {
 while (n-- > 0) tick();
 mut.unlock();
  }
 }
 int value() {
 return c;
  }
 };
 void task(counter& ctr) {
 for (int i=0; i<100; i++) {
 pause_thread_ms(1);
 ctr.tickManyIfCan(10);
  }
 }
 int main() {
 counter ctr;
 thread t1(task, ref(ctr)), t2(task, ref(ctr)), t3(task, ref(ctr));
 t1.join(); t2.join(); t3.join();
 cout << "\nvalue = " << ctr.value();
 }
```

#### Timed Mutex Example: {#tme}

```cpp
timed_mutex mut;
 void attempt (atomic<int>& successes) {
  if (mut.try_lock_for(chrono::milliseconds(50))) {
  // now we have the lock
  ++successes;
  pause_thread_ms(2);
  mut.unlock();
 }
}
 void run() {
  thread ts[100];
   atomic<int> successes = 0;
   for (int i=0; i<100; ++i)
   ts[i] = thread(attempt, ref(successes));
   for (auto& t : ts)
   t.join();
   cout << "#successes = " << successes << endl;
  }
 int main() {
  run(); run(); run();
 }
```

#### Shared Mutex Example: {#sme}

```cpp
 td::shared_mutex
  s_mut;
  timer tm;
  void reading(const string& data, int secs) {
   s_mut.lock_shared();
   pause_thread_s(secs);
   alang::logl("Reader ", data, " ", tm.elapsed());
   s_mut.unlock_shared();
 }
  void writing(string& data, string d, int secs) {
   s_mut.lock();
   pause_thread_s(secs);
   data = d;
   s_mut.unlock();
   alang::logl("Writer ", d, " ", tm.elapsed());
  }
  int main() {
   string data = "A";
   vector<thread> ts;
   tm.reset();
   ts.emplace_back(reading, cref(data), 3);
   ts.emplace_back(reading, cref(data), 4);
   ts.emplace_back(writing, ref(data), "B", 1);
   ts.emplace_back(writing, ref(data), "C", 2);
   ts.emplace_back(reading, cref(data), 0);
   for (auto& t : ts) t.join();
 }
```

### Mutex-Wrappers {#cpp-mutex-wrapper}

#### RAII {#raii}

```cpp
int c;
mutex cm;
 ...
 {
 lock_guard<mutex> lock(cm); // mutex locked here
 foo(c);
 } // unlocked here when lock destroyed

```

#### lock and lock_guard: {#lock-lockguard}

- Adopts an already locked mutex \* **std::lock()** takes a given number of mutexes and locking them without [deadlocking](#deadlock)

```cpp
container a, b; // assume both have mutex member variable
{
 std::lock(a.mutex, b.mutex);
 lock_guard<mutex> l1(a.mutex, std::adopt_lock_t);
 lock_guard<mutex> l2(b.mutex, std::adopt_lock_t);
 a.put(b.get()); // maybe exceptions
 } // locks released here

```

#### unique_lock {#unique-lock}

- Can be given more policies
  - **adopt_lock_t**
  - **defer_lock_t**
  - **try_to_lock_t**
- or a duration or time point
  - For how long or wait time to acquire lock
- Moveable, transfers the mutex
- Unlocking and re locking possible

```cpp
container a, b; // assume both have mutex member variable
{
 unique_lock<mutex> l1(a.mutex, defer_lock_t);
 unique_lock<mutex> l2(b.mutex, defer_lock_t);
 lock(l1, l2);
 a.put(b.get());// maybe exceptions
 }// locks released here

```

#### scoped_lock wrapper {#scoped-lock-wrapper}

- Easiest mutex lock
- Can wrapt multiple mutexes from the constructor without deadlocking

```cpp
std::mutex m1, m2, m3;
 ...
{
 std::scoped_lock lock(m1, m2, m3);
 // critical section
} // mutexes released here (in reverse order)
```

- Mutexes can be different types
- No need to specify mutex types(C++17âs class template argument deduction)

### C++ Conditional Variables {#cpp-conditional-variables}

- Allows blocking a thread until notified
- Waiting methods from the **conditional variable** class puts the thread to sleep, to start waiting for a conditional variable
  - **void wait(unique_lock<mutex>);** see [unique-lock](#unique-lock)
  - **void wait_for(unique_lock<mutex>, chrono::duration<â¦>);** see [unique_lock](#unique_lock)
  - **wait_until(unique_lock<mutex>, chrono::time_point<â¦>);**
- A thread starts waiting holding a lock, and wakes up holding a lock
  - unique_lock associated with a mutex
- Notifies threads with:
  - **void notify_one()**
  - **void notify_all)()**
- **Spurious wakeup**
  - Scheduler can wake up threads without a calling notifying function

- Example:

```cpp
#include <condition_variable>
mutex mut;
condition_variable cv;
int resource = 0;
void worker (int amount) {
 unique_lock<mutex> lock(mut);
 while (amount > resource) cv.wait(lock);
 resource -= amount;
 cout << "Handled  " << amount << ", remains " << resource << endl;
 }
int main ()  {
 thread ts[10];
 for (int i = 0; i < 10; ++i)
  ts[i] = thread(worker, i);

  {
   unique_lock<mutex> lock(mut);
   pause_thread_s(1);
   resource = 100;} // unlock here
   cv.notify_all();
   for (auto& t : ts) t.join();
  }
```

#### Thread Local Variables {#thread-local-variables}

- **thread_local** \* Each thread has an instance of thread_local variable
- Allocated when a thread begins and Deallocated when it terminates
- Can be namespace scope, block scope or static member variables

#### Call once {#call-once}

- Allocates a piece of code to a single thread
- **call_once()**

```cpp
template< class Callable, class... Args >
void call_once(std::once_flag& flag, Callable&& f, Args&&... args);
```

- Each call of call_once with the once_flag defines a group
  - Other threads block on **call_once()** so that once thread at a time can execute until the flag is set

#### C++ Atomics {#cpp-atomics}

- **atomic<T> x**
  _ **T** cannot be arbitrary type, used for integral and pointer types
  _ Can be created an instance trivially copy type
  _ Can be implemented with hardware lock-free atomic opâs or:
  _ implemented using mutexes

#### Atomic Objects {#atomic-objects}

- **Atomic assignment**
  - T operator=(T)
  - void store(T, memory_order = std::memory_order_seq_cst)
- **Atomic read**
  - operator T() const
  - T load(memory_order = std::memory_order_seq_cst) const
- **Atomic Swap**
  - T exchange(T, memory_order = std::memory_order_seq_cst)
- **Compare-and-swap**
  - bool compare_exchange_weak (T& expected, T desired, ...)
  - bool compare_exchange_strong(T& expected, T desired, ...)
    - (the...stands for memory order parameters)
- **Atomic bit manipulation and arithmetic for those T that make sense**
  - fetch_and,fetch_or,fetch_xor,fetch_add,fetch_sub

#### Compare and Swap {#compare-and-swap}

```cpp
bool atomic<T>::compare_exchange_weak(T& expected, T desired);
```

- Use in a loop for as long as the value is expected

#### Task-Based Parallelism {#task-based-paralellelism}

- Abstracts over OS thread
  - Because OS threads are more expensive
  - Decomposed into independent **tasks**
- Tasks are determined from **dependency graphs**
  - **Future/Promised** and [**async**](#async) creates these graphs
  - **Promise and Future** are basic building blocks
  - A packaged task wraps any function object with a promise-future channel
  - A **Future object** is attached to the wrapped function object
  - Calling the object resolves the promise with **set_value**
  - Exception sets with **set_exception** \* **async** abstracts over a packaged task
- **Implementation ideas:**
  - **Thread pools**
  - **Work stealing**
  - Idle PSâs steal tasks from another PSâs queue
  - Tasks should be freely migrated between threads

### Futures {#futures}

- Delayed value that promises that eventually a value will exist

    ```cpp
    future<int> f = async([]{ return hailstone(9780657631) });
    ```

- A future can be queried when a value is required \* Could be blocking until value is not available yet

    ```cpp
     if (f.get() == 1) { ... }
     ```

- A placeholder for a result of a computation
  - **Three States**
    - Pending: Future has no value yet
    - Fulfilled: The future value has been achieved
    - Rejected: The future never got it's expected value

#### Future Class {#future-class}

- **template<class T> class future;**
  - Tis the type of the result (can be void)
  - T must beMoveConstructible
  - future<T>cannot be copied, only moved
- **void wait() const;**
  - blocks until futureâs result available
  - also wait_for() and wait_until()
- **T get();**
  - blocks until result available, then returns it
  - get can only be called once
- **bool valid() const;**
  - has the value not been queried? (with get or share)
  - does the future have a shared state
- **std::shared_future<T> share();** \
  - gets the value and moves the futureâs value to a shared future

#### shared_future<T> {#shared-future}

- Same as **future<T>** but can be copied
  - Many threads can wait
- Construct shared_future object for each shared state
- Example:

```cpp
void detect(int x, shared_future<int> y) {
 static std::mutex iom;
 if (x == y.get()) {
  unique_lock l(iom);
   cout << "Found " << x << endl;
   } else {
   unique_lock l(iom);
    cout << "Expecting " << x << endl;
    }
 }

int main() {
 promise<int> p;
 shared_future<int> f = p.get_future().share();
 for (int j=0; j<10; ++j)
  thread(detect, j, f).detach();
  pause_thread_s(1);
  p.set_value(7);
  pause_thread_s(1);
 }
```

#### Future Combinators {#future-combinators}

- **when_any**
  - Wait until at least one of a set of futures is ready:

   ```cpp
   auto f_or_g = when_any(async(f), async(g)); f_or_g.then([](future<int> f) { ... });
   ```

- **when_all**
  - Wait until all futures of a set is ready:

  ```cpp
  future<tuple<future<int>, future<int>>> f_and_g = when_all(async(f), async(g));
  future<int> futf, futg; tie(futf, futg) = f_and_g.get(); // blocks
  cout << futf.get() + futg.get();// does not block
  ```

#### future::then {#future-then}

- Used instead of blocking with **get** until a future is ready \* Does not block
- Example:

```cpp
#include <future>
using namespace std;
 future<int> f1 = async([]{ return hailstone(12342342); });
 future<string> f2 = f1.then(
 [](int i) { return to_string(i); }
 };

 cout << f2.get();
}

```

### Promises {#promises}

- Object
- Promise -> Future is a one-off communication channel
  - Together has a shared state
  - Ready flag
  - Eventual result or exception when ready
  - Only one future per promise
  - **get_future** can be called once
  - or [shared_future](#shared-future)
  - **set_value, set exception**
  - set ready flag and value/exception
  - unblock threads waiting for promise
  - Destruction a promise
  - Gives up shared state
  - Deletes if no future waiting
    - Else throws **broken_promise**
- Synchronized with **set_value** and **set_exception**
  - e.g futures **get** and **wait**

### Async {#async}

Two **Overloads:**

```cpp
// 1
template<class Function, class... Args>
std::future<typename std::result_of<Function(Args...)>::type>
async(Function&& f, Args&&... args);

// 2
template< class Function, class... Args >
std::future<typename std::result_of<Function(Args...)>::type>
async(std::launch policy, Function&& f, Args&&... args);

```

- Launch policy:
  - **launch::async** executes a new thread with thread locals initialized
  - **launch::deferred** executes in the same thread at a **get()** call

### Task System Implementations {#task-system-implementations}

- Determine the benefits of multithreading
  - **Amdahlâs Law:**
  - $ S(n) = \frac{1}{1-p + \frac{p}{n}} $
  - S is theoretical speedup
  - n is the factor of increase in resources(number of cores)
    - p is the portion benefitting from the resources(unit is time)

- Returning out results is a way for tasks to communicate
  - **async** schedules a packaged task and returns a future
  - future becomes **ready** when task completes

- All following examples assumes these are included:

```cpp
#include <thread>
#include <mutex>
#include <deque>
#include <vector>
#include <unordered_map>
#include <functional>
#include <algorithm>
#include <string>
#include <future>
#include <type_traits>
using std::forward;
using std::move;
using std::function;
using std::thread;
using std::string;
using std::future;
using lock_t = std::unique_lock<std::mutex>;
```

### Number of threads {#number of threads}

- **thread::hardware_concurrency()**
  - May provide the number of cores currently in our system
- Number of threads allocated for the task affects speedup

```cpp
unsigned int number_of_threads() {
 return std::min(
 32u,
 std::max(1u, thread::hardware_concurrency()));
 }
```

### Compute Primes {#compute-primes}

```cpp
#include "task-system-utilities.hpp"

class notification_queue {
 std::deque<function<void()>> _q;
 std::mutex                   _mutex;
 std::condition_variable      _ready;
 bool                         _done = false;
  public:
   void done() {
    {
  lock_t lock(_mutex); _done = true;
     }
  _ready.notify_all();
   }

   bool pop(function<void()>& f) {
    lock_t lock(_mutex);
    while (_q.empty() && !_done) _ready.wait(lock);
    if (_q.empty()) return false;
    f = move(_q.front());
    _q.pop_front();return true;
   }
   template <typename F> void push(F&& f) {
    {
      lock_t lock(_mutex);
      _q.emplace_back(forward<F>(f));
      }
     _ready.notify_one();
   }
  };

class task_system {
 const unsigned int  _nthreads;
 std::vector<thread> _threads;
 notification_queue  _q;
 void run() {
  while (true) {
   function<void()> f;
   if (!_q.pop(f)) break; // !
   f();
   }
  }
 public:
  task_system(int nthreads = 0)
  : _nthreads(nthreads > 0 ? nthreads : number_of_threads())
  {
  for (unsigned int n = 0; n < _nthreads; ++n) {
  _threads.emplace_back([&]{ run(); });
  }
 }
 ~task_system() { _q.done(); for (thread& t: _threads) t.join(); }
 template <typename F>
 void async(F&& f) { _q.push(forward<F>(f)); }
};

bool is_prime(long num) {
 long limit = sqrt(num);
 if (num < 2) return false;
 for (long i=2; i<=limit ; i++) {
 if (num % i == 0) return false;
 } return true;
}

std::atomic<int> found = 0;
int count_primes(long n) {
 int count = 0; while (n-- > 1) { if (is_prime(n)) ++count; }
 return count;
}

const int ntasks = 4096;
void test(int nthreads) {
 double time;
  timer tmr;
  {
   task_system ts(nthreads);
   for (int i=0; i<ntasks; ++i)
    ts.async([&]{ found += count_primes(1000);  });
    }
  time = tmr.elapsed();
  logl("time ", time, " using ", nthreads, " threads");
 }

int main() {
 for (int n = 1; n <= 2048; n *= 2)
 test(n);
 test(thread::hardware_concurrency());
}
```

- **lock_t** is defined as **[std::unique_lock<std::mutex>](#unique-lock)**

- **front** accesses the first element, **pop_front** discards it
- Functions are moved, not copied

## Software Transactional Memory {#stm}

- Declare blocks of code that should execute atomically
- No locks
- Threads write without regard for other threads
- Keeps log of memory read/write
  - Logs are read after execution and compared to the memory
  - If execution has changed, the transaction is rolled back
  - Otherwise commited
- Good for programmer because
  - No need to keep track of locks(unless implemented)
  - No deadlock

- **Pros**
  - [Fine-Grained](#fine-grained-atomicity)
  - Good performance in dist. inviroments
- **Cons**
  - Performance could be a lot worse than locking

### Rollback

- **Occurs**
  - On Read
    - if variable is locked
    - Version greated than rv
- On commit
  - If any log variable can not be loacked
  - If any log variable locked or version higher than rv

## Message Passing Concurrency

- **Distributed Memory Architectures**
  - Processors has private memory
  - Connects with other PS's with **interconnect** network
  - Processes communicate by sending messages and recieving messages through **shared channels**
    - Via **RPC** og **rendez-vous**
    - Big Picture:

    ```cpp

                                        (implicit mutual exclusion)
                                     --> [Monitors]        -->
    [Busy Waiting] --> [Semaphores]                             [RPC/Rendez-vous]
                                     --> [Message Passing] -->
                                        (each semaphore carries data)

    ```

### Channel

- Communication path between processes
- chan c(type1, id1,....,typen,idn)

- ```cpp
    chan c1(int acc-id, int ctr, int amount)
    ```

- **Primitives**
  - Send
    - c(e1,e2,....,en)
    - Channel has c Space
    - Blocks if channel is full
  - recieve
    - c(var1,var2,...,varn)
    - Removes the message if C has atleast one
    - Blocks if empty
  - empty(c)

- **Channel abstraction**
  - One way
  - FIFO Queue
  - Atomic access to queue
  - Error-free
  - Typed

- **Filters**
  - One-way interaction pattern
  - A PS who recieves message from input channel
  - Sends to output(function of input and initial state) channels

### Client-Server with Message Passing

```cpp
    chan request(int clientID, typesofinpit);
    chan reply[n] (typesofresults)
    Process Server{
        int clientID;
        // initializstion, permanent variables
        while(true){
            recieve request(clientID, input values);
            // body
            send reply[clientID, result values]
        }
    }
    process client[i=0 to n-1]{
        send request(i,args);
        recieve reply[i] (res_args)
    }
    monitor Server{
        permanenet variables;
        initialization code;
        procesdure op(input_args){/* body; */ }
    }
```

### Synchronouse Message Passing

- **Sync_Send**
  - c(e1,e2,....,en)
  - Blocks until message is recieved
  - Sender and reciever synchroniza on sending and recieving a message
- **Perks**
  - Fixed channel size(no memory for message data)
    - At most one pending recieves message
    - At most one undelievered message
- **Draws**
  - Reduced parallelism
  - Higher [deadlock](#deadlock) risk
    - Deadlock example:

    ```cpp
    chan in1(int),in2(int);
    process P1{
        int v1,v2 = 1;
        sync_send
    }
    process P2 {
        int v1,v2 = 2;
        sync_send in1 (v2);
        recieve in2(v1):
    }


    ```

## Coroutine {#coroutine}

- Control abstraction for co-operative, or non-preemptive multitasking
- Generalization of [subroutines](#subroutine)
  - Suspending the execution
  - Resuming a suspended execution
- Coroutines are in progress simultaneously, but not executed at the same time

- Five transfer of control events:
  - Call
    - Activation frame/record pushed on to the stack
  - Return
    - Activation frame/record is popped from the stack
  - Suspend
    - Suspends execution, saves the frame/record, remembers the current point and transfer execution back to caller
  - Resume
    - Restores saved frame/record
  - Destroy
    - Deallocates saved frame/record

- Corollary: activation frame lifetime are not nested
  - Heap allocation

- Can run asynchronously with caller
- Caller can wait for suspension/return

```javascript
function* primes() {
    let primes = [];
    let c = 2;
    while (true) {
        let composite = false;
        for (let p of primes) {
            if (c % p == 0) {
                 composite = true;
                  break;
                   }
                  }
                  if (!composite) {
                      primes.push(c);
                       yield c;
                    }
                    ++c;
            }
    }
let p = primes();
while (true) {
    let r = p.next();
    if (r.value > 20) break;
    console.log(r.value);
    }

```

### Subroutine {#subroutine}

- Has a call and return

- Call
  - Pushes a new frame to stack
  - Suspends caller
  - jumps to the beginning of the function
- Return
  - passes return value to caller
  - Pops the frame
  - Resumes callerâs execution

- Has register for top of stack and allocates/deallocates(modify) the top of the stack

### **Symmetric**

- Singe control transfer operator that specifies target

### **Asymmetric**

- Similar to subroutines, transferred back to caller
- Symmetric/Asymmetric equally expensive, so can emulate each other

### First-class coroutines

- âBehaves like any value
- Can be store in variable
- Passed as parameter
- Returned from function
- Be yielded

- **Stackfull**
  - coroutines can suspend in nested functions
- **Stackless** coroutines can only suspend at top level
  - Must create new coroutine layer

### Generators-Iterators-Coroutines {#iterators}

- Is iterator if it implements next() with:
  - no arguments
  - returns object p such that
    - p.done : boolean
  - if p.done == false, then p.value is returned by the iterator

- An object is iterable if it has the computed property [Symbol.iterator], which is a nullary function returning an iterator

### Coroutine Frame

- Located in the iterator object
- Local variables are iterator objectsâs member variables

### Closing coroutines

- Breaking out of the iterator loop, closes the iterator
- Generators are close able iterators
- Resources can be cleansed at close
- Generators/Iterators are iterables and iterators

### Suspending coroutine

- yield communicates data from a coroutine to its caller when the coroutine is suspended
- yield e also receives data when coroutine resumed

### Resuming coroutine

- yield e is an expression, its value is the value sent to coroutine when it is resumed
- yield e can resume with an exception sent from its caller(ASYNC/AWAIT)

- Functions defined as async can contain await statements
- await e evaluates e to a promise, and waits until the promise is resolved
- The resolved promiseâs value is the value of the expression await e
- A rejected promise turns into an exception

## Coding {#coding}

### **C++ Coding {cpp-coding}**

### Ticket Algorithm {c++-ticket}

- [Explanation of the algorithm](#ticket-algorithm)

```cpp
#include "alang.hpp"
#include <vector>
using namespace std;

const int n = 4;
const int nCustomers = 4; // this many customers
const int nRounds = 5;    // each use service this many times
A<int> current_number = 0, next_served = 0;

int take_ticket_and_wait(int i)
{
    // take a ticket, print the received ticket number, and block until it is your turn
    // return the recived ticket number
    int myturn;
    ATO myturn = current_number;
    current_number = current_number + 1;MIC;
    alang::log("\nProcess ", i, " got turn: ", myturn);
    ATO AWAIT(myturn == next_served);MIC;
    return myturn;
}

void release_ticket()
{
    // let the next process proceed
    ATO next_served = next_served + 1; MIC;
}

int main()
{
    {
        processes ps;

        for (int i : range(0, nCustomers))
        {
            ps += [&, i] {
                for (int j : range(0, nRounds))
                {
                    int turn = take_ticket_and_wait(i);
                    // Perform task
                    alang::logl("\nProcess ", i, " runs on turn ", turn);
                    release_ticket();
                }
            };
        }
    }
}
```

**Output:**
<br>Process 1 got turn 0
<br>Process 0 got turn 1
<br>Process 2 got turn 2
<br>Process 3 got turn 3
<br>Process 1 runs on turn 0
<br>Process 1 got turn 4
<br>Process 0 runs on turn 1
<br>Process 0 got turn 5
<br>Process 2 runs on turn 2
<br>Process 2 got turn 6
<br>Process 3 runs on turn 3
<br>Process 3 got turn 7
<br>Process 1 runs on turn 4
<br>Process 1 got turn 8
<br>Process 0 runs on turn 5
<br>Process 0 got turn 9
<br>Process 2 runs on turn 6
<br>Process 2 got turn 10
<br>Process 3 runs on turn 7
<br>Process 3 got turn 11
<br>Process 1 runs on turn 8
<br>Process 1 got turn 12
<br>Process 0 runs on turn 9
<br>Process 0 got turn 13
<br>Process 2 runs on turn 10
<br>Process 2 got turn 14
<br>Process 3 runs on turn 11
<br>Process 3 got turn 15
<br>Process 1 runs on turn 12
<br>Process 1 got turn 16
<br>Process 0 runs on turn 13
<br>Process 0 got turn 17
<br>Process 2 runs on turn 14
<br>Process 2 got turn 18
<br>Process 3 runs on turn 15
<br>Process 3 got turn 19
<br>Process 1 runs on turn 16
<br>Process 0 runs on turn 17
<br>Process 2 runs on turn 18
<br>Process 3 runs on turn 19

### Semaphores {#cpp-semaphores}

- See [semaphores](semaphores)

### Semaphores implementation {#cpp-semaphores-implementation}

```cpp
#include "alang.hpp"

class barrier
{
    alang::semaphore arrive, depart;
    int ctr, n;

public:
    barrier(int n) : arrive(1), depart(0), ctr(0), n(n) {}

    void set(){
        arrive.P();
        if(ctr > n){
            arrive.V();
        } else {
            depart.V();
        }
        depart.P();
        if(ctr > 0){depart.V();}
             else{
                 arrive.V();
             }
        }
};

void launch_processes(processes &ps, barrier &b, int stages, int n){
    for (int i = 0; i < n; ++i)
    {
        ps += [&, i, stages] {
            for (int s = 0; s < stages; ++s)
            {
                logl("Stage ", s, ", process ", i);
                b.set();
            }
        };
    }
}
int main(){
    {
        barrier b(4);
        processes ps;
        launch_processes(ps, b, 3, 4);
    }
}

```

**Output:**
Stage 0, process 0
Stage 1, process 0
Stage 2, process 0
Stage 0, process 1
Stage 1, process 1
Stage 2, process 1
Stage 0, process 3
Stage 1, process 3
Stage 2, process 3
Stage 0, process 2
Stage 1, process 2
Stage 2, process 2

### Semaphores Banking Problem {#cpp-banking-problem}

- Multiple threads trying to deposit and withdraw from bank accounts

```cpp

#include "alang.hpp"

class bank_account
{
    alang::semaphore sem;
    int balance;
    int number;

public:
    bank_account(int n) :sem(1), balance(0), number(n) {}

    int get_number() { return number; }
    int get_balance() { return balance; }

    void deposit(int sum){
        sem.P();
        balance = balance + sum;
        sem.V();
    }

    void withdraw(int sum){
        sem.P();
        balance = balance - sum;
        sem.V();
    }

    void transfer_to(bank_account &b, int sum){
        if(this -> number < b.number){
        sem.P();
        b.sem.P();
        balance = balance - sum;
        b.balance = b.balance + sum;
        b.sem.V();
        sem.V();
        }else{
            sem.P();
            b.sem.P();
            balance = balance - sum;
            b.balance = b.balance + sum;
            sem.V();
            b.sem.V();
        }
    }
};
int main(){
    std::vector<bank_account *> vec;
    for (int i = 0; i < 10; ++i)
    {
        vec.push_back(new bank_account(i));
    }
    {
        processes ps;
        for (int i = 0; i < 100; ++i)
        {
            ps += [i, &vec] {
                for (int j = 0; j < 10; ++j)
                {
                    for (int k = 0; k < 10; ++k)
                    {
                        vec[j]->deposit(100);
                        vec[k]->withdraw(100);
                        vec[j]->withdraw(100);
                        vec[k]->deposit(100);
                        if (j != k)
                            vec[j]->transfer_to(*(vec[k]), 10);
                    }
                }
            };
        }
    }
    for (int i = 0; i < 10; ++i){
        alang::logl("Account ", i, " has balance ", vec[i]->get_balance());
    }
}

```

**Output**
<br>Account 0 has balance -70
<br>Account 1 has balance -240
<br>Account 2 has balance 0
<br>Account 3 has balance -210
<br>Account 4 has balance 30
<br>Account 5 has balance 110
<br>Account 6 has balance 90
<br>Account 7 has balance 90
<br>Account 8 has balance -300
<br>Account 9 has balance 240

### Monitor {#cpp-monitor}

#### Bridge Crossing Problem {#cpp-bridge}

- Cars has to drive over a bridge
- Only cars allowed in the same direction is allowed to drive at once
- Cars can drive past each other
- Cars coming from the opposite direction has to wait until the cars on the bridge have passed

```cpp
#include "alang.hpp"
#include <array>

using alang::logl;
using alang::prandom;
using alang::sleep_ms;
using std::array;
using std::string;

// "?" is a conditional statment in c++. If north is true, north is return, otherwise south
enum direction{ north = 0, south = 1};
direction opposite(direction dir){return (dir == north ? south : north);}

class bridge :  monitor{
    private:
        array<int, 2> ncars = { 0,0 }; // creates an array to see how many cars going in each direction
        // invariant ncars[north] == 0 ||Â ncars[south] == 0
        cond empty_bridge;
    public:
        bridge() {}
            array<int, 2> bridge_status(){
                SYNC;
                return ncars;
            }

            void car_arrive(direction dir){
                SYNC;
                while(ncars[opposite(dir)] != 0){
                    wait(empty_bridge);
                }
                ++(ncars[dir]);
            }

            void car_leave(direction dir){
            {
                SYNC;
                --(ncars[dir]);
            }
            if(ncars[dir]==0)
                signal_all(empty_bridge);
            }
};

auto car(bridge &b,
         int max_crossings,     // cross at most this many times
         int min_crossing_time, // crossing takes at least this long
         int max_crossing_time, // crossing takes at most this long
         int min_idle_time,     // wait at least this long before trying to cross again
         int max_idle_time){ // wait at most this long before trying to cross again

    return [=, &b] {
        direction dir = static_cast<direction>(prandom(0, 1)); // Casts a random direction
        int n = prandom(max_crossings);

        while(n-- > 0)
        {
            sleep_ms(prandom(min_idle_time, max_idle_time)); // Random idle time
            b.car_arrive(dir); // car arrives on bridge
            array<int, 2> counts = b.bridge_status(); // car on bridge checks car distrubution(invariant)
            assert(counts[north] == 0 || counts[south] == 0); // checks if it is empty

            if(counts[north] > 0)
                logl(string(counts[north], 'N'));
            else
                 logl(string(counts[south], 'S'));

            alang::sleep_ms(alang::prandom(min_crossing_time, max_crossing_time)); //random crossing time for car
            b.car_leave(dir); // bye bye car

            counts = b.bridge_status(); // checks bridge status againg
            assert(counts[north] == 0 || counts[south] == 0);

            dir = opposite(dir); // car turns back
        }
    };
}

int main(){
    bridge b;{
        processes ps;
        for (int i = 0; i < 10; i++){
            ps += car(b, 8, 1, 10, 2, 20);
             // 10 cars, 8 crossings each, each crossing takes 1-10ms, each car waits 2-20 ms
        }
    }
}

```

**Output:**
<br>N
<br>NN
<br>S
<br>SS
<br>SSS
<br>SSS
<br>N
<br>NN
<br>NNN
<br>S
<br>...

### Message Passing and Channels {#message-passing-channels}

- P1 sends random numbers to P2
- When P1 generates -1, P2 sends back the sum of the numbers sent by P1

```cpp
#include "alang.hpp"

alang::channel<int> c1, c2;

int main(){
    processes ps;
    ps += [] {
        int sum, m;
        while(m != -1){
			m = alang::prandom(-1, 10);
            c1.send(m);
            alang::logl("Sent ", m);
    	}
		c2.receive(sum);
		alang::logl("Recieved sum ", sum);
	};

    ps += [] {
        int sum, m = 0;
		while(true){
			c1.receive(m);
			alang::logl("Recieved ", m);
			if(m == -1)	break;
			sum += m;
			}
		alang::logl("Sending sum ", sum);
		c2.send(sum);
    };
}

```

### Filters With Quicksort {#filters-with-quicksort}

```cpp
#include "alang.hpp"

using d_channel = alang::channel<int>;
using alang::channel;
using alang::prandom;
using std::vector;

const int EOS = -1;

void partition_filter(int pivot, d_channel in1, d_channel out1, d_channel out2){
    int r;
    in1.receive(r);
    while(r != EOS){
        if(r <= pivot)
            out1.send(r);
        else
            out2.send(r);
        in1.receive(r);
    }
    out1.send(EOS);
    out2.send(EOS);
}

void merge_filter(d_channel in1, d_channel in2, d_channel out){
    int v1, v2;
    in1.receive(v1);
    in2.receive(v2);
    while (v1 != EOS && v2 != EOS){
        if (v1 <= v2){
            out.send(v1);
            in1.receive(v1);
        } else{
            out.send(v2);
            in2.receive(v2);
        }
    }while (v1 != EOS)  {
        out.send(v1);
        in1.receive(v1);
    }   while (v2 != EOS)  {
        out.send(v2);
        in2.receive(v2);
    }
    out.send(EOS);
}

void quick_sort(d_channel in, d_channel out){
    int pivot;
    in.receive(pivot);
    if(pivot == EOS){
        out.send(EOS);
        return;
    }
    d_channel sort1, sort2, o1, o2;

    processes ps;
    ps += [&]() { partition_filter(pivot, in, o1, o2); };
    ps += [&]() { quick_sort(o1, sort1); };
    ps += [&]() { sort2.send(pivot); quick_sort(o2,sort2); };
    ps += [&]() { merge_filter(sort1, sort2, out); };
}


int main(){
    const int EOS = -1;
    vector<int> vin, vout;{
        d_channel in, out; // note: channels are defined before ps, so that they are destructed after ps
        processes ps;

        ps += [&] { quick_sort(in, out); };

        ps += [&] {
            int p;
            do{
                p = prandom(-1, 10);
                vin.push_back(p);
                in.send(p);
            } while (p != EOS);
        };
        ps += [&] {
            while (true){
                int p;
                out.receive(p);
                vout.push_back(p);
                if (p == EOS)break;
            }
        };
    }
    for (auto i : vin)
        log(i, " ");
    logl();
    for (auto i : vout)
        log(i, " ");
    logl();
}

```

### Saving Account {#savings-account}

```cpp
#include "alang.hpp"

using alang::channel;
using std::to_string;
using std::vector;

using money = int;
using option = int;
using reply = money;

channel <channel<reply> , option, money> request;

const int DEPOSIT = 0, WITHDRAW = 1, KILL = 2;

auto bankServer = [] {
    std::deque<std::pair<channel<reply>, money>> queue;
    int balance = 0;
    while(true)
    {
        channel<reply> reply_channel;

        option op;
        money amount;

        request.receive(reply_channel, op, amount);
        switch (op)
        {

        case DEPOSIT:
            balance += amount;
            reply_channel.send(balance);

            while(!queue.empty())
            {
                auto p = queue.front();
                if(p.second < balance)
                {
                    balance -= p.second;
                    p.first.send(balance);
                    queue.pop_front();
                }else{
                    break;
                }
            }
            break;

        case WITHDRAW:
            if(amount > balance)
            {
                queue.push_back(std::make_pair(reply_channel, amount));

            }
            else{
                balance -= amount;
                reply_channel.send(amount);
            }
            break;

        case KILL: return;
        }
    }
};

int main(){
    processes ps;
    ps += [] {
        reply r;
        channel<reply> ch;
        for (int i = 0; i < 10; ++i)
        {
            request.send(ch, DEPOSIT, 100);
            ch.receive(r);
            logl(r);
        }
    };
    ps += [] {
        reply r;
        channel<reply> ch;
        for (int i = 0; i < 10; ++i)
        {
            request.send(ch, WITHDRAW, 100);
            ch.receive(r);
            logl(r);
        }# **INF214 Cheat Sheet**

- [**INF214 Cheat Sheet**](#inf214-cheat-sheet)
  - [Processes and Synchronization](#processes-and-synchronization)
    - [Terms](#terms)
      - [State](#state)
      - [Atomic Action {#atomic-action}](#atomic-action-atomic-action)
      - [Interference {#interference}](#interference-interference)
      - [Noninterference {#noninterference}](#noninterference-noninterference)
      - [Race Condition {#race-condition}](#race-condition-race-condition)
      - [Unnecessary delay {#unnecessary-delay}](#unnecessary-delay-unnecessary-delay)
      - [Eventual Entry {#eventual-entry}](#eventual-entry-eventual-entry)
      - [Properties {#properties}](#properties-properties)
      - [Assertions {#assertions}](#assertions-assertions)
      - [Pre Condition {#precondition}](#pre-condition-precondition)
      - [Post Condition {#postcondition}](#post-condition-postcondition)
      - [Fine-Grained Atomicity {#fine-grained-atomicity}](#fine-grained-atomicity-fine-grained-atomicity)
      - [Coarse-Grained Atomicity {#coarse-grained-atomicity}](#coarse-grained-atomicity-coarse-grained-atomicity)
      - [At-Most-Once Property {#at-most-once-property}](#at-most-once-property-at-most-once-property)
      - [Partial Correctness {#partial-correctness}](#partial-correctness-partial-correctness)
      - [Total Correctness {#total-correctness}](#total-correctness-total-correctness)
      - [Mutual exclusion {#mutual-exclusion}](#mutual-exclusion-mutual-exclusion)
      - [Critical Reference {#critical-reference}](#critical-reference-critical-reference)
      - [Critical Section {#critical-section}](#critical-section-critical-section)
    - [Logic](#logic)
    - [Fairness {#fairness}](#fairness-fairness)
      - [Unconditional fairness {#unconditional-fairness}](#unconditional-fairness-unconditional-fairness)
      - [Weak fairness {#weak-fairness}](#weak-fairness-weak-fairness)
      - [Strong fairness {#strong-fairness}](#strong-fairness-strong-fairness)
  - [Locks and Barriers {#locks-barriers}](#locks-and-barriers-locks-barriers)
    - [Locks {#locks}](#locks-locks)
      - [Deadlock {#deadlock}](#deadlock-deadlock)
      - [Livelock {livelock}](#livelock-livelock)
      - [Spinlock {#spinlock}](#spinlock-spinlock)
    - [Fair Solutions Algorithms {#fair-solutions-algorithms}](#fair-solutions-algorithms-fair-solutions-algorithms)
      - [The Ticket Algorithm {#ticket-algorithm}](#the-ticket-algorithm-ticket-algorithm)
  - [Barriers {#barriers}](#barriers-barriers)
    - [Barrier Implementation {#barrier-implementation}](#barrier-implementation-barrier-implementation)
      - [(BAD) Shared counter {#shared-counter}](#bad-shared-counter-shared-counter)
    - [Flags and Coordinator {#flags-and-coordinators}](#flags-and-coordinator-flags-and-coordinators)
    - [Symmetric Barriers {#symmetric-barriers}](#symmetric-barriers-symmetric-barriers)
  - [Semaphores {#semaphores}](#semaphores-semaphores)
    - [Semaphore Definition {#semaphore-definition}](#semaphore-definition-semaphore-definition)
    - [Syntax](#syntax)
    - [Mutual Exclusion With Semaphores {#mutex-semaphores}](#mutual-exclusion-with-semaphores-mutex-semaphores)
    - [Barrier With Semaphores {#barrier-semaphores}](#barrier-with-semaphores-barrier-semaphores)
    - [Split Binary Semaphores {#split-binary-semaphores}](#split-binary-semaphores-split-binary-semaphores)
  - [Monitors {#monitors}](#monitors-monitors)
    - [Monitor Properties {#monitor-properties}](#monitor-properties-monitor-properties)
  - [Monitor-Implementation {#monitor-implementation}](#monitor-implementation-monitor-implementation)
  - [Signalling {#monitor-signalling}](#signalling-monitor-signalling)
    - [C++ Monitor API {#cpp-monitor-api}](#c-monitor-api-cpp-monitor-api)
  - [Alang {#alang}](#alang-alang)
    - [Basics {#alang-basics}](#basics-alang-basics)
      - [Lambda Funcions{#lambda}](#lambda-funcionslambda)
      - [Processes in alang {#ps-alang}](#processes-in-alang-ps-alang)
      - [Indexes Processes {#indexed-processes}](#indexes-processes-indexed-processes)
      - [CO Function {#co-function}](#co-function-co-function)
    - [Atomic Execution {#alang-atomic-execution}](#atomic-execution-alang-atomic-execution)
      - [Critical Sections {#alang-critical-section}](#critical-sections-alang-critical-section)
      - [Atomic Variables {#alang-atomic}](#atomic-variables-alang-atomic)
      - [AWAIT Statement {#alang-await}](#await-statement-alang-await)
    - [SemaphoresÂ {#alang-semaphores}](#semaphores-alang-semaphores)
    - [Monitors {#alang-monitors}](#monitors-alang-monitors)
    - [Channels {#alang-channels}](#channels-alang-channels)
    - [Pointes {#pointers}](#pointes-pointers)
  - [C++ Concurrency {#cpp-concurrency}](#c-concurrency-cpp-concurrency)
    - [Sequential Consistency {#sequential-consistency}](#sequential-consistency-sequential-consistency)
    - [C++ Threads {#cpp-threads}](#c-threads-cpp-threads)
    - [Mutex {#cpp-mutex}](#mutex-cpp-mutex)
    - [Types of mutexes {#cpp-mutex-types}](#types-of-mutexes-cpp-mutex-types)
    - [Examples {#cpp-mutex-examples}](#examples-cpp-mutex-examples)
      - [Try-Lock Recursive mutex example: {#tlrme}](#try-lock-recursive-mutex-example-tlrme)
      - [Timed Mutex Example: {#tme}](#timed-mutex-example-tme)
      - [Shared Mutex Example: {#sme}](#shared-mutex-example-sme)
    - [Mutex-Wrappers {#cpp-mutex-wrapper}](#mutex-wrappers-cpp-mutex-wrapper)
      - [RAII {#raii}](#raii-raii)
      - [lock and lock_guard: {#lock-lockguard}](#lock-and-lockguard-lock-lockguard)
      - [unique_lock {#unique-lock}](#uniquelock-unique-lock)
      - [scoped_lock wrapper {#scoped-lock-wrapper}](#scopedlock-wrapper-scoped-lock-wrapper)
    - [C++ Conditional Variables {#cpp-conditional-variables}](#c-conditional-variables-cpp-conditional-variables)
      - [Thread Local Variables {#thread-local-variables}](#thread-local-variables-thread-local-variables)
      - [Call once {#call-once}](#call-once-call-once)
      - [C++ Atomics {#cpp-atomics}](#c-atomics-cpp-atomics)
      - [Atomic Objects {#atomic-objects}](#atomic-objects-atomic-objects)
      - [Compare and Swap {#compare-and-swap}](#compare-and-swap-compare-and-swap)
      - [Task-Based Parallelism {#task-based-paralellelism}](#task-based-parallelism-task-based-paralellelism)
    - [Futures {#futures}](#futures-futures)
      - [Future Class {#future-class}](#future-class-future-class)
      - [shared_future<T> {#shared-future}](#sharedfuturet-shared-future)
      - [Future Combinators {#future-combinators}](#future-combinators-future-combinators)
      - [future::then {#future-then}](#futurethen-future-then)
    - [Promises {#promises}](#promises-promises)
    - [Async {#async}](#async-async)
    - [Task System Implementations {#task-system-implementations}](#task-system-implementations-task-system-implementations)
    - [Number of threads {#number of threads}](#number-of-threads-number-of-threads)
    - [Compute Primes {#compute-primes}](#compute-primes-compute-primes)
  - [Software Transactional Memory {#stm}](#software-transactional-memory-stm)
    - [Rollback](#rollback)
  - [Message Passing Concurrency](#message-passing-concurrency)
    - [Channel](#channel)
    - [Client-Server with Message Passing](#client-server-with-message-passing)
    - [Synchronouse Message Passing](#synchronouse-message-passing)
  - [Coroutine {#coroutine}](#coroutine-coroutine)
    - [Subroutine {#subroutine}](#subroutine-subroutine)
    - [**Symmetric**](#symmetric)
    - [**Asymmetric**](#asymmetric)
    - [First-class coroutines](#first-class-coroutines)
    - [Generators-Iterators-Coroutines {#iterators}](#generators-iterators-coroutines-iterators)
    - [Coroutine Frame](#coroutine-frame)
    - [Closing coroutines](#closing-coroutines)
    - [Suspending coroutine](#suspending-coroutine)
    - [Resuming coroutine](#resuming-coroutine)
  - [Coding {#coding}](#coding-coding)
    - [**C++ Coding {cpp-coding}**](#c-coding-cpp-coding)
    - [Ticket Algorithm {c++-ticket}](#ticket-algorithm-c-ticket)
    - [Semaphores {#cpp-semaphores}](#semaphores-cpp-semaphores)
    - [Semaphores implementation {#cpp-semaphores-implementation}](#semaphores-implementation-cpp-semaphores-implementation)
    - [Semaphores Banking Problem {#cpp-banking-problem}](#semaphores-banking-problem-cpp-banking-problem)
    - [Monitor {#cpp-monitor}](#monitor-cpp-monitor)
      - [Bridge Crossing Problem {#cpp-bridge}](#bridge-crossing-problem-cpp-bridge)
    - [Message Passing and Channels {#message-passing-channels}](#message-passing-and-channels-message-passing-channels)
    - [Filters With Quicksort {#filters-with-quicksort}](#filters-with-quicksort-filters-with-quicksort)
    - [Saving Account {#savings-account}](#saving-account-savings-account)
## Processes and Synchronization

### Terms

#### State

- A value a variable has at a given time

#### Atomic Action {#atomic-action}

- A sequence of one or more statements that appears to execute as a single, indivisible action

#### Interference {#interference}

- The result of two processes reading and writing the same variable in an unpredictable order

#### Noninterference {#noninterference}

- A relation between an atomic action and a critical assertion C in another process. Executing a does not interfere with c if it leaves c true if c is already true

#### Race Condition {#race-condition}

- A scenario where to processes interacts with a shared variable, causing on process to write to the variable and continue executing. Thus racing ahead before the other process and changes the variable again before the other process sees the result of the first change

#### Unnecessary delay {#unnecessary-delay}

- If a process is trying to enter its critical section and the other processes are executing their noncritical sections or have terminated, the process is not prevented from entering its critical section

#### Eventual Entry {#eventual-entry}

- A process that is trying to enter its critical section, is eventually allowed to succeed

#### Properties {#properties}

- Attribute that is true for every possible history of the program
- **Safety Property**
  - A property where the program never enters a bad state, where the variables have undesired values
- **Liveness Property**
  - A property where the program eventually reaches a good state, variables have desired values

#### Assertions {#assertions}

- An assertion characterises an acceptable program state

#### Pre Condition {#precondition}

- An assertion that is true when statement **S** finishes

#### Post Condition {#postcondition}

- An assertion that is true when statement **Q** finished

#### Fine-Grained Atomicity {#fine-grained-atomicity}

- No intermediate state is visible to the program
- An assignment appears to be atomic since no state from a process is visible to another process

#### Coarse-Grained Atomicity {#coarse-grained-atomicity}

- Atomicity implemented using [critical section](#critical-section) protocols

#### At-Most-Once Property {#at-most-once-property}

- Attribute of an assignment **x = e** where x is not read by another process and e only contains at most one reference to a variable changed by another process, it does contains a [critical reference](#critical-reference), or
- x is not written by another process and e contains no references to a variable changed by another process
- There can be at most one shared variable that can at most be referenced once
- If the assignments meets AMO, it will appear [atomic](#atomic-action)

#### Partial Correctness {#partial-correctness}

- The program is correct if the final state is correct
- If the initial program state satisfies P, then the final state will satisfy Q assuming S terminates

#### Total Correctness {#total-correctness}

- Combines partial correction with termination. A program is totally correct if the program always terminates with the desired results

#### Mutual exclusion {#mutual-exclusion}

- A synchronization ensuring statements in different processes can not execute at the same time

#### Critical Reference {#critical-reference}

- Reference to a variable changed by another process

#### Critical Section {#critical-section}

- A sequence of statements where shared variables are read and written by multiple processes

### Logic

- Formal logic system that allows one to state and prove properties of programs (PL system)
- Formulas of PL are called triples{#triples}

  - Has the form **{P} S {Q}**
  - P and Q are [assertions](#assertions)
  - P is the [pre condition](#precondition) and Q the [post condition](#postcondition)
  - Is true if execution of S has begun in a state satisfying P resulting in Q when the program terminates
  - Executing **S** in state **{P}** == **{Q}**
  - Is [partial correctness](#partial-correctness)

- Hoare tripple
  - **{P} C {Q}**
  - P and Q are [assertions](#assertions)
  - C is the command
  - Provides logical axioms and interference rules causing the command to execute when the [pre condition](#precondition) is met, and establishes the [post condition](#postcondition)

### Fairness {#fairness}

- **An attribute of a program ensuring that every delayed process gets a chance to proceed**
- Concerned with guaranteeing that a process gets a chance to proceed regardless of the other processes
- A process is **eligible**{#eligible} if it is the next [atomic action](#atomic-action) in the process that could be executed
- A scheduling policy determines which process will be executed next

#### Unconditional fairness {#unconditional-fairness}

- A scheduling policy is unconditionally fair if every unconditionally atomic action is eligible for execution eventually

#### Weak fairness {#weak-fairness}

- Unconditionally fair
- Action is continuously enabled and will eventually be executed
- If p holds from a point and on, then q will also hold eventually
- Not sufficient for ensuring every eligible await statement is executed eventually because the condition might change from **true** to **false** while a process is delayed, for this, **strong fairness** is required

#### Strong fairness {#strong-fairness}

- Implies an action has to be continuously enabled infinitely often
- If p holds infinitely often, then eventually q will hold
- If an await statement is present in a program, even though the condition is false, the program will eventually terminate because the condition is infinitely often true

## Locks and Barriers {#locks-barriers}

- The **Goal** is to implement a system satisfying the following properties:
  - **[Mutual Exclusion](#mutual-exclusion)**
  - **[Absence of Deadlock](#deadlock)(Livelock)** ([safety property](#safety-property))
  - **[Absence of Unnecessary Delay](#unnecessary-delay)** ([safety property](#safety-property))
  - **[Eventual Entry](#eventual-entry)**
- The first three are [safety properties](#safety-property)
- The last is a [liveness property](#liveness-property)

### Locks {#locks}

#### Deadlock {#deadlock}

- A state where to processes wait for each other where none gets to execute

#### Livelock {livelock}

- A scenario where a process is waiting for a process to be **true**, that will never become true. Livelock is the busy-waiting analog of deadlock

#### Spinlock {#spinlock}

- A boolean variable used with a busy-waiting to protect a critical section. A process wanting to enter, spins until it is allowed to enter

### Fair Solutions Algorithms {#fair-solutions-algorithms}

#### The Ticket Algorithm {#ticket-algorithm}

- Name based on drawing tickets
- **Practical example:** - Imagine a bakery where customers are served based on their arrival - When a customer arrives, he draws a ticket one larger than the previous customer - The customer waits until all the previous customers are served until it is his turn - Implemented by a number dispenser and a display displaying which customers turn it is - see [C++ Ticket Algorithm](#c++-ticket)

## Barriers {#barriers}

- Two solution to parallel computation:
  - **BAD**: Using CO statements in the body of the iteration depending on the previous iteration and ignoring termination
    - Inefficient because it is costly to the memory to create and destroy processes than to implement process synchronization
  - **GOOD** : Create the processes once at the beginning of the computation, then have them synchronize at the end of each computation.
    - This is what **Barrier Synchronization** is
- Computes disjoints parts of the solution in parallel
- Iterations are dependent of the result of the previous iteration
- Has a delay point(barrier) at the end of each iteration every process has to reach before any is allowed to pass

### Barrier Implementation {#barrier-implementation}

#### (BAD) Shared counter {#shared-counter}

- A counter that is initially 0, and when it reaches the desired n, all processes may pass
  - **AWAIT**
  - **Not Efficient!** since counter has to reset each time all processes pass
  - Can be solved with two counters, but this adds complexity since a process might get delayed examining one of the counters
  - Should only be used if target machine has [atomic](#atomic-action) increment instructions

### Flags and Coordinator {#flags-and-coordinators}

- Solves the memory contention problem from shared counters by implementing count as a sum of n shared values
- Achieved by adding a creating a array of integers **Arrive** and a new set new set of shared variables called **coordinator**
- Instead of having each worker sum and test values, set **Arrive[i]** to 1, each **worker[i]** delays waiting for **continue[i]** to become 1, this only has to wait for a single value to become true
- By calling this single value **continue**(which is an array of integers initialized as 0), a **worker[i]** only has to wait for **continue[i]** to be 1
- The **coordinator** waits for all elements of **arrive** to become 1 before letting before setting all elements of **continue** to be 1
- **Arrive** and **Continue** are examples of **Flag Variables**{#flag-variables}
- A variable raised by one process to signal another that the synchronization is true -

- **Flag Synchronization**{#flag-synchronization}
  - A process that wait for synchronization flag to be set, is the one that should clear the flag
    - Ensures flag is not cleared before it has been seen to be set
  - A flag should not be set until it is known that it is clear
    - Ensures a process not setting the same flag again if it has already been set

### Symmetric Barriers {#symmetric-barriers}

- Each process has a flag it sets when itâs arriving at a barrier. It then waits for the other process to set its flag before clearing the other processes flag
- Communicating with a binary connection
- **Butterfly Barrier:** -
  - Each process communicates with another process at each stage
  - Processes are indirectly synchronized with each other

## Semaphores {#semaphores}

### Semaphore Definition {#semaphore-definition}

- A program variable - Whose value is an integer > 0
- Can **only** be updated
- Controlled by two operations:
  - **P** : Wait for signal -
    - Wait until value > 0, then decrease value by one
  - **V** : Signal an event
    - Increase value by one

### Syntax

```cpp
sem; // init to null
sem s=k; // init to k
sem s[n] = ([n]1); // array of semaphores
```

- By default a semaphore is initialized as 0, but it can be initialized as any non-negative integer
- A **Binary Semaphore** only takes in the values 0 and 1

### Mutual Exclusion With Semaphores {#mutex-semaphores}

```cpp
sem mutex = 1;
process P[i=1 to m]{
 while(true){
 P(mutex);
 CS(critical section)
 V(mutex);
 non-cs
 }
}
```

- Semaphore initially 1, so that one process can enter the [Critical Section](#critical-section)
- **Always** **P**before **V** so value stays <=1
- Use one semaphore for each [synchronization flag](#flag-synchronization)
  - A PS sets a flag by executing **V**
  - Then waits for a flag to be set, and clears it with **P**

### Barrier With Semaphores {#barrier-semaphores}

- Using to signaling semaphores
- Processes signal their arrival by executing a **V** operation on its own semaphore, then waiting for another process and executing a **P** operation on its semaphore
- Typical signaling pattern:

```cpp
sem arrive1 = 0, arrive2 =0;
process P1 {
 V(arrive1) // signal arrival
 P(arrive2) // wait for other process
}
process P2{
 V(arrive2) // signal arrival
 P(arrive1) // wait for other process
}
```

- semaphores initialized to Ã
  - signal event **V**
  - wait for event **P**

### Split Binary Semaphores {#split-binary-semaphores}

- A set of semaphores where the **sum** of values <= 1
- [Mutual Exclusion](#mutual-exclusion) of many PSâs, guiding which one can execute
  - Initialize one semaphore to 1, other to Ã
  - Ensure that on every execution **P(s1)** is followed by **V(s2)** for some of the semaphores s1, s2
  - All statements between **P(s1)** and **P(s2)** is executed in mutual exclusion
- Has a shared buffer
- **Empty** and **Full** are two semaphores indicating if the buffer is full or empty

```cpp
typeT buf; // buffer of some type T
sem empty = 1, full = 0;

process Producer[i = 1 to m] {
 while(true){
  â¦
  // produce some data and deposit it in the buffer
  P(empty);
  buf = data;
  V(full)
 }
}
process Consumer[i = 1 to m] {
 while(true){
  â¦
  // fetch result, then consume it
  P(full);
  result = buf;
  V(empty)
  }
 }


```

## Monitors {#monitors}

### Monitor Properties {#monitor-properties}

- Thread safe abstract data type with synchronization
- Encapsulates representation of an abstract object
- Allows implicit [mutual exclusion](#mutual-exclusion)(at most one process can execute a function at any given time) and wait condition
- Has a [mutex lock](#mutex-lock) and conditional variables
- Threads wait for certain conditions to be met
- Processes are active, while monitors are passive

- **Monitor invariant**
  - Predicate that is true when no procedure is running, describes the valid good states
    - When an object is in a valid state, the class invariant holds
    - Must hold after initialization, when procedure terminates and when wait suspends executing
    - Assumes to hold at the beginning of procedure and after wait

## Monitor-Implementation {#monitor-implementation}

monitor m {
<br> permanent variables // shared by all processes
<br> initialization
<br> procedures // public
<br>}

## Signalling {#monitor-signalling}

- if cvâs queue is empty, no effect
- wake up a ps
- when ps calls signal, it is inside a monitor, making it two active psâs: current and the one being awakened

- Two strategies for ps to not run simultaneously
  - Signal and continue (SC), signaller continues running
  - Signal and wait (SW), signalled starts executing

### C++ Monitor API {#cpp-monitor-api}

- cond cv; // declaration
- empty(cv); // check if empty queue
- wait(cv); // make ps wait in cvâs queue
- signal(cv); // wake up a ps in cvâs queue
- signal_all(cv); // wake up all ps in cvâs queue

## Alang {#alang}

### Basics {#alang-basics}

- **compile with :**
  - -std=c++2a

#### Lambda Funcions{#lambda}

```cpp
[&, i, j, k] { /* body that uses i, j, and k */ }

```

#### Processes in alang {#ps-alang}

```cpp
processes ps; // ps will hold all processes

  ps += [&] { // define a task and start executing it
    while (x == 0);
```

#### Indexes Processes {#indexed-processes}

```cpp
int sum = 0;
{   // note this extra scope
    processes ps;

    for (int i=0; i<10; ++i) ps += [&,i]{ sum = sum + i; };
  } // ps goes out of scope here. Execution waits until all processes finished

  cout << "Sum is = " << sum << endl;
```

#### CO Function {#co-function}

```cpp
int x = 0;

  for (int i : range(0, 1000000))
    CO([&]{ x = x + 1; }, [&]{ x = x + 1; });

  cout << x << endl;

```

### Atomic Execution {#alang-atomic-execution}

#### Critical Sections {#alang-critical-section}

- [Definition](#critical-section)

```cpp
processes ps;
  for (int i : range(0, 10)) ps += [&, i] {
    enter_critical;
    cout << i << "+" << i << "=" << i+i << endl;
    exit_critical;
  };
```

#### Atomic Variables {#alang-atomic}

- [Definition](#atomic-action)

```cpp
 A<int> x = 0; // must use A<int>; otherwise ATOMIC has no effect

  for (int i : range(0, 100000))
    CO([&]{ ATOMIC([&]{x = x + 1;}); },
       [&]{ ATOMIC([&]{x = x + 1;}); },
       [&]{ ATOMIC([&]{x = x + 1;}); },
       [&]{ ATOMIC([&]{x = x + 1;}); });

  cout << x << endl;
```

```cpp
 A<int> x;
  ATO
    x = 1;
    return;
    x = 2;
  MIC;
  cout << x << endl;
```

#### AWAIT Statement {#alang-await}

```cpp
A<int> x = 0;
  CO([&]{ ATO AWAIT (x == 100); x = -100; MIC; },
     [&]{ ATO while (x < 100) x = x + 1; MIC; });
  alang::logl(x);
```

### SemaphoresÂ {#alang-semaphores}

- [Definition](#semaphore-definition)

```cpp
semaphore sem1;     // declare a semaphore, initialize to 0
semaphore sem2 = 1; // declare a semaphore, initialize to 1

sem1.P(); // P operation
sem1.V(); // V operation
```

```cpp
semaphore sem;

  CO([&]{ cout << "Waiting... "; sem.P(); cout << "Got through." << endl; },
     [&]{ sleep(1s); cout << "Releasing... "; sem.V(); });
```

### Monitors {#alang-monitors}

- [Definition](#monitor)

```cpp
class semon : monitor {
  cond cv; // declare a condition variable in the monitor
  int s;   // semaphore's value
public:
  semon(int s=0) : s(s) { if (s<0) throw "bad semaphore"; }

  void P() {
    SYNC;
    while (s == 0) { wait(cv); }
    s = s - 1;
  }

  void V() {
    SYNC;
    s = s + 1;
    signal(cv);
  }

  int value() { SYNC; return s; } // not part of the semaphore API. Added so we can test.
};

int main() {
  semon s = 0;
  {
    processes ps;
    ps += [&s]{            for (int i=0; i<100; ++i) s.P(); };
    ps += [&s]{ sleep(1s); for (int i=0; i<200; ++i) s.V(); };
  }
  alang::logl(s.value());
}
```

```cpp
class m1 : monitor {
public:
  void f() { SYNC; }
  void g() { SYNC; f(); } // cannot call another procedure that is SYNCed
}

class m2 : monitor {
  helper() { /* do some work */ }
public:
  void f() { SYNC; helper(); } // ok
  void g() { SYNC; helper(); } // ok
}
```

### Channels {#alang-channels}

- [Definition](#channel)

```cpp
channel<int> c1;
channel<int, string> c2;
channel<vector<int>> c3;
channel<channel<int>*> c4;
```

```cpp


#include "alang.hpp"
using alang::channel;

int main() {
  channel<channel<int>, int> request;

  processes ps;

  // a server that doubles an integer
  ps += [&request]{
    channel<int> cr; // the channel for the response from the server
    int i;
    request.receive(cr, i);
    cr.send(2*i);
  };

  // a client process
  ps += [&request]{
    channel<int> c; int i;
    request.send(c, 1);
    c.receive(i);
    logl(i);
  };
}
```

### Pointes {#pointers}

```cpp
int x = 10;
int& y = x; // y refers to x, y and x are aliased
int z = y; // z = 10, z is not aliased with x or y
```

## C++ Concurrency {#cpp-concurrency}

- A memory model defines the semantics of shared variables
  - A set of guarantees about the order a program reads and writes are observed by a thread
    - âRulesâ a programmer has to follow when writing concurrent code
- **Threads**
  - Multiple threads can access the same shared variables
  - Each thread has its own local variables

### Sequential Consistency {#sequential-consistency}

- The result of an execution is the same for any order the operations from a processor
  - A sequential processor does **NOT** guarantee sequential consistency
  - Each processor issues memory requests
  - Processed from a FIFO(first-in, first-out) queue
  - If a program has no [data races](#race-condition), it is sequentially consistent
  - If else its behaviour is undefined
  - None of todays architecture is sequential consistent \* Because of performance optimization in hardware and

### C++ Threads {#cpp-threads}

- Each instance of the **thread** class represents threads of execution
- Communicates through shared variables
- Only terminates from inside program, not outside
- Creating a thread object:

```cpp
void print(string s1, string s2) {
cout << s1 << s2; }
std::thread t1([]() {
cout << "Hello"; });
std::thread t2(print, ", ", "World!");
```

- A thread may be joinable
  - A joinable thread is potentially executing
  - A not joinable thread is not executing
  - Only not joinable threads can be safely destroyed
  - Destructor of thread calls **std::terminate()**
- Example of joining thread:

```cpp
#include <iostream>
#include <thread>
void print(string s1, string s2) { cout << s1 << s2; }

int main() {
 std::thread t1([]() {cout << "Hello"; });
 std::thread t2(print, ", ", "World!");
 t1.join();
 t2.join();
 return 0;
}
```

- Example of **NOT** joining threads:

```cpp
#include <iostream>
#include <thread>
void print(string s1, string s2) { cout << s1 << s2; }
int main() {
 std::thread t1([]() { cout << "Hello"; });
 std::thread t2(print, ", ", "World!");
 //    t1.join();
 //    t2.join();
 return 0;
}
```

- Same example in alang:

```cpp
#include "alang.hpp"
void print(string s1, string s2) { cout << s1 << s2; }
int main() {
 processes ps;ps += []() {
 cout << "Hello";
 };
  ps += []() {
  print(", ", "World!");
  };
  return 0;
 }
```

- Helper function:

```cpp
void pause_thread_s(int n) {
 std::this_thread::sleep_for(std::chrono::seconds(n));
}
void pause_thread_ms(int n) {
 std::this_thread::sleep_for(std::chrono::milliseconds(n));
}
```

- this_thread:
  _get_id gets threads id
  _ yield hints to the scheduler to reschedule

- **detach()** lets a thread âlooseâ
- thread object becomes not joinable
- Example, removing âWorld!â:

```cpp
void print(string s1, string s2) { cout << s1 << s2; }
int main(){
 std::thread([]() {
 pause_thread_s(2);
 std::cout << "Hello";}).detach();
 std::thread(print, ", ", "World!").detach();
 pause_thread_s(1);
}
```

- Thread constructor parameters:

```cpp
template <class Fn, class... Args>
explicit thread (Fn&& fn, Args&&... args);
```

- Unhandled exceptions on thread terminates a program

### Mutex {#cpp-mutex}

- C++ protects access to shared data with:
  - [Mutexes](#mutual-exclusions)
  - [Locks](#locks)
  - [Atomics](#atomic-action)
- Mutual exclusion object
  - Thread gets ownership of a mutex by locking and releases it by unlocking
  - Member functions
  - **lock()** - block until mutex is available, the lock and continue
  - **try_lock()** - lock if available, otherwise false
    - **unlock()** - release ownership
- Code example:

```cpp

int acc = 0;
mutex acc_mutex;
void acc_square(int x) {
 int tmp = x * x;
 acc_mutex.lock();
 acc += tmp;acc_mutex.unlock();
 }
int main() {
 map<int, int> m;
 for (int j=0; j<1000; ++j) {
 acc = 0;
  vector<thread> ts;
  for (int i = 1; i <= 10; i++)
  ts.push_back(thread(acc_square, i));
  for (auto& t : ts) t.join();
  if (m.count(acc) == 0)
   m[acc] = 1;
    else m[acc]++;
    }
    for (auto kv : m)
    cout << "acc=" << kv.first << ": " << kv.second << " times\n";
  }
```

### Types of mutexes {#cpp-mutex-types}

- **Recursive mutex**
  _ Can be locked repeatedly by the same thread
  _ Released when unlocked the same amount of times
- **Timed Mutex**
  - Only wait for a locked mutex a limited amount of time before it gives up
- **Shared-timed-mutex, shared-recursive-mutex**:
  _ Shared and exclusive access
  _ Use full when there is a lot of read activity, but writing has to be exclusive

### Examples {#cpp-mutex-examples}

#### Try-Lock Recursive mutex example: {#tlrme}

```cpp
class counter {
 recursive_mutex mut;
 int c = 0;
 public:void tick() {
   mut.lock();
    ++c;
    mut.unlock();
    }
 void tickManyIfCan(int n) {
 if (mut.try_lock()) {
 while (n-- > 0) tick();
 mut.unlock();
  }
 }
 int value() {
 return c;
  }
 };
 void task(counter& ctr) {
 for (int i=0; i<100; i++) {
 pause_thread_ms(1);
 ctr.tickManyIfCan(10);
  }
 }
 int main() {
 counter ctr;
 thread t1(task, ref(ctr)), t2(task, ref(ctr)), t3(task, ref(ctr));
 t1.join(); t2.join(); t3.join();
 cout << "\nvalue = " << ctr.value();
 }
```

#### Timed Mutex Example: {#tme}

```cpp
timed_mutex mut;
 void attempt (atomic<int>& successes) {
  if (mut.try_lock_for(chrono::milliseconds(50))) {
  // now we have the lock
  ++successes;
  pause_thread_ms(2);
  mut.unlock();
 }
}
 void run() {
  thread ts[100];
   atomic<int> successes = 0;
   for (int i=0; i<100; ++i)
   ts[i] = thread(attempt, ref(successes));
   for (auto& t : ts)
   t.join();
   cout << "#successes = " << successes << endl;
  }
 int main() {
  run(); run(); run();
 }
```

#### Shared Mutex Example: {#sme}

```cpp
 td::shared_mutex
  s_mut;
  timer tm;
  void reading(const string& data, int secs) {
   s_mut.lock_shared();
   pause_thread_s(secs);
   alang::logl("Reader ", data, " ", tm.elapsed());
   s_mut.unlock_shared();
 }
  void writing(string& data, string d, int secs) {
   s_mut.lock();
   pause_thread_s(secs);
   data = d;
   s_mut.unlock();
   alang::logl("Writer ", d, " ", tm.elapsed());
  }
  int main() {
   string data = "A";
   vector<thread> ts;
   tm.reset();
   ts.emplace_back(reading, cref(data), 3);
   ts.emplace_back(reading, cref(data), 4);
   ts.emplace_back(writing, ref(data), "B", 1);
   ts.emplace_back(writing, ref(data), "C", 2);
   ts.emplace_back(reading, cref(data), 0);
   for (auto& t : ts) t.join();
 }
```

### Mutex-Wrappers {#cpp-mutex-wrapper}

#### RAII {#raii}

```cpp
int c;
mutex cm;
 ...
 {
 lock_guard<mutex> lock(cm); // mutex locked here
 foo(c);
 } // unlocked here when lock destroyed

```

#### lock and lock_guard: {#lock-lockguard}

- Adopts an already locked mutex \* **std::lock()** takes a given number of mutexes and locking them without [deadlocking](#deadlock)

```cpp
container a, b; // assume both have mutex member variable
{
 std::lock(a.mutex, b.mutex);
 lock_guard<mutex> l1(a.mutex, std::adopt_lock_t);
 lock_guard<mutex> l2(b.mutex, std::adopt_lock_t);
 a.put(b.get()); // maybe exceptions
 } // locks released here

```

#### unique_lock {#unique-lock}

- Can be given more policies
  - **adopt_lock_t**
  - **defer_lock_t**
  - **try_to_lock_t**
- or a duration or time point
  - For how long or wait time to acquire lock
- Moveable, transfers the mutex
- Unlocking and re locking possible

```cpp
container a, b; // assume both have mutex member variable
{
 unique_lock<mutex> l1(a.mutex, defer_lock_t);
 unique_lock<mutex> l2(b.mutex, defer_lock_t);
 lock(l1, l2);
 a.put(b.get());// maybe exceptions
 }// locks released here

```

#### scoped_lock wrapper {#scoped-lock-wrapper}

- Easiest mutex lock
- Can wrapt multiple mutexes from the constructor without deadlocking

```cpp
std::mutex m1, m2, m3;
 ...
{
 std::scoped_lock lock(m1, m2, m3);
 // critical section
} // mutexes released here (in reverse order)
```

- Mutexes can be different types
- No need to specify mutex types(C++17âs class template argument deduction)

### C++ Conditional Variables {#cpp-conditional-variables}

- Allows blocking a thread until notified
- Waiting methods from the **conditional variable** class puts the thread to sleep, to start waiting for a conditional variable
  - **void wait(unique_lock<mutex>);** see [unique-lock](#unique-lock)
  - **void wait_for(unique_lock<mutex>, chrono::duration<â¦>);** see [unique_lock](#unique_lock)
  - **wait_until(unique_lock<mutex>, chrono::time_point<â¦>);**
- A thread starts waiting holding a lock, and wakes up holding a lock
  - unique_lock associated with a mutex
- Notifies threads with:
  - **void notify_one()**
  - **void notify_all)()**
- **Spurious wakeup**
  - Scheduler can wake up threads without a calling notifying function

- Example:

```cpp
#include <condition_variable>
mutex mut;
condition_variable cv;
int resource = 0;
void worker (int amount) {
 unique_lock<mutex> lock(mut);
 while (amount > resource) cv.wait(lock);
 resource -= amount;
 cout << "Handled  " << amount << ", remains " << resource << endl;
 }
int main ()  {
 thread ts[10];
 for (int i = 0; i < 10; ++i)
  ts[i] = thread(worker, i);

  {
   unique_lock<mutex> lock(mut);
   pause_thread_s(1);
   resource = 100;} // unlock here
   cv.notify_all();
   for (auto& t : ts) t.join();
  }
```

#### Thread Local Variables {#thread-local-variables}

- **thread_local** \* Each thread has an instance of thread_local variable
- Allocated when a thread begins and Deallocated when it terminates
- Can be namespace scope, block scope or static member variables

#### Call once {#call-once}

- Allocates a piece of code to a single thread
- **call_once()**

```cpp
template< class Callable, class... Args >
void call_once(std::once_flag& flag, Callable&& f, Args&&... args);
```

- Each call of call_once with the once_flag defines a group
  - Other threads block on **call_once()** so that once thread at a time can execute until the flag is set

#### C++ Atomics {#cpp-atomics}

- **atomic<T> x**
  _ **T** cannot be arbitrary type, used for integral and pointer types
  _ Can be created an instance trivially copy type
  _ Can be implemented with hardware lock-free atomic opâs or:
  _ implemented using mutexes

#### Atomic Objects {#atomic-objects}

- **Atomic assignment**
  - T operator=(T)
  - void store(T, memory_order = std::memory_order_seq_cst)
- **Atomic read**
  - operator T() const
  - T load(memory_order = std::memory_order_seq_cst) const
- **Atomic Swap**
  - T exchange(T, memory_order = std::memory_order_seq_cst)
- **Compare-and-swap**
  - bool compare_exchange_weak (T& expected, T desired, ...)
  - bool compare_exchange_strong(T& expected, T desired, ...)
    - (the...stands for memory order parameters)
- **Atomic bit manipulation and arithmetic for those T that make sense**
  - fetch_and,fetch_or,fetch_xor,fetch_add,fetch_sub

#### Compare and Swap {#compare-and-swap}

```cpp
bool atomic<T>::compare_exchange_weak(T& expected, T desired);
```

- Use in a loop for as long as the value is expected

#### Task-Based Parallelism {#task-based-paralellelism}

- Abstracts over OS thread
  - Because OS threads are more expensive
  - Decomposed into independent **tasks**
- Tasks are determined from **dependency graphs**
  - **Future/Promised** and [**async**](#async) creates these graphs
  - **Promise and Future** are basic building blocks
  - A packaged task wraps any function object with a promise-future channel
  - A **Future object** is attached to the wrapped function object
  - Calling the object resolves the promise with **set_value**
  - Exception sets with **set_exception** \* **async** abstracts over a packaged task
- **Implementation ideas:**
  - **Thread pools**
  - **Work stealing**
  - Idle PSâs steal tasks from another PSâs queue
  - Tasks should be freely migrated between threads

### Futures {#futures}

- Delayed value that promises that eventually a value will exist

    ```cpp
    future<int> f = async([]{ return hailstone(9780657631) });
    ```

- A future can be queried when a value is required \* Could be blocking until value is not available yet

    ```cpp
     if (f.get() == 1) { ... }
     ```

- A placeholder for a result of a computation
  - **Three States**
    - Pending: Future has no value yet
    - Fulfilled: The future value has been achieved
    - Rejected: The future never got it's expected value

#### Future Class {#future-class}

- **template<class T> class future;**
  - Tis the type of the result (can be void)
  - T must beMoveConstructible
  - future<T>cannot be copied, only moved
- **void wait() const;**
  - blocks until futureâs result available
  - also wait_for() and wait_until()
- **T get();**
  - blocks until result available, then returns it
  - get can only be called once
- **bool valid() const;**
  - has the value not been queried? (with get or share)
  - does the future have a shared state
- **std::shared_future<T> share();** \
  - gets the value and moves the futureâs value to a shared future

#### shared_future<T> {#shared-future}

- Same as **future<T>** but can be copied
  - Many threads can wait
- Construct shared_future object for each shared state
- Example:

```cpp
void detect(int x, shared_future<int> y) {
 static std::mutex iom;
 if (x == y.get()) {
  unique_lock l(iom);
   cout << "Found " << x << endl;
   } else {
   unique_lock l(iom);
    cout << "Expecting " << x << endl;
    }
 }

int main() {
 promise<int> p;
 shared_future<int> f = p.get_future().share();
 for (int j=0; j<10; ++j)
  thread(detect, j, f).detach();
  pause_thread_s(1);
  p.set_value(7);
  pause_thread_s(1);
 }
```

#### Future Combinators {#future-combinators}

- **when_any**
  - Wait until at least one of a set of futures is ready:

   ```cpp
   auto f_or_g = when_any(async(f), async(g)); f_or_g.then([](future<int> f) { ... });
   ```

- **when_all**
  - Wait until all futures of a set is ready:

  ```cpp
  future<tuple<future<int>, future<int>>> f_and_g = when_all(async(f), async(g));
  future<int> futf, futg; tie(futf, futg) = f_and_g.get(); // blocks
  cout << futf.get() + futg.get();// does not block
  ```

#### future::then {#future-then}

- Used instead of blocking with **get** until a future is ready \* Does not block
- Example:

```cpp
#include <future>
using namespace std;
 future<int> f1 = async([]{ return hailstone(12342342); });
 future<string> f2 = f1.then(
 [](int i) { return to_string(i); }
 };

 cout << f2.get();
}

```

### Promises {#promises}

- Object
- Promise -> Future is a one-off communication channel
  - Together has a shared state
  - Ready flag
  - Eventual result or exception when ready
  - Only one future per promise
  - **get_future** can be called once
  - or [shared_future](#shared-future)
  - **set_value, set exception**
  - set ready flag and value/exception
  - unblock threads waiting for promise
  - Destruction a promise
  - Gives up shared state
  - Deletes if no future waiting
    - Else throws **broken_promise**
- Synchronized with **set_value** and **set_exception**
  - e.g futures **get** and **wait**

### Async {#async}

Two **Overloads:**

```cpp
// 1
template<class Function, class... Args>
std::future<typename std::result_of<Function(Args...)>::type>
async(Function&& f, Args&&... args);

// 2
template< class Function, class... Args >
std::future<typename std::result_of<Function(Args...)>::type>
async(std::launch policy, Function&& f, Args&&... args);

```

- Launch policy:
  - **launch::async** executes a new thread with thread locals initialized
  - **launch::deferred** executes in the same thread at a **get()** call

### Task System Implementations {#task-system-implementations}

- Determine the benefits of multithreading
  - **Amdahlâs Law:**
  - $ S(n) = \frac{1}{1-p + \frac{p}{n}} $
  - S is theoretical speedup
  - n is the factor of increase in resources(number of cores)
    - p is the portion benefitting from the resources(unit is time)

- Returning out results is a way for tasks to communicate
  - **async** schedules a packaged task and returns a future
  - future becomes **ready** when task completes

- All following examples assumes these are included:

```cpp
#include <thread>
#include <mutex>
#include <deque>
#include <vector>
#include <unordered_map>
#include <functional>
#include <algorithm>
#include <string>
#include <future>
#include <type_traits>
using std::forward;
using std::move;
using std::function;
using std::thread;
using std::string;
using std::future;
using lock_t = std::unique_lock<std::mutex>;
```

### Number of threads {#number of threads}

- **thread::hardware_concurrency()**
  - May provide the number of cores currently in our system
- Number of threads allocated for the task affects speedup

```cpp
unsigned int number_of_threads() {
 return std::min(
 32u,
 std::max(1u, thread::hardware_concurrency()));
 }
```

### Compute Primes {#compute-primes}

```cpp
#include "task-system-utilities.hpp"

class notification_queue {
 std::deque<function<void()>> _q;
 std::mutex                   _mutex;
 std::condition_variable      _ready;
 bool                         _done = false;
  public:
   void done() {
    {
  lock_t lock(_mutex); _done = true;
     }
  _ready.notify_all();
   }

   bool pop(function<void()>& f) {
    lock_t lock(_mutex);
    while (_q.empty() && !_done) _ready.wait(lock);
    if (_q.empty()) return false;
    f = move(_q.front());
    _q.pop_front();return true;
   }
   template <typename F> void push(F&& f) {
    {
      lock_t lock(_mutex);
      _q.emplace_back(forward<F>(f));
      }
     _ready.notify_one();
   }
  };

class task_system {
 const unsigned int  _nthreads;
 std::vector<thread> _threads;
 notification_queue  _q;
 void run() {
  while (true) {
   function<void()> f;
   if (!_q.pop(f)) break; // !
   f();
   }
  }
 public:
  task_system(int nthreads = 0)
  : _nthreads(nthreads > 0 ? nthreads : number_of_threads())
  {
  for (unsigned int n = 0; n < _nthreads; ++n) {
  _threads.emplace_back([&]{ run(); });
  }
 }
 ~task_system() { _q.done(); for (thread& t: _threads) t.join(); }
 template <typename F>
 void async(F&& f) { _q.push(forward<F>(f)); }
};

bool is_prime(long num) {
 long limit = sqrt(num);
 if (num < 2) return false;
 for (long i=2; i<=limit ; i++) {
 if (num % i == 0) return false;
 } return true;
}

std::atomic<int> found = 0;
int count_primes(long n) {
 int count = 0; while (n-- > 1) { if (is_prime(n)) ++count; }
 return count;
}

const int ntasks = 4096;
void test(int nthreads) {
 double time;
  timer tmr;
  {
   task_system ts(nthreads);
   for (int i=0; i<ntasks; ++i)
    ts.async([&]{ found += count_primes(1000);  });
    }
  time = tmr.elapsed();
  logl("time ", time, " using ", nthreads, " threads");
 }

int main() {
 for (int n = 1; n <= 2048; n *= 2)
 test(n);
 test(thread::hardware_concurrency());
}
```

- **lock_t** is defined as **[std::unique_lock<std::mutex>](#unique-lock)**

- **front** accesses the first element, **pop_front** discards it
- Functions are moved, not copied

## Software Transactional Memory {#stm}

- Declare blocks of code that should execute atomically
- No locks
- Threads write without regard for other threads
- Keeps log of memory read/write
  - Logs are read after execution and compared to the memory
  - If execution has changed, the transaction is rolled back
  - Otherwise commited
- Good for programmer because
  - No need to keep track of locks(unless implemented)
  - No deadlock

- **Pros**
  - [Fine-Grained](#fine-grained-atomicity)
  - Good performance in dist. inviroments
- **Cons**
  - Performance could be a lot worse than locking

### Rollback

- **Occurs**
  - On Read
    - if variable is locked
    - Version greated than rv
- On commit
  - If any log variable can not be loacked
  - If any log variable locked or version higher than rv

## Message Passing Concurrency

- **Distributed Memory Architectures**
  - Processors has private memory
  - Connects with other PS's with **interconnect** network
  - Processes communicate by sending messages and recieving messages through **shared channels**
    - Via **RPC** og **rendez-vous**
    - Big Picture:

    ```cpp

                                        (implicit mutual exclusion)
                                     --> [Monitors]        -->
    [Busy Waiting] --> [Semaphores]                             [RPC/Rendez-vous]
                                     --> [Message Passing] -->
                                        (each semaphore carries data)

    ```

### Channel

- Communication path between processes
- chan c(type1, id1,....,typen,idn)

- ```cpp
    chan c1(int acc-id, int ctr, int amount)
    ```

- **Primitives**
  - Send
    - c(e1,e2,....,en)
    - Channel has c Space
    - Blocks if channel is full
  - recieve
    - c(var1,var2,...,varn)
    - Removes the message if C has atleast one
    - Blocks if empty
  - empty(c)

- **Channel abstraction**
  - One way
  - FIFO Queue
  - Atomic access to queue
  - Error-free
  - Typed

- **Filters**
  - One-way interaction pattern
  - A PS who recieves message from input channel
  - Sends to output(function of input and initial state) channels

### Client-Server with Message Passing

```cpp
    chan request(int clientID, typesofinpit);
    chan reply[n] (typesofresults)
    Process Server{
        int clientID;
        // initializstion, permanent variables
        while(true){
            recieve request(clientID, input values);
            // body
            send reply[clientID, result values]
        }
    }
    process client[i=0 to n-1]{
        send request(i,args);
        recieve reply[i] (res_args)
    }
    monitor Server{
        permanenet variables;
        initialization code;
        procesdure op(input_args){/* body; */ }
    }
```

### Synchronouse Message Passing

- **Sync_Send**
  - c(e1,e2,....,en)
  - Blocks until message is recieved
  - Sender and reciever synchroniza on sending and recieving a message
- **Perks**
  - Fixed channel size(no memory for message data)
    - At most one pending recieves message
    - At most one undelievered message
- **Draws**
  - Reduced parallelism
  - Higher [deadlock](#deadlock) risk
    - Deadlock example:

    ```cpp
    chan in1(int),in2(int);
    process P1{
        int v1,v2 = 1;
        sync_send
    }
    process P2 {
        int v1,v2 = 2;
        sync_send in1 (v2);
        recieve in2(v1):
    }


    ```

## Coroutine {#coroutine}

- Control abstraction for co-operative, or non-preemptive multitasking
- Generalization of [subroutines](#subroutine)
  - Suspending the execution
  - Resuming a suspended execution
- Coroutines are in progress simultaneously, but not executed at the same time

- Five transfer of control events:
  - Call
    - Activation frame/record pushed on to the stack
  - Return
    - Activation frame/record is popped from the stack
  - Suspend
    - Suspends execution, saves the frame/record, remembers the current point and transfer execution back to caller
  - Resume
    - Restores saved frame/record
  - Destroy
    - Deallocates saved frame/record

- Corollary: activation frame lifetime are not nested
  - Heap allocation

- Can run asynchronously with caller
- Caller can wait for suspension/return

```javascript
function* primes() {
    let primes = [];
    let c = 2;
    while (true) {
        let composite = false;
        for (let p of primes) {
            if (c % p == 0) {
                 composite = true;
                  break;
                   }
                  }
                  if (!composite) {
                      primes.push(c);
                       yield c;
                    }
                    ++c;
            }
    }
let p = primes();
while (true) {
    let r = p.next();
    if (r.value > 20) break;
    console.log(r.value);
    }

```

### Subroutine {#subroutine}

- Has a call and return

- Call
  - Pushes a new frame to stack
  - Suspends caller
  - jumps to the beginning of the function
- Return
  - passes return value to caller
  - Pops the frame
  - Resumes callerâs execution

- Has register for top of stack and allocates/deallocates(modify) the top of the stack

### **Symmetric**

- Singe control transfer operator that specifies target

### **Asymmetric**

- Similar to subroutines, transferred back to caller
- Symmetric/Asymmetric equally expensive, so can emulate each other

### First-class coroutines

- âBehaves like any value
- Can be store in variable
- Passed as parameter
- Returned from function
- Be yielded

- **Stackfull**
  - coroutines can suspend in nested functions
- **Stackless** coroutines can only suspend at top level
  - Must create new coroutine layer

### Generators-Iterators-Coroutines {#iterators}

- Is iterator if it implements next() with:
  - no arguments
  - returns object p such that
    - p.done : boolean
  - if p.done == false, then p.value is returned by the iterator

- An object is iterable if it has the computed property [Symbol.iterator], which is a nullary function returning an iterator

### Coroutine Frame

- Located in the iterator object
- Local variables are iterator objectsâs member variables

### Closing coroutines

- Breaking out of the iterator loop, closes the iterator
- Generators are close able iterators
- Resources can be cleansed at close
- Generators/Iterators are iterables and iterators

### Suspending coroutine

- yield communicates data from a coroutine to its caller when the coroutine is suspended
- yield e also receives data when coroutine resumed

### Resuming coroutine

- yield e is an expression, its value is the value sent to coroutine when it is resumed
- yield e can resume with an exception sent from its caller(ASYNC/AWAIT)

- Functions defined as async can contain await statements
- await e evaluates e to a promise, and waits until the promise is resolved
- The resolved promiseâs value is the value of the expression await e
- A rejected promise turns into an exception

## Coding {#coding}

### **C++ Coding {cpp-coding}**

### Ticket Algorithm {c++-ticket}

- [Explanation of the algorithm](#ticket-algorithm)

```cpp
#include "alang.hpp"
#include <vector>
using namespace std;

const int n = 4;
const int nCustomers = 4; // this many customers
const int nRounds = 5;    // each use service this many times
A<int> current_number = 0, next_served = 0;

int take_ticket_and_wait(int i)
{
    // take a ticket, print the received ticket number, and block until it is your turn
    // return the recived ticket number
    int myturn;
    ATO myturn = current_number;
    current_number = current_number + 1;MIC;
    alang::log("\nProcess ", i, " got turn: ", myturn);
    ATO AWAIT(myturn == next_served);MIC;
    return myturn;
}

void release_ticket()
{
    // let the next process proceed
    ATO next_served = next_served + 1; MIC;
}

int main()
{
    {
        processes ps;

        for (int i : range(0, nCustomers))
        {
            ps += [&, i] {
                for (int j : range(0, nRounds))
                {
                    int turn = take_ticket_and_wait(i);
                    // Perform task
                    alang::logl("\nProcess ", i, " runs on turn ", turn);
                    release_ticket();
                }
            };
        }
    }
}
```

**Output:**
<br>Process 1 got turn 0
<br>Process 0 got turn 1
<br>Process 2 got turn 2
<br>Process 3 got turn 3
<br>Process 1 runs on turn 0
<br>Process 1 got turn 4
<br>Process 0 runs on turn 1
<br>Process 0 got turn 5
<br>Process 2 runs on turn 2
<br>Process 2 got turn 6
<br>Process 3 runs on turn 3
<br>Process 3 got turn 7
<br>Process 1 runs on turn 4
<br>Process 1 got turn 8
<br>Process 0 runs on turn 5
<br>Process 0 got turn 9
<br>Process 2 runs on turn 6
<br>Process 2 got turn 10
<br>Process 3 runs on turn 7
<br>Process 3 got turn 11
<br>Process 1 runs on turn 8
<br>Process 1 got turn 12
<br>Process 0 runs on turn 9
<br>Process 0 got turn 13
<br>Process 2 runs on turn 10
<br>Process 2 got turn 14
<br>Process 3 runs on turn 11
<br>Process 3 got turn 15
<br>Process 1 runs on turn 12
<br>Process 1 got turn 16
<br>Process 0 runs on turn 13
<br>Process 0 got turn 17
<br>Process 2 runs on turn 14
<br>Process 2 got turn 18
<br>Process 3 runs on turn 15
<br>Process 3 got turn 19
<br>Process 1 runs on turn 16
<br>Process 0 runs on turn 17
<br>Process 2 runs on turn 18
<br>Process 3 runs on turn 19

### Semaphores {#cpp-semaphores}

- See [semaphores](semaphores)

### Semaphores implementation {#cpp-semaphores-implementation}

```cpp
#include "alang.hpp"

class barrier
{
    alang::semaphore arrive, depart;
    int ctr, n;

public:
    barrier(int n) : arrive(1), depart(0), ctr(0), n(n) {}

    void set(){
        arrive.P();
        if(ctr > n){
            arrive.V();
        } else {
            depart.V();
        }
        depart.P();
        if(ctr > 0){depart.V();}
             else{
                 arrive.V();
             }
        }
};

void launch_processes(processes &ps, barrier &b, int stages, int n){
    for (int i = 0; i < n; ++i)
    {
        ps += [&, i, stages] {
            for (int s = 0; s < stages; ++s)
            {
                logl("Stage ", s, ", process ", i);
                b.set();
            }
        };
    }
}
int main(){
    {
        barrier b(4);
        processes ps;
        launch_processes(ps, b, 3, 4);
    }
}

```

**Output:**
Stage 0, process 0
Stage 1, process 0
Stage 2, process 0
Stage 0, process 1
Stage 1, process 1
Stage 2, process 1
Stage 0, process 3
Stage 1, process 3
Stage 2, process 3
Stage 0, process 2
Stage 1, process 2
Stage 2, process 2

### Semaphores Banking Problem {#cpp-banking-problem}

- Multiple threads trying to deposit and withdraw from bank accounts

```cpp

#include "alang.hpp"

class bank_account
{
    alang::semaphore sem;
    int balance;
    int number;

public:
    bank_account(int n) :sem(1), balance(0), number(n) {}

    int get_number() { return number; }
    int get_balance() { return balance; }

    void deposit(int sum){
        sem.P();
        balance = balance + sum;
        sem.V();
    }

    void withdraw(int sum){
        sem.P();
        balance = balance - sum;
        sem.V();
    }

    void transfer_to(bank_account &b, int sum){
        if(this -> number < b.number){
        sem.P();
        b.sem.P();
        balance = balance - sum;
        b.balance = b.balance + sum;
        b.sem.V();
        sem.V();
        }else{
            sem.P();
            b.sem.P();
            balance = balance - sum;
            b.balance = b.balance + sum;
            sem.V();
            b.sem.V();
        }
    }
};
int main(){
    std::vector<bank_account *> vec;
    for (int i = 0; i < 10; ++i)
    {
        vec.push_back(new bank_account(i));
    }
    {
        processes ps;
        for (int i = 0; i < 100; ++i)
        {
            ps += [i, &vec] {
                for (int j = 0; j < 10; ++j)
                {
                    for (int k = 0; k < 10; ++k)
                    {
                        vec[j]->deposit(100);
                        vec[k]->withdraw(100);
                        vec[j]->withdraw(100);
                        vec[k]->deposit(100);
                        if (j != k)
                            vec[j]->transfer_to(*(vec[k]), 10);
                    }
                }
            };
        }
    }
    for (int i = 0; i < 10; ++i){
        alang::logl("Account ", i, " has balance ", vec[i]->get_balance());
    }
}

```

**Output**
<br>Account 0 has balance -70
<br>Account 1 has balance -240
<br>Account 2 has balance 0
<br>Account 3 has balance -210
<br>Account 4 has balance 30
<br>Account 5 has balance 110
<br>Account 6 has balance 90
<br>Account 7 has balance 90
<br>Account 8 has balance -300
<br>Account 9 has balance 240

### Monitor {#cpp-monitor}

#### Bridge Crossing Problem {#cpp-bridge}

- Cars has to drive over a bridge
- Only cars allowed in the same direction is allowed to drive at once
- Cars can drive past each other
- Cars coming from the opposite direction has to wait until the cars on the bridge have passed

```cpp
#include "alang.hpp"
#include <array>

using alang::logl;
using alang::prandom;
using alang::sleep_ms;
using std::array;
using std::string;

// "?" is a conditional statment in c++. If north is true, north is return, otherwise south
enum direction{ north = 0, south = 1};
direction opposite(direction dir){return (dir == north ? south : north);}

class bridge :  monitor{
    private:
        array<int, 2> ncars = { 0,0 }; // creates an array to see how many cars going in each direction
        // invariant ncars[north] == 0 ||Â ncars[south] == 0
        cond empty_bridge;
    public:
        bridge() {}
            array<int, 2> bridge_status(){
                SYNC;
                return ncars;
            }

            void car_arrive(direction dir){
                SYNC;
                while(ncars[opposite(dir)] != 0){
                    wait(empty_bridge);
                }
                ++(ncars[dir]);
            }

            void car_leave(direction dir){
            {
                SYNC;
                --(ncars[dir]);
            }
            if(ncars[dir]==0)
                signal_all(empty_bridge);
            }
};

auto car(bridge &b,
         int max_crossings,     // cross at most this many times
         int min_crossing_time, // crossing takes at least this long
         int max_crossing_time, // crossing takes at most this long
         int min_idle_time,     // wait at least this long before trying to cross again
         int max_idle_time){ // wait at most this long before trying to cross again

    return [=, &b] {
        direction dir = static_cast<direction>(prandom(0, 1)); // Casts a random direction
        int n = prandom(max_crossings);

        while(n-- > 0)
        {
            sleep_ms(prandom(min_idle_time, max_idle_time)); // Random idle time
            b.car_arrive(dir); // car arrives on bridge
            array<int, 2> counts = b.bridge_status(); // car on bridge checks car distrubution(invariant)
            assert(counts[north] == 0 || counts[south] == 0); // checks if it is empty

            if(counts[north] > 0)
                logl(string(counts[north], 'N'));
            else
                 logl(string(counts[south], 'S'));

            alang::sleep_ms(alang::prandom(min_crossing_time, max_crossing_time)); //random crossing time for car
            b.car_leave(dir); // bye bye car

            counts = b.bridge_status(); // checks bridge status againg
            assert(counts[north] == 0 || counts[south] == 0);

            dir = opposite(dir); // car turns back
        }
    };
}

int main(){
    bridge b;{
        processes ps;
        for (int i = 0; i < 10; i++){
            ps += car(b, 8, 1, 10, 2, 20);
             // 10 cars, 8 crossings each, each crossing takes 1-10ms, each car waits 2-20 ms
        }
    }
}

```

**Output:**
<br>N
<br>NN
<br>S
<br>SS
<br>SSS
<br>SSS
<br>N
<br>NN
<br>NNN
<br>S
<br>...

### Message Passing and Channels {#message-passing-channels}

- P1 sends random numbers to P2
- When P1 generates -1, P2 sends back the sum of the numbers sent by P1

```cpp
#include "alang.hpp"

alang::channel<int> c1, c2;

int main(){
    processes ps;
    ps += [] {
        int sum, m;
        while(m != -1){
			m = alang::prandom(-1, 10);
            c1.send(m);
            alang::logl("Sent ", m);
    	}
		c2.receive(sum);
		alang::logl("Recieved sum ", sum);
	};

    ps += [] {
        int sum, m = 0;
		while(true){
			c1.receive(m);
			alang::logl("Recieved ", m);
			if(m == -1)	break;
			sum += m;
			}
		alang::logl("Sending sum ", sum);
		c2.send(sum);
    };
}

```

### Filters With Quicksort {#filters-with-quicksort}

```cpp
#include "alang.hpp"

using d_channel = alang::channel<int>;
using alang::channel;
using alang::prandom;
using std::vector;

const int EOS = -1;

void partition_filter(int pivot, d_channel in1, d_channel out1, d_channel out2){
    int r;
    in1.receive(r);
    while(r != EOS){
        if(r <= pivot)
            out1.send(r);
        else
            out2.send(r);
        in1.receive(r);
    }
    out1.send(EOS);
    out2.send(EOS);
}

void merge_filter(d_channel in1, d_channel in2, d_channel out){
    int v1, v2;
    in1.receive(v1);
    in2.receive(v2);
    while (v1 != EOS && v2 != EOS){
        if (v1 <= v2){
            out.send(v1);
            in1.receive(v1);
        } else{
            out.send(v2);
            in2.receive(v2);
        }
    }while (v1 != EOS)  {
        out.send(v1);
        in1.receive(v1);
    }   while (v2 != EOS)  {
        out.send(v2);
        in2.receive(v2);
    }
    out.send(EOS);
}

void quick_sort(d_channel in, d_channel out){
    int pivot;
    in.receive(pivot);
    if(pivot == EOS){
        out.send(EOS);
        return;
    }
    d_channel sort1, sort2, o1, o2;

    processes ps;
    ps += [&]() { partition_filter(pivot, in, o1, o2); };
    ps += [&]() { quick_sort(o1, sort1); };
    ps += [&]() { sort2.send(pivot); quick_sort(o2,sort2); };
    ps += [&]() { merge_filter(sort1, sort2, out); };
}


int main(){
    const int EOS = -1;
    vector<int> vin, vout;{
        d_channel in, out; // note: channels are defined before ps, so that they are destructed after ps
        processes ps;

        ps += [&] { quick_sort(in, out); };

        ps += [&] {
            int p;
            do{
                p = prandom(-1, 10);
                vin.push_back(p);
                in.send(p);
            } while (p != EOS);
        };
        ps += [&] {
            while (true){
                int p;
                out.receive(p);
                vout.push_back(p);
                if (p == EOS)break;
            }
        };
    }
    for (auto i : vin)
        log(i, " ");
    logl();
    for (auto i : vout)
        log(i, " ");
    logl();
}

```

### Saving Account {#savings-account}

```cpp
#include "alang.hpp"

using alang::channel;
using std::to_string;
using std::vector;

using money = int;
using option = int;
using reply = money;

channel <channel<reply> , option, money> request;

const int DEPOSIT = 0, WITHDRAW = 1, KILL = 2;

auto bankServer = [] {
    std::deque<std::pair<channel<reply>, money>> queue;
    int balance = 0;
    while(true)
    {
        channel<reply> reply_channel;

        option op;
        money amount;

        request.receive(reply_channel, op, amount);
        switch (op)
        {

        case DEPOSIT:
            balance += amount;
            reply_channel.send(balance);

            while(!queue.empty())
            {
                auto p = queue.front();
                if(p.second < balance)
                {
                    balance -= p.second;
                    p.first.send(balance);
                    queue.pop_front();
                }else{
                    break;
                }
            }
            break;

        case WITHDRAW:
            if(amount > balance)
            {
                queue.push_back(std::make_pair(reply_channel, amount));

            }
            else{
                balance -= amount;
                reply_channel.send(amount);
            }
            break;

        case KILL: return;
        }
    }
};

int main(){
    processes ps;
    ps += [] {
        reply r;
        channel<reply> ch;
        for (int i = 0; i < 10; ++i)
        {
            request.send(ch, DEPOSIT, 100);
            ch.receive(r);
            logl(r);
        }
    };
    ps += [] {
        reply r;
        channel<reply> ch;
        for (int i = 0; i < 10; ++i)
        {
            request.send(ch, WITHDRAW, 100);
            ch.receive(r);
            logl(r);
        }
    };
    ps += bankServer;
    sleep(100ms);
    request.send(channel<reply>(), KILL, 0);

}


```

    };
    ps += bankServer;
    sleep(100ms);
    request.send(channel<reply>(), KILL, 0);

}


```
